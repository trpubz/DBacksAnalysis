{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Prep & Modeling\n",
    "## Filtering"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3m83__aSeqPA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-set shape prior to filtering: (867, 30)\n",
      "data-set shape after to filtering sac hits: (865, 30)\n",
      "data-set shape after to filtering missing spin observations: (859, 30)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "marte_raw = pd.read_csv('marte_vs_nlwest_19_22.csv',\n",
    "                        usecols=['pitch_type', 'game_date', 'release_speed', 'release_pos_x', 'release_pos_z', 'pitcher', 'zone', 'des', 'p_throws', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x', 'pfx_z', 'hc_x', 'hc_y', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_spin_rate', 'release_extension', 'estimated_woba_using_speedangle', 'woba_value', 'woba_denom', 'iso_value', 'launch_speed_angle', 'pitch_name', 'spin_axis'])\n",
    "\n",
    "# rename the primary response variable\n",
    "marte_raw.rename(columns={'estimated_woba_using_speedangle': 'xwOBA'}, inplace=True)\n",
    "print(f\"data-set shape prior to filtering: {marte_raw.shape}\")\n",
    "\n",
    "# filter sacrifice events; if woba_denom is NaN, then sacrifice event\n",
    "marte_raw.dropna(axis='rows', subset=['woba_denom'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering sac hits: {marte_raw.shape}\")\n",
    "\n",
    "# filter missing observation data\n",
    "marte_raw.dropna(axis='rows', subset=['release_spin_rate', 'spin_axis'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering missing spin observations: {marte_raw.shape}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjpJVOHZeqPD",
    "outputId": "8a3f1122-c3ed-40be-ede5-aad90efd49bf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- release_speed\n",
    "    - Pitch velocities from 2008-16 are via Pitch F/X, and adjusted to roughly out-of-hand release point. All velocities from 2017 and beyond are Statcast, which are reported out-of-hand.\n",
    "- release_pos_x\n",
    "    - horizontal Release Position of the ball measured in feet from the catcher's perspective.\n",
    "- release_pos_z\n",
    "    - Vertical Release Position of the ball measured in feet from the catcher's perspective.\n",
    "- plate_x\n",
    "    - Horizontal position of the ball when it crosses home plate from the catcher's perspective.\n",
    "- plate_z\n",
    "    - Vertical position of the ball when it crosses home plate from the catcher's perspective.\n",
    "- pitcher\n",
    "    - MLB Player Id tied to the play event.\n",
    "- zone\n",
    "    - Zone location of the ball when it crosses the plate from the catcher's perspective.\n",
    "- pfx_x\n",
    "    - Horizontal movement in feet from the catcher's perspective.\n",
    "- pfx_z\n",
    "    - Vertical movement in feet from the catcher's perpsective.\n",
    "- effective_speed\n",
    "    - Derived speed based on the the extension of the pitcher's release.\n",
    "- release_spin\n",
    "    - Spin rate of pitch tracked by Statcast.\n",
    "- spin_axis\n",
    "    - The Spin Axis in the 2D X-Z plane in degrees from 0 to 360, such that 180 represents a pure backspin fastball and 0 degrees represents a pure topspin (12-6) curveball"
   ],
   "metadata": {
    "collapsed": false,
    "id": "LFY3TD-xeqPF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtering ext., Computed Features, NaN Conversions"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wd6jzfWWeqPF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data-set shape after to filtering for proper metrics: (859, 12)\n",
      "number of NaN xwOBA PAs prior to conversion: 184\n",
      "data-set shape after to filtering walks: (805, 13)\n",
      "   xwOBA  woba_value  game_year  pitcher p_throws pitch_type  release_speed  \\\n",
      "0  0.709         0.9       2022   596001        R         SI           92.9   \n",
      "1  0.262         0.0       2022   596001        R         SI           92.6   \n",
      "2  0.231         0.0       2022   596001        R         SI           93.0   \n",
      "3  0.117         0.0       2022   518397        L         SI           93.3   \n",
      "4  0.438         0.0       2022   502171        R         SI           94.1   \n",
      "\n",
      "   release_spin_rate  spin_axis  zone  pfx_x  pfx_z     pfx_v  \n",
      "0             2303.0      211.0     5  -1.15   0.68  1.336001  \n",
      "1             2316.0      204.0     9  -1.05   0.80  1.320038  \n",
      "2             2245.0      219.0     8  -1.13   0.79  1.378768  \n",
      "3             2189.0      135.0     8   1.19   0.28  1.222497  \n",
      "4             2126.0      221.0     4  -1.34   0.45  1.413542  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# filter raw set with proposed model metrics\n",
    "marte_vs = marte_raw.drop(columns=['game_date', 'release_pos_x', 'release_pos_z', 'des', 'bb_type', 'balls', 'strikes', 'hc_x', 'hc_y', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_extension', 'woba_denom', 'iso_value', 'launch_speed_angle', 'pitch_name'])\n",
    "print(f\"new data-set shape after to filtering for proper metrics: {marte_vs.shape}\")\n",
    "\n",
    "# vectorize the horizontal & vertical movement using pythagorean theorem\n",
    "marte_vs['pfx_v'] = np.sqrt(marte_vs.pfx_x ** 2 + marte_vs.pfx_z ** 2)\n",
    "\n",
    "print(f\"number of NaN xwOBA PAs prior to conversion: {marte_vs.xwOBA.isnull().sum()}\")\n",
    "\n",
    "# convert xwOBA stat to 0.0 for strikeouts\n",
    "# if the xwOBA stat is NaN & a strikeout, then need to use the woba_value\n",
    "\n",
    "marte_vs['xwOBA'] = marte_vs.apply(lambda x: x.woba_value if (math.isnan(x.xwOBA) and x.woba_value == 0.0) else x.xwOBA, axis=1)\n",
    "\n",
    "# filter out walks, dropped 54 walks\n",
    "marte_vs.dropna(axis='rows', subset=['xwOBA'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering walks: {marte_vs.shape}\")\n",
    "\n",
    "# reorder columns for logical readability\n",
    "marte_vs = marte_vs.reindex(columns=['xwOBA', 'woba_value','game_year', 'pitcher', 'p_throws', 'pitch_type', 'release_speed', 'release_spin_rate', 'spin_axis', 'zone', 'pfx_x', 'pfx_z', 'pfx_v'])\n",
    "\n",
    "print(marte_vs.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXIpP4T_eqPF",
    "outputId": "836785a0-8c81-47e6-b56e-ae3c079fdb0d"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:ylabel='Count'>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Yeo-Johnson transformation of output\n",
    "pt_out = PowerTransformer(standardize=True)\n",
    "# extract target and convert to 1D array\n",
    "y_xwOBA = marte_vs.xwOBA.to_numpy().reshape(-1, 1)\n",
    "# transformation\n",
    "trx_xwOBA = pt_out.fit_transform(y_xwOBA)\n",
    "sns.histplot(trx_xwOBA)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "ya5e7LEAeqPH",
    "outputId": "f780d700-7b90-4b4a-e5c0-b09537306e92"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations\n",
    "### Dummies\n",
    "A common mistake is to apply transformations to the entire data before splitting into training and test sets. This will bias the model evaluation because information would have leaked from the test set to the training set."
   ],
   "metadata": {
    "collapsed": false,
    "id": "k8-b34Z7eqPJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   xwOBA  woba_value  game_year  pitcher  release_speed  release_spin_rate  \\\n0  0.709         0.9       2022   596001           92.9             2303.0   \n1  0.262         0.0       2022   596001           92.6             2316.0   \n2  0.231         0.0       2022   596001           93.0             2245.0   \n3  0.117         0.0       2022   518397           93.3             2189.0   \n4  0.438         0.0       2022   502171           94.1             2126.0   \n\n   spin_axis  pfx_x  pfx_z     pfx_v  ...  zone_5  zone_6  zone_7  zone_8  \\\n0      211.0  -1.15   0.68  1.336001  ...       1       0       0       0   \n1      204.0  -1.05   0.80  1.320038  ...       0       0       0       0   \n2      219.0  -1.13   0.79  1.378768  ...       0       0       0       1   \n3      135.0   1.19   0.28  1.222497  ...       0       0       0       1   \n4      221.0  -1.34   0.45  1.413542  ...       0       0       0       0   \n\n   zone_9  zone_11  zone_12  zone_13  zone_14  p_throws_R  \n0       0        0        0        0        0           1  \n1       1        0        0        0        0           1  \n2       0        0        0        0        0           1  \n3       0        0        0        0        0           0  \n4       0        0        0        0        0           1  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xwOBA</th>\n      <th>woba_value</th>\n      <th>game_year</th>\n      <th>pitcher</th>\n      <th>release_speed</th>\n      <th>release_spin_rate</th>\n      <th>spin_axis</th>\n      <th>pfx_x</th>\n      <th>pfx_z</th>\n      <th>pfx_v</th>\n      <th>...</th>\n      <th>zone_5</th>\n      <th>zone_6</th>\n      <th>zone_7</th>\n      <th>zone_8</th>\n      <th>zone_9</th>\n      <th>zone_11</th>\n      <th>zone_12</th>\n      <th>zone_13</th>\n      <th>zone_14</th>\n      <th>p_throws_R</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.709</td>\n      <td>0.9</td>\n      <td>2022</td>\n      <td>596001</td>\n      <td>92.9</td>\n      <td>2303.0</td>\n      <td>211.0</td>\n      <td>-1.15</td>\n      <td>0.68</td>\n      <td>1.336001</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.262</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>596001</td>\n      <td>92.6</td>\n      <td>2316.0</td>\n      <td>204.0</td>\n      <td>-1.05</td>\n      <td>0.80</td>\n      <td>1.320038</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.231</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>596001</td>\n      <td>93.0</td>\n      <td>2245.0</td>\n      <td>219.0</td>\n      <td>-1.13</td>\n      <td>0.79</td>\n      <td>1.378768</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.117</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>518397</td>\n      <td>93.3</td>\n      <td>2189.0</td>\n      <td>135.0</td>\n      <td>1.19</td>\n      <td>0.28</td>\n      <td>1.222497</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.438</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>502171</td>\n      <td>94.1</td>\n      <td>2126.0</td>\n      <td>221.0</td>\n      <td>-1.34</td>\n      <td>0.45</td>\n      <td>1.413542</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marte_vs_trx = pd.get_dummies(data=marte_vs, columns=['pitch_type', 'zone'])\n",
    "marte_vs_trx = pd.get_dummies(data=marte_vs_trx, columns=['p_throws'], drop_first=True)\n",
    "marte_vs_trx.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "84OYs0UjeqPJ",
    "outputId": "c585b648-7d5f-4f37-8af4-6d16a33516c9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature and output transformations"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eOHPujHyeqPJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = marte_vs_trx.drop(columns=['xwOBA', 'game_year', 'pitcher'])  # remove response var and extra features\n",
    "y = marte_vs.xwOBA\n",
    "# split data into training and testing sets\n",
    "\n",
    "X = sm.add_constant(X)   # only needed for sm (not smf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=1642)\n",
    "\n",
    "print('Train set shape\\n', X_train.shape, y_train.shape)\n",
    "print('Test set shape\\n', X_test.shape, y_test.shape)\n",
    "print('---')\n",
    "\n",
    "# transform numerical data\n",
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "\n",
    "num_feats = ['release_speed', 'release_spin_rate', 'spin_axis', 'pfx_v', 'pfx_x', 'pfx_z']\n",
    "# used for positive values\n",
    "pt = PowerTransformer()\n",
    "# get a transformed series of numerical features\n",
    "X_train_trx = pt.fit_transform(X_train[num_feats])\n",
    "# overwrite raw numerical data\n",
    "X_train[num_feats] = X_train_trx\n",
    "\n",
    "# transform the test set with the trained lambdas\n",
    "X_test_trx = pt.transform(X_test[num_feats])\n",
    "# overwrite raw numerical dataframe\n",
    "X_test[num_feats] = X_test_trx\n",
    "############################\n",
    "# # normalize output\n",
    "mms = MinMaxScaler().fit(y_train.to_numpy().reshape(-1, 1))\n",
    "y_train_trx = pd.Series(map(lambda x: x[0], mms.transform(y_train.to_numpy().reshape(-1, 1))), index=y_train.index)\n",
    "# normalize on the test output, converted to a pandas.Series with the original indicies\n",
    "y_test_trx = pd.Series(map(lambda x: x[0], mms.transform(y_test.to_numpy().reshape(-1, 1))), index=y_test.index)\n",
    "\n",
    "# drop woba_value from feature after use in normalizing response\n",
    "X_train.drop(columns=['woba_value'], inplace=True)\n",
    "X_test.drop(columns=['woba_value'], inplace=True)\n",
    "\n",
    "print('Train trx set shape\\n', X_train_trx.shape, y_train_trx.shape)\n",
    "print('Test trx set shape\\n', X_test_trx.shape, y_test_trx.shape)\n",
    "print('---')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua5JsML8eqPJ",
    "outputId": "042f0b6e-7ecb-49aa-d3a9-1a0554da0670"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling\n",
    "### Naive Model\n",
    "*Note: did not transform the output for the naive model."
   ],
   "metadata": {
    "collapsed": false,
    "id": "8IiTdci1eqPK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Marte's xwOBA for last 4 seasons ('19-'22) == .348\n",
    "from sklearn.metrics import *\n",
    "\n",
    "print(y.mean())\n",
    "y_same_xwOBA = pd.Series(.348, index=range(0, y_train.size))\n",
    "# if squared is false then rmse\n",
    "naive_rmse = mean_squared_error(y_true=y_train, y_pred=y_same_xwOBA, squared=False)\n",
    "print(f\"naive mse: {naive_rmse}\")\n",
    "\n",
    "naive_r2 = r2_score(y_true=y_train, y_pred=y_same_xwOBA)\n",
    "print(f\"naive r2 score: {naive_r2}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvUQkDpNeqPK",
    "outputId": "f156edcb-0b57-4917-f72d-fd9beeca1577"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NN\n",
    "#### Model 1"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZwwZvAkgeqPM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "# normalizer = preprocessing.Normalization()\n",
    "# normalizer.adapt(np.array(train_features))\n",
    "X_1 = X_train.release_spin_rate\n",
    "X_1_test = X_test.release_spin_rate\n",
    "number_of_inputs = 1  # number of features\n",
    "model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_1,\n",
    "    y_train_trx,\n",
    "    batch_size=42,\n",
    "    epochs=16,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_1_test, y_test_trx),\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_1_test, y_test_trx, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_1_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "TCMOA02OeqPM",
    "outputId": "6a57723d-c5a4-4fc5-faea-356d1b3d4949"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NN2 -- Higher Fidelity Model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "75g2YTHVeqPN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_feats2 = ['release_speed', 'release_spin_rate', 'spin_axis', 'pfx_v', 'pitch_type_CH', 'pitch_type_CS', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL', 'zone_1', 'zone_2', 'zone_3', 'zone_4', 'zone_5', 'zone_6', 'zone_7', 'zone_8', 'zone_9', 'zone_11', 'zone_12', 'zone_13', 'zone_14', 'p_throws_R']\n",
    "X_full = X_train[X_feats2]\n",
    "X_full_test = X_test[X_feats2]\n",
    "number_of_inputs = X_full.shape[1]  # number of features\n",
    "model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=32,\n",
    "    epochs=16,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "TfuKL2MleqPN",
    "outputId": "42a3ac58-d9db-4075-a12c-6fd35f73ad22"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "X_feats3 = ['release_speed', 'release_spin_rate', 'spin_axis', 'pfx_v', 'pitch_type_CH', 'pitch_type_CS', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL']\n",
    "X_full = X_train[X_feats3]\n",
    "X_full_test = X_test[X_feats3]\n",
    "number_of_inputs = X_full.shape[1]  # number of features\n",
    "model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(), bias_regularizer=regularizers.l1()),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=32,\n",
    "    epochs=4000,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "WGQcArJAeqPN",
    "outputId": "65214ea7-8b91-4fe1-ef28-3d52ec4c0f6c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyper sweep"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GRJuMVxYeqPN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_and_compile_model():\n",
    "    # create model\n",
    "    model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                              layers.Dense(16, activation='relu'),\n",
    "                              layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_and_compile_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [8, 16, 32, 64, 128]\n",
    "epochs = [10, 50, 250, 1250]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_full, y_train_trx)"
   ],
   "metadata": {
    "id": "Oa7tgTCKeqPN",
    "outputId": "71ed2d3c-6c54-439c-e5e7-dc8d9d300090"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"train accuracy %f for: %r\" % (mean, param))"
   ],
   "metadata": {
    "id": "N0MGbe69eqPO",
    "outputId": "c5ef14b0-4b59-4c8e-afe4-6c3c51d8dba7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def create_and_compile_model(num_neurons, num_layers):\n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=number_of_inputs, activation='relu'))\n",
    "\n",
    "    if num_layers > 0:\n",
    "\n",
    "        while num_layers > 0:\n",
    "            model.add(Dense(num_neurons, activation='relu'))\n",
    "            num_layers=num_layers-1\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation='linear')) # output layer for regression\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    print(model.summary())\n",
    "    print('--')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_and_compile_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "num_neurons_grid = [4, 8, 16]\n",
    "num_layers_grid = [1, 2, 3, 4]\n",
    "\n",
    "param_grid = dict(num_neurons=num_neurons_grid, num_layers=num_layers_grid)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_full, y_train_trx)"
   ],
   "metadata": {
    "id": "hNCHKDI2eqPO",
    "outputId": "86f1f710-d14d-484d-f061-9177a1a23a5c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"train accuracy %f for: %r\" % (mean, param))"
   ],
   "metadata": {
    "id": "ivLCP-mKeqPO",
    "outputId": "3fcdebf0-1f38-4bbd-9f73-b663b1a8bef3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Combining Sweep\n",
    "layers = 4\n",
    "neurons = 8\n",
    "batch_size = 8\n",
    "epochs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "id": "dcDdbQIGeqPO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.Sequential([layers.Dense(8, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(8, activation='relu'),\n",
    "                          layers.Dense(8, activation='relu'),\n",
    "                          layers.Dense(8, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=8,\n",
    "    epochs=10,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "HA6M9GnZeqPO",
    "outputId": "e832cdea-8e1e-4ce8-cfa0-00f0291f4f5c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "factor = 0.01\n",
    "model = keras.Sequential([layers.Dense(8, activation='relu', input_dim=number_of_inputs, kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=8,\n",
    "    epochs=10,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "noz0g6sLeqPP",
    "outputId": "56e08cae-c25b-46f7-87ab-d04ac3f36f8a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TW NN"
   ],
   "metadata": {
    "id": "LK4GPXF6h81X"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the loss plot\n",
    "def plot_loss(history, num_neurons):\n",
    "  plt.plot(history.history['mse'], label='mse')\n",
    "  plt.plot(history.history['val_mse'], label='val_mse')\n",
    "  # plt.ylim([0, y_lim])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('mse')\n",
    "  plt.legend()\n",
    "  plt.title(f\"{num_neurons} neurons\")\n",
    "\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from   tensorflow import keras\n",
    "from   tensorflow.keras import layers, regularizers\n",
    "from   tensorflow.keras.layers.experimental import preprocessing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from   tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#setup normalizer\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(X_train))\n",
    "\n",
    "number_of_inputs= X_train.shape[1]\n",
    "print(f\"# of inputs = {number_of_inputs}\")\n",
    "\n",
    "num_neurons = 3\n",
    "\n",
    "# create model\n",
    "model = keras.Sequential([normalizer,\n",
    "                          layers.Dense(num_neurons, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(num_neurons, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ])  \n",
    "  \n",
    "model.compile(loss='mse',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics='mse')\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_split = 0.2)  # Calculate validation results on 20% of the training data\n",
    "                  \n",
    "# Isolate and plot training curves \n",
    "hist = pd.DataFrame(history.history)\n",
    "plot_loss(history, num_neurons)\n",
    "\n",
    "# calculate metrics ---------------\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# train\n",
    "y_pred = model.predict(X_train)\n",
    "print(f\"MAE Train = {mean_absolute_error(y_train, y_pred)}\")\n",
    "print(f\"MSE Train = { mean_squared_error(y_train, y_pred)}\")\n",
    "print(f\"R2  = {                 r2_score(y_train, y_pred)}\")\n",
    "print(f\"\")\n",
    "\n",
    "# holdout\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"MAE Test = {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MSE Test = { mean_squared_error(y_test, y_pred)}\")\n",
    "print(f\"R2  = {                r2_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7W-1w75ceqPP",
    "outputId": "895b9f00-63a2-47ea-f495-9a999799e9b7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TW NN neurons sweep"
   ],
   "metadata": {
    "id": "0c2FEQCjiZIj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the loss plot\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['mse'], label='mse')\n",
    "  plt.plot(history.history['val_mse'], label='val_mse')\n",
    "  # plt.ylim([0, y_lim])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('mse')\n",
    "  plt.legend()\n",
    "  plt.title(f\"{num_neurons} neurons\")\n",
    "\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "#setup normalizer\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(X_train))\n",
    "\n",
    "number_of_inputs = X_train.shape[1]\n",
    "\n",
    "# sweep neurons\n",
    "mse_list = []\n",
    "val_mse_list = []\n",
    "\n",
    "neurons_to_try = [1, 2, 3, 5, 7, 10, 15]\n",
    "\n",
    "for num_neurons in neurons_to_try:\n",
    "\n",
    "  #---- pasted in model\n",
    "  model = keras.Sequential([normalizer,\n",
    "                            layers.Dense(num_neurons, activation = 'relu', input_dim = number_of_inputs),\n",
    "                            layers.Dense(num_neurons, activation = 'relu'),\n",
    "                            layers.Dense(1, activation = 'linear') ])\n",
    "    \n",
    "  model.compile(loss='mse',\n",
    "                optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "                metrics = 'mse')\n",
    "\n",
    "  history = model.fit(X_train, y_train, \n",
    "                      epochs = 100,\n",
    "                      batch_size = 32,\n",
    "                      validation_split = 0.2)  # Calculate validation results on 20% of the training data\n",
    "                    \n",
    "  # Isolate the metric for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  #---- end model paste\n",
    "\n",
    "  # record metrics\n",
    "\n",
    "  current_mse = hist['mse']\n",
    "  current_mse = current_mse[len(current_mse)-1]  # last element is the final value\n",
    "  mse_list.append(current_mse)  \n",
    "\n",
    "  current_val_mse = hist['val_mse']\n",
    "  current_val_mse = current_val_mse[len(current_val_mse)-1] #  last element is the final value\n",
    "  val_mse_list.append(current_val_mse)\n",
    "\n",
    "  plot_loss(history)\n",
    "\n",
    "  # calculate metrics ---------------\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  from sklearn.metrics import r2_score\n",
    "\n",
    "  # train\n",
    "  y_pred = model.predict(X_train)\n",
    "  print(f\"MAE Train = {mean_absolute_error(y_train, y_pred)}\")\n",
    "  print(f\"MSE Train = { mean_squared_error(y_train, y_pred)}\")\n",
    "  print(f\"R2  = {                 r2_score(y_train, y_pred)}\")\n",
    "  print(f\"\")\n",
    "\n",
    "  # holdout\n",
    "  y_pred = model.predict(X_test)\n",
    "  print(f\"MAE Test = {mean_absolute_error(y_test, y_pred)}\")\n",
    "  print(f\"MSE Test = { mean_squared_error(y_test, y_pred)}\")\n",
    "  print(f\"R2  = {                r2_score(y_test, y_pred)}\")\n",
    "\n",
    "#plot results of sweep\n",
    "plt.plot(neurons_to_try, mse_list, label='MSE')\n",
    "plt.plot(neurons_to_try, val_mse_list, label='Validation MSE')\n",
    "\n",
    "# plt.ylim([1,y_lim])\n",
    "plt.xlabel('Neurons')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VrbOdqLPia1K",
    "outputId": "9fb216d3-60ad-4ff1-e215-ac8ec1bb0623"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
