{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Prep & Modeling\n",
    "## Filtering"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3m83__aSeqPA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-set shape prior to filtering: (867, 30)\n",
      "data-set shape after to filtering sac hits: (865, 30)\n",
      "data-set shape after to filtering missing spin observations: (859, 30)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "marte_raw = pd.read_csv('marte_vs_nlwest_19_22.csv',\n",
    "                        usecols=['pitch_type', 'game_date', 'release_speed', 'release_pos_x', 'release_pos_z', 'pitcher', 'zone', 'des', 'p_throws', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x', 'pfx_z', 'hc_x', 'hc_y', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_spin_rate', 'release_extension', 'estimated_woba_using_speedangle', 'woba_value', 'woba_denom', 'iso_value', 'launch_speed_angle', 'pitch_name', 'spin_axis'])\n",
    "\n",
    "# rename the primary response variable\n",
    "marte_raw.rename(columns={'estimated_woba_using_speedangle': 'xwOBA'}, inplace=True)\n",
    "print(f\"data-set shape prior to filtering: {marte_raw.shape}\")\n",
    "\n",
    "# filter sacrifice events; if woba_denom is NaN, then sacrifice event\n",
    "marte_raw.dropna(axis='rows', subset=['woba_denom'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering sac hits: {marte_raw.shape}\")\n",
    "\n",
    "# filter missing observation data\n",
    "marte_raw.dropna(axis='rows', subset=['release_spin_rate', 'spin_axis'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering missing spin observations: {marte_raw.shape}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjpJVOHZeqPD",
    "outputId": "8a3f1122-c3ed-40be-ede5-aad90efd49bf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- release_speed\n",
    "    - Pitch velocities from 2008-16 are via Pitch F/X, and adjusted to roughly out-of-hand release point. All velocities from 2017 and beyond are Statcast, which are reported out-of-hand.\n",
    "- release_pos_x\n",
    "    - horizontal Release Position of the ball measured in feet from the catcher's perspective.\n",
    "- release_pos_z\n",
    "    - Vertical Release Position of the ball measured in feet from the catcher's perspective.\n",
    "- plate_x\n",
    "    - Horizontal position of the ball when it crosses home plate from the catcher's perspective.\n",
    "- plate_z\n",
    "    - Vertical position of the ball when it crosses home plate from the catcher's perspective.\n",
    "- pitcher\n",
    "    - MLB Player Id tied to the play event.\n",
    "- zone\n",
    "    - Zone location of the ball when it crosses the plate from the catcher's perspective.\n",
    "- pfx_x\n",
    "    - Horizontal movement in feet from the catcher's perspective.\n",
    "- pfx_z\n",
    "    - Vertical movement in feet from the catcher's perpsective.\n",
    "- effective_speed\n",
    "    - Derived speed based on the the extension of the pitcher's release.\n",
    "- release_spin\n",
    "    - Spin rate of pitch tracked by Statcast.\n",
    "- spin_axis\n",
    "    - The Spin Axis in the 2D X-Z plane in degrees from 0 to 360, such that 180 represents a pure backspin fastball and 0 degrees represents a pure topspin (12-6) curveball"
   ],
   "metadata": {
    "collapsed": false,
    "id": "LFY3TD-xeqPF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtering ext., Computed Features, NaN Conversions"
   ],
   "metadata": {
    "collapsed": false,
    "id": "wd6jzfWWeqPF"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new data-set shape after to filtering for proper metrics: (859, 12)\n",
      "number of NaN xwOBA PAs prior to conversion: 184\n",
      "data-set shape after to filtering walks: (805, 13)\n",
      "   xwOBA  woba_value  game_year  pitcher p_throws pitch_type  release_speed  \\\n",
      "0  0.709         0.9       2022   596001        R         SI           92.9   \n",
      "1  0.262         0.0       2022   596001        R         SI           92.6   \n",
      "2  0.231         0.0       2022   596001        R         SI           93.0   \n",
      "3  0.117         0.0       2022   518397        L         SI           93.3   \n",
      "4  0.438         0.0       2022   502171        R         SI           94.1   \n",
      "\n",
      "   release_spin_rate  spin_axis  zone  pfx_x  pfx_z     pfx_v  \n",
      "0             2303.0      211.0     5  -1.15   0.68  1.336001  \n",
      "1             2316.0      204.0     9  -1.05   0.80  1.320038  \n",
      "2             2245.0      219.0     8  -1.13   0.79  1.378768  \n",
      "3             2189.0      135.0     8   1.19   0.28  1.222497  \n",
      "4             2126.0      221.0     4  -1.34   0.45  1.413542  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# filter raw set with proposed model metrics\n",
    "marte_vs = marte_raw.drop(columns=['game_date', 'release_pos_x', 'release_pos_z', 'des', 'bb_type', 'balls', 'strikes', 'hc_x', 'hc_y', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_extension', 'woba_denom', 'iso_value', 'launch_speed_angle', 'pitch_name'])\n",
    "print(f\"new data-set shape after to filtering for proper metrics: {marte_vs.shape}\")\n",
    "\n",
    "# vectorize the horizontal & vertical movement using pythagorean theorem\n",
    "marte_vs['pfx_v'] = np.sqrt(marte_vs.pfx_x ** 2 + marte_vs.pfx_z ** 2)\n",
    "\n",
    "print(f\"number of NaN xwOBA PAs prior to conversion: {marte_vs.xwOBA.isnull().sum()}\")\n",
    "\n",
    "# convert xwOBA stat to 0.0 for strikeouts\n",
    "# if the xwOBA stat is NaN & a strikeout, then need to use the woba_value\n",
    "\n",
    "marte_vs['xwOBA'] = marte_vs.apply(lambda x: x.woba_value if (math.isnan(x.xwOBA) and x.woba_value == 0.0) else x.xwOBA, axis=1)\n",
    "\n",
    "# filter out walks, dropped 54 walks\n",
    "marte_vs.dropna(axis='rows', subset=['xwOBA'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering walks: {marte_vs.shape}\")\n",
    "\n",
    "# reorder columns for logical readability\n",
    "marte_vs = marte_vs.reindex(columns=['xwOBA', 'woba_value','game_year', 'pitcher', 'p_throws', 'pitch_type', 'release_speed', 'release_spin_rate', 'spin_axis', 'zone', 'pfx_x', 'pfx_z', 'pfx_v'])\n",
    "\n",
    "print(marte_vs.head())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lXIpP4T_eqPF",
    "outputId": "836785a0-8c81-47e6-b56e-ae3c079fdb0d"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations\n",
    "### Dummies\n",
    "A common mistake is to apply transformations to the entire data before splitting into training and test sets. This will bias the model evaluation because information would have leaked from the test set to the training set."
   ],
   "metadata": {
    "collapsed": false,
    "id": "k8-b34Z7eqPJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   xwOBA  woba_value  game_year  pitcher  release_speed  release_spin_rate  \\\n0  0.709         0.9       2022   596001           92.9             2303.0   \n1  0.262         0.0       2022   596001           92.6             2316.0   \n2  0.231         0.0       2022   596001           93.0             2245.0   \n3  0.117         0.0       2022   518397           93.3             2189.0   \n4  0.438         0.0       2022   502171           94.1             2126.0   \n\n   spin_axis  pfx_x  pfx_z     pfx_v  ...  zone_5  zone_6  zone_7  zone_8  \\\n0      211.0  -1.15   0.68  1.336001  ...       1       0       0       0   \n1      204.0  -1.05   0.80  1.320038  ...       0       0       0       0   \n2      219.0  -1.13   0.79  1.378768  ...       0       0       0       1   \n3      135.0   1.19   0.28  1.222497  ...       0       0       0       1   \n4      221.0  -1.34   0.45  1.413542  ...       0       0       0       0   \n\n   zone_9  zone_11  zone_12  zone_13  zone_14  p_throws_R  \n0       0        0        0        0        0           1  \n1       1        0        0        0        0           1  \n2       0        0        0        0        0           1  \n3       0        0        0        0        0           0  \n4       0        0        0        0        0           1  \n\n[5 rows x 33 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>xwOBA</th>\n      <th>woba_value</th>\n      <th>game_year</th>\n      <th>pitcher</th>\n      <th>release_speed</th>\n      <th>release_spin_rate</th>\n      <th>spin_axis</th>\n      <th>pfx_x</th>\n      <th>pfx_z</th>\n      <th>pfx_v</th>\n      <th>...</th>\n      <th>zone_5</th>\n      <th>zone_6</th>\n      <th>zone_7</th>\n      <th>zone_8</th>\n      <th>zone_9</th>\n      <th>zone_11</th>\n      <th>zone_12</th>\n      <th>zone_13</th>\n      <th>zone_14</th>\n      <th>p_throws_R</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.709</td>\n      <td>0.9</td>\n      <td>2022</td>\n      <td>596001</td>\n      <td>92.9</td>\n      <td>2303.0</td>\n      <td>211.0</td>\n      <td>-1.15</td>\n      <td>0.68</td>\n      <td>1.336001</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.262</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>596001</td>\n      <td>92.6</td>\n      <td>2316.0</td>\n      <td>204.0</td>\n      <td>-1.05</td>\n      <td>0.80</td>\n      <td>1.320038</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.231</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>596001</td>\n      <td>93.0</td>\n      <td>2245.0</td>\n      <td>219.0</td>\n      <td>-1.13</td>\n      <td>0.79</td>\n      <td>1.378768</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.117</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>518397</td>\n      <td>93.3</td>\n      <td>2189.0</td>\n      <td>135.0</td>\n      <td>1.19</td>\n      <td>0.28</td>\n      <td>1.222497</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.438</td>\n      <td>0.0</td>\n      <td>2022</td>\n      <td>502171</td>\n      <td>94.1</td>\n      <td>2126.0</td>\n      <td>221.0</td>\n      <td>-1.34</td>\n      <td>0.45</td>\n      <td>1.413542</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 33 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marte_vs_trx = pd.get_dummies(data=marte_vs, columns=['pitch_type', 'zone'])\n",
    "marte_vs_trx = pd.get_dummies(data=marte_vs_trx, columns=['p_throws'], drop_first=True)\n",
    "marte_vs_trx.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "84OYs0UjeqPJ",
    "outputId": "c585b648-7d5f-4f37-8af4-6d16a33516c9"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature and output transformations"
   ],
   "metadata": {
    "collapsed": false,
    "id": "eOHPujHyeqPJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape\n",
      " (523, 31) (523,)\n",
      "Test set shape\n",
      " (282, 31) (282,)\n",
      "---\n",
      "Train trx set shape\n",
      " (523, 6) (523,)\n",
      "Test trx set shape\n",
      " (282, 6) (282,)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = marte_vs_trx.drop(columns=['xwOBA', 'game_year', 'pitcher'])  # remove response var and extra features\n",
    "y = marte_vs.xwOBA\n",
    "# split data into training and testing sets\n",
    "\n",
    "X = sm.add_constant(X)   # only needed for sm (not smf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=1642)\n",
    "\n",
    "print('Train set shape\\n', X_train.shape, y_train.shape)\n",
    "print('Test set shape\\n', X_test.shape, y_test.shape)\n",
    "print('---')\n",
    "\n",
    "# transform numerical data\n",
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "\n",
    "num_feats = ['release_speed', 'release_spin_rate', 'spin_axis', 'pfx_v', 'pfx_x', 'pfx_z']\n",
    "# used for positive values\n",
    "pt = PowerTransformer()\n",
    "# get a transformed series of numerical features\n",
    "X_train_trx = pt.fit_transform(X_train[num_feats])\n",
    "# overwrite raw numerical data\n",
    "X_train[num_feats] = X_train_trx\n",
    "\n",
    "# transform the test set with the trained lambdas\n",
    "X_test_trx = pt.transform(X_test[num_feats])\n",
    "# overwrite raw numerical dataframe\n",
    "X_test[num_feats] = X_test_trx\n",
    "############################\n",
    "# # normalize output\n",
    "mms = MinMaxScaler().fit(y_train.to_numpy().reshape(-1, 1))\n",
    "y_train_trx = pd.Series(map(lambda x: x[0], mms.transform(y_train.to_numpy().reshape(-1, 1))), index=y_train.index)\n",
    "# normalize on the test output, converted to a pandas.Series with the original indicies\n",
    "y_test_trx = pd.Series(map(lambda x: x[0], mms.transform(y_test.to_numpy().reshape(-1, 1))), index=y_test.index)\n",
    "\n",
    "# drop woba_value from feature after use in normalizing response\n",
    "X_train.drop(columns=['woba_value'], inplace=True)\n",
    "X_test.drop(columns=['woba_value'], inplace=True)\n",
    "\n",
    "print('Train trx set shape\\n', X_train_trx.shape, y_train_trx.shape)\n",
    "print('Test trx set shape\\n', X_test_trx.shape, y_test_trx.shape)\n",
    "print('---')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ua5JsML8eqPJ",
    "outputId": "042f0b6e-7ecb-49aa-d3a9-1a0554da0670"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling\n",
    "### Naive Model\n",
    "*Note: did not transform the output for the naive model."
   ],
   "metadata": {
    "collapsed": false,
    "id": "8IiTdci1eqPK"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3059652173913044\n",
      "naive mse: 0.38327834366022984\n",
      "naive r2 score: -0.0034002397516113003\n"
     ]
    }
   ],
   "source": [
    "# Marte's xwOBA for last 4 seasons ('19-'22) == .348\n",
    "from sklearn.metrics import *\n",
    "\n",
    "print(y.mean())\n",
    "y_same_xwOBA = pd.Series(.348, index=range(0, y_train.size))\n",
    "# if squared is false then rmse\n",
    "naive_rmse = mean_squared_error(y_true=y_train, y_pred=y_same_xwOBA, squared=False)\n",
    "print(f\"naive mse: {naive_rmse}\")\n",
    "\n",
    "naive_r2 = r2_score(y_true=y_train, y_pred=y_same_xwOBA)\n",
    "print(f\"naive r2 score: {naive_r2}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvUQkDpNeqPK",
    "outputId": "f156edcb-0b57-4917-f72d-fd9beeca1577"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### NN\n",
    "#### Model 1"
   ],
   "metadata": {
    "collapsed": false,
    "id": "ZwwZvAkgeqPM"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:15:35.544176: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 22:15:43.148504: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 14ms/step - loss: 0.0590 - root_mean_squared_error: 0.2430 - mean_absolute_error: 0.1666 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1776 - val_mean_absolute_error: 0.1250\n",
      "Epoch 2/16\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0456 - root_mean_squared_error: 0.2136 - mean_absolute_error: 0.1528 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662 - val_mean_absolute_error: 0.1271\n",
      "Epoch 3/16\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0430 - root_mean_squared_error: 0.2073 - mean_absolute_error: 0.1563 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657 - val_mean_absolute_error: 0.1312\n",
      "Epoch 4/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0408 - root_mean_squared_error: 0.2019 - mean_absolute_error: 0.1527 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1608 - val_mean_absolute_error: 0.1263\n",
      "Epoch 5/16\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0397 - root_mean_squared_error: 0.1992 - mean_absolute_error: 0.1512 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1601 - val_mean_absolute_error: 0.1284\n",
      "Epoch 6/16\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0391 - root_mean_squared_error: 0.1977 - mean_absolute_error: 0.1517 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1602 - val_mean_absolute_error: 0.1292\n",
      "Epoch 7/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0385 - root_mean_squared_error: 0.1963 - mean_absolute_error: 0.1509 - val_loss: 0.0257 - val_root_mean_squared_error: 0.1603 - val_mean_absolute_error: 0.1301\n",
      "Epoch 8/16\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - mean_absolute_error: 0.1511 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1599 - val_mean_absolute_error: 0.1298\n",
      "Epoch 9/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0383 - root_mean_squared_error: 0.1958 - mean_absolute_error: 0.1528 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1612 - val_mean_absolute_error: 0.1328\n",
      "Epoch 10/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0382 - root_mean_squared_error: 0.1955 - mean_absolute_error: 0.1529 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1600 - val_mean_absolute_error: 0.1298\n",
      "Epoch 11/16\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 0.0383 - root_mean_squared_error: 0.1958 - mean_absolute_error: 0.1496 - val_loss: 0.0254 - val_root_mean_squared_error: 0.1593 - val_mean_absolute_error: 0.1286\n",
      "Epoch 12/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0383 - root_mean_squared_error: 0.1957 - mean_absolute_error: 0.1528 - val_loss: 0.0261 - val_root_mean_squared_error: 0.1614 - val_mean_absolute_error: 0.1337\n",
      "Epoch 13/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - mean_absolute_error: 0.1534 - val_loss: 0.0256 - val_root_mean_squared_error: 0.1599 - val_mean_absolute_error: 0.1306\n",
      "Epoch 14/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0383 - root_mean_squared_error: 0.1958 - mean_absolute_error: 0.1515 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1597 - val_mean_absolute_error: 0.1295\n",
      "Epoch 15/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0383 - root_mean_squared_error: 0.1956 - mean_absolute_error: 0.1525 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1606 - val_mean_absolute_error: 0.1323\n",
      "Epoch 16/16\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 0.0380 - root_mean_squared_error: 0.1950 - mean_absolute_error: 0.1516 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1591 - val_mean_absolute_error: 0.1290\n",
      "Evaluate on test data\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0253 - root_mean_squared_error: 0.1591 - mean_absolute_error: 0.1290\n",
      "test loss, test acc: [0.025308573618531227, 0.1590866893529892, 0.12895765900611877]\n",
      "Generate predictions for 42 samples\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "predictions shape: (42, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "\n",
    "\n",
    "# normalizer = preprocessing.Normalization()\n",
    "# normalizer.adapt(np.array(train_features))\n",
    "X_1 = X_train.release_spin_rate\n",
    "X_1_test = X_test.release_spin_rate\n",
    "number_of_inputs = 1  # number of features\n",
    "model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_1,\n",
    "    y_train_trx,\n",
    "    batch_size=42,\n",
    "    epochs=16,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_1_test, y_test_trx),\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_1_test, y_test_trx, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_1_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "TCMOA02OeqPM",
    "outputId": "6a57723d-c5a4-4fc5-faea-356d1b3d4949"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### NN2 -- Higher Fidelity Model"
   ],
   "metadata": {
    "collapsed": false,
    "id": "75g2YTHVeqPN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/16\n",
      "17/17 [==============================] - 1s 10ms/step - loss: 0.1336 - root_mean_squared_error: 0.3656 - mean_absolute_error: 0.2907 - val_loss: 0.0553 - val_root_mean_squared_error: 0.2352 - val_mean_absolute_error: 0.1688\n",
      "Epoch 2/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0585 - root_mean_squared_error: 0.2419 - mean_absolute_error: 0.1685 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1790 - val_mean_absolute_error: 0.1294\n",
      "Epoch 3/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0443 - root_mean_squared_error: 0.2104 - mean_absolute_error: 0.1554 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1760 - val_mean_absolute_error: 0.1366\n",
      "Epoch 4/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0423 - root_mean_squared_error: 0.2056 - mean_absolute_error: 0.1573 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1729 - val_mean_absolute_error: 0.1349\n",
      "Epoch 5/16\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.0407 - root_mean_squared_error: 0.2017 - mean_absolute_error: 0.1524 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1689 - val_mean_absolute_error: 0.1292\n",
      "Epoch 6/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0394 - root_mean_squared_error: 0.1985 - mean_absolute_error: 0.1495 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1677 - val_mean_absolute_error: 0.1291\n",
      "Epoch 7/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0384 - root_mean_squared_error: 0.1959 - mean_absolute_error: 0.1491 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1673 - val_mean_absolute_error: 0.1299\n",
      "Epoch 8/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0375 - root_mean_squared_error: 0.1937 - mean_absolute_error: 0.1488 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1669 - val_mean_absolute_error: 0.1303\n",
      "Epoch 9/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0368 - root_mean_squared_error: 0.1917 - mean_absolute_error: 0.1468 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1663 - val_mean_absolute_error: 0.1292\n",
      "Epoch 10/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0361 - root_mean_squared_error: 0.1901 - mean_absolute_error: 0.1449 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650 - val_mean_absolute_error: 0.1278\n",
      "Epoch 11/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0355 - root_mean_squared_error: 0.1885 - mean_absolute_error: 0.1443 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1659 - val_mean_absolute_error: 0.1295\n",
      "Epoch 12/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0350 - root_mean_squared_error: 0.1871 - mean_absolute_error: 0.1434 - val_loss: 0.0274 - val_root_mean_squared_error: 0.1655 - val_mean_absolute_error: 0.1294\n",
      "Epoch 13/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0346 - root_mean_squared_error: 0.1859 - mean_absolute_error: 0.1418 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1648 - val_mean_absolute_error: 0.1277\n",
      "Epoch 14/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0340 - root_mean_squared_error: 0.1845 - mean_absolute_error: 0.1413 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1660 - val_mean_absolute_error: 0.1298\n",
      "Epoch 15/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0336 - root_mean_squared_error: 0.1833 - mean_absolute_error: 0.1405 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662 - val_mean_absolute_error: 0.1299\n",
      "Epoch 16/16\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - mean_absolute_error: 0.1407 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1665 - val_mean_absolute_error: 0.1297\n",
      "Evaluate on test data\n",
      "18/18 [==============================] - 0s 760us/step - loss: 0.0277 - root_mean_squared_error: 0.1665 - mean_absolute_error: 0.1297\n",
      "test loss, test acc: [0.02771475352346897, 0.1664774864912033, 0.12967830896377563]\n",
      "Generate predictions for 42 samples\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "predictions shape: (42, 1)\n"
     ]
    }
   ],
   "source": [
    "X_feats2 = ['release_speed', 'release_spin_rate', 'spin_axis', 'pfx_v', 'pitch_type_CH', 'pitch_type_CS', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL', 'zone_1', 'zone_2', 'zone_3', 'zone_4', 'zone_5', 'zone_6', 'zone_7', 'zone_8', 'zone_9', 'zone_11', 'zone_12', 'zone_13', 'zone_14', 'p_throws_R']\n",
    "X_full = X_train[X_feats2]\n",
    "X_full_test = X_test[X_feats2]\n",
    "number_of_inputs = X_full.shape[1]  # number of features\n",
    "model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=32,\n",
    "    epochs=16,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "TfuKL2MleqPN",
    "outputId": "42a3ac58-d9db-4075-a12c-6fd35f73ad22"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/4000\n",
      "17/17 [==============================] - 1s 12ms/step - loss: 1.5972 - root_mean_squared_error: 0.2446 - mean_absolute_error: 0.1875 - val_loss: 1.4601 - val_root_mean_squared_error: 0.1753 - val_mean_absolute_error: 0.1310\n",
      "Epoch 2/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.3881 - root_mean_squared_error: 0.2130 - mean_absolute_error: 0.1602 - val_loss: 1.2687 - val_root_mean_squared_error: 0.1680 - val_mean_absolute_error: 0.1318\n",
      "Epoch 3/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.2034 - root_mean_squared_error: 0.2059 - mean_absolute_error: 0.1577 - val_loss: 1.0943 - val_root_mean_squared_error: 0.1635 - val_mean_absolute_error: 0.1255\n",
      "Epoch 4/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 1.0361 - root_mean_squared_error: 0.2016 - mean_absolute_error: 0.1554 - val_loss: 0.9377 - val_root_mean_squared_error: 0.1633 - val_mean_absolute_error: 0.1299\n",
      "Epoch 5/4000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.8852 - root_mean_squared_error: 0.1990 - mean_absolute_error: 0.1525 - val_loss: 0.7949 - val_root_mean_squared_error: 0.1619 - val_mean_absolute_error: 0.1284\n",
      "Epoch 6/4000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.7486 - root_mean_squared_error: 0.1970 - mean_absolute_error: 0.1517 - val_loss: 0.6672 - val_root_mean_squared_error: 0.1618 - val_mean_absolute_error: 0.1307\n",
      "Epoch 7/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.6269 - root_mean_squared_error: 0.1961 - mean_absolute_error: 0.1526 - val_loss: 0.5529 - val_root_mean_squared_error: 0.1607 - val_mean_absolute_error: 0.1296\n",
      "Epoch 8/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.5187 - root_mean_squared_error: 0.1950 - mean_absolute_error: 0.1501 - val_loss: 0.4522 - val_root_mean_squared_error: 0.1592 - val_mean_absolute_error: 0.1274\n",
      "Epoch 9/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.4242 - root_mean_squared_error: 0.1946 - mean_absolute_error: 0.1503 - val_loss: 0.3652 - val_root_mean_squared_error: 0.1593 - val_mean_absolute_error: 0.1288\n",
      "Epoch 10/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.3425 - root_mean_squared_error: 0.1942 - mean_absolute_error: 0.1504 - val_loss: 0.2900 - val_root_mean_squared_error: 0.1591 - val_mean_absolute_error: 0.1290\n",
      "Epoch 11/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2725 - root_mean_squared_error: 0.1942 - mean_absolute_error: 0.1504 - val_loss: 0.2258 - val_root_mean_squared_error: 0.1582 - val_mean_absolute_error: 0.1281\n",
      "Epoch 12/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.2136 - root_mean_squared_error: 0.1942 - mean_absolute_error: 0.1503 - val_loss: 0.1720 - val_root_mean_squared_error: 0.1570 - val_mean_absolute_error: 0.1261\n",
      "Epoch 13/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1650 - root_mean_squared_error: 0.1944 - mean_absolute_error: 0.1489 - val_loss: 0.1283 - val_root_mean_squared_error: 0.1558 - val_mean_absolute_error: 0.1240\n",
      "Epoch 14/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.1261 - root_mean_squared_error: 0.1949 - mean_absolute_error: 0.1499 - val_loss: 0.0949 - val_root_mean_squared_error: 0.1564 - val_mean_absolute_error: 0.1260\n",
      "Epoch 15/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0962 - root_mean_squared_error: 0.1952 - mean_absolute_error: 0.1504 - val_loss: 0.0691 - val_root_mean_squared_error: 0.1573 - val_mean_absolute_error: 0.1280\n",
      "Epoch 16/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0730 - root_mean_squared_error: 0.1952 - mean_absolute_error: 0.1514 - val_loss: 0.0498 - val_root_mean_squared_error: 0.1569 - val_mean_absolute_error: 0.1264\n",
      "Epoch 17/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0577 - root_mean_squared_error: 0.1958 - mean_absolute_error: 0.1504 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1575 - val_mean_absolute_error: 0.1272\n",
      "Epoch 18/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0490 - root_mean_squared_error: 0.1961 - mean_absolute_error: 0.1531 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1581 - val_mean_absolute_error: 0.1278\n",
      "Epoch 19/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0449 - root_mean_squared_error: 0.1961 - mean_absolute_error: 0.1531 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1583 - val_mean_absolute_error: 0.1277\n",
      "Epoch 20/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0426 - root_mean_squared_error: 0.1964 - mean_absolute_error: 0.1516 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1593 - val_mean_absolute_error: 0.1301\n",
      "Epoch 21/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0416 - root_mean_squared_error: 0.1961 - mean_absolute_error: 0.1533 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1605 - val_mean_absolute_error: 0.1322\n",
      "Epoch 22/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0409 - root_mean_squared_error: 0.1960 - mean_absolute_error: 0.1538 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1594 - val_mean_absolute_error: 0.1298\n",
      "Epoch 23/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0405 - root_mean_squared_error: 0.1961 - mean_absolute_error: 0.1514 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1595 - val_mean_absolute_error: 0.1301\n",
      "Epoch 24/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0403 - root_mean_squared_error: 0.1959 - mean_absolute_error: 0.1525 - val_loss: 0.0277 - val_root_mean_squared_error: 0.1608 - val_mean_absolute_error: 0.1327\n",
      "Epoch 25/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0401 - root_mean_squared_error: 0.1959 - mean_absolute_error: 0.1535 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1611 - val_mean_absolute_error: 0.1332\n",
      "Epoch 26/4000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 0.0401 - root_mean_squared_error: 0.1961 - mean_absolute_error: 0.1545 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1607 - val_mean_absolute_error: 0.1323\n",
      "Evaluate on test data\n",
      "18/18 [==============================] - 0s 724us/step - loss: 0.0278 - root_mean_squared_error: 0.1607 - mean_absolute_error: 0.1323\n",
      "test loss, test acc: [0.02776293456554413, 0.16068275272846222, 0.13229943811893463]\n",
      "Generate predictions for 42 samples\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "predictions shape: (42, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "\n",
    "X_feats3 = ['release_speed', 'release_spin_rate', 'spin_axis', 'pfx_v', 'pitch_type_CH', 'pitch_type_CS', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL']\n",
    "X_full = X_train[X_feats3]\n",
    "X_full_test = X_test[X_feats3]\n",
    "number_of_inputs = X_full.shape[1]  # number of features\n",
    "model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l1_l2(), bias_regularizer=regularizers.l1()),\n",
    "                          layers.Dense(16, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=32,\n",
    "    epochs=4000,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "WGQcArJAeqPN",
    "outputId": "65214ea7-8b91-4fe1-ef28-3d52ec4c0f6c"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyper sweep"
   ],
   "metadata": {
    "collapsed": false,
    "id": "GRJuMVxYeqPN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nz/57m0v30s0kqdtdm5876x20qw0000gn/T/ipykernel_13941/1658499985.py:15: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_and_compile_model, verbose=0)\n",
      "2022-11-30 22:15:49.027869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:49.027908: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:49.027949: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:49.027869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:49.058103: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:49.068325: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:49.081753: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:49.111187: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.846540: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.846916: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.848849: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.849407: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.849970: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.850946: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.850955: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-30 22:15:56.852227: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 9ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 5ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 4ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 989us/step\n",
      "6/6 [==============================] - 0s 676us/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 550us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_and_compile_model():\n",
    "    # create model\n",
    "    model = keras.Sequential([layers.Dense(16, activation='relu', input_dim=number_of_inputs),\n",
    "                              layers.Dense(16, activation='relu'),\n",
    "                              layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_and_compile_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "batch_size = [8, 16, 32, 64, 128]\n",
    "epochs = [10, 50, 250, 1250]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_full, y_train_trx)"
   ],
   "metadata": {
    "id": "Oa7tgTCKeqPN",
    "outputId": "71ed2d3c-6c54-439c-e5e7-dc8d9d300090"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.255660 using {'batch_size': 8, 'epochs': 10}\n",
      "train accuracy -0.255660 for: {'batch_size': 8, 'epochs': 10}\n",
      "train accuracy -0.255660 for: {'batch_size': 8, 'epochs': 50}\n",
      "train accuracy -0.255660 for: {'batch_size': 8, 'epochs': 250}\n",
      "train accuracy -0.255662 for: {'batch_size': 8, 'epochs': 1250}\n",
      "train accuracy -0.255660 for: {'batch_size': 16, 'epochs': 10}\n",
      "train accuracy -0.255660 for: {'batch_size': 16, 'epochs': 50}\n",
      "train accuracy -0.255660 for: {'batch_size': 16, 'epochs': 250}\n",
      "train accuracy -0.255661 for: {'batch_size': 16, 'epochs': 1250}\n",
      "train accuracy -0.255660 for: {'batch_size': 32, 'epochs': 10}\n",
      "train accuracy -0.255660 for: {'batch_size': 32, 'epochs': 50}\n",
      "train accuracy -0.255660 for: {'batch_size': 32, 'epochs': 250}\n",
      "train accuracy -0.255664 for: {'batch_size': 32, 'epochs': 1250}\n",
      "train accuracy -0.255680 for: {'batch_size': 64, 'epochs': 10}\n",
      "train accuracy -0.255660 for: {'batch_size': 64, 'epochs': 50}\n",
      "train accuracy -0.255660 for: {'batch_size': 64, 'epochs': 250}\n",
      "train accuracy -0.255661 for: {'batch_size': 64, 'epochs': 1250}\n",
      "train accuracy -0.256232 for: {'batch_size': 128, 'epochs': 10}\n",
      "train accuracy -0.255660 for: {'batch_size': 128, 'epochs': 50}\n",
      "train accuracy -0.255660 for: {'batch_size': 128, 'epochs': 250}\n",
      "train accuracy -0.255661 for: {'batch_size': 128, 'epochs': 1250}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"train accuracy %f for: %r\" % (mean, param))"
   ],
   "metadata": {
    "id": "N0MGbe69eqPO",
    "outputId": "c5ef14b0-4b59-4c8e-afe4-6c3c51d8dba7"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_42 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_33 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 513\n",
      "Trainable params: 513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 513\n",
      "Trainable params: 513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nz/57m0v30s0kqdtdm5876x20qw0000gn/T/ipykernel_13941/3761777028.py:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(build_fn=create_and_compile_model, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "--\n",
      "1/6 [====>.........................] - ETA: 0sNone\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "1/6 [====>.........................] - ETA: 0sNone\n",
      "--\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 513\n",
      "Trainable params: 513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265\n",
      "Trainable params: 265\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_49 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_40 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "None\n",
      "--\n",
      "1/6 [====>.........................] - ETA: 0sNone\n",
      "--\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 3ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_22 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337\n",
      "Trainable params: 337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337\n",
      "Trainable params: 337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_31 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 337\n",
      "Trainable params: 337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "1/6 [====>.........................] - ETA: 0sNone\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_19 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_54 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "1/6 [====>.........................] - ETA: 0sNone\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_44 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,057\n",
      "Trainable params: 1,057\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 4)                 56        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 141\n",
      "Trainable params: 141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_36 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409\n",
      "Trainable params: 409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_45 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409\n",
      "Trainable params: 409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 409\n",
      "Trainable params: 409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_49 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329\n",
      "Trainable params: 1,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "1/6 [====>.........................] - ETA: 0sNone\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_59 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329\n",
      "Trainable params: 1,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "1/6 [====>.........................] - ETA: 0sModel: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 16)                224       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 16)                272       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,329\n",
      "Trainable params: 1,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 1ms/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 811us/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 665us/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 654us/step\n",
      "None\n",
      "--\n",
      "6/6 [==============================] - 0s 564us/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_14 (Dense)            (None, 8)                 112       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 8)                 72        \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "def create_and_compile_model(num_neurons, num_layers):\n",
    "    # create model\n",
    "    model = keras.Sequential()\n",
    "    model.add(Dense(num_neurons, input_dim=number_of_inputs, activation='relu'))\n",
    "\n",
    "    if num_layers > 0:\n",
    "\n",
    "        while num_layers > 0:\n",
    "            model.add(Dense(num_neurons, activation='relu'))\n",
    "            num_layers=num_layers-1\n",
    "\n",
    "\n",
    "    model.add(Dense(1, activation='linear')) # output layer for regression\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='mse',\n",
    "                  metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    print(model.summary())\n",
    "    print('--')\n",
    "\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_and_compile_model, verbose=0)\n",
    "\n",
    "# define the grid search parameters\n",
    "num_neurons_grid = [4, 8, 16]\n",
    "num_layers_grid = [1, 2, 3, 4]\n",
    "\n",
    "param_grid = dict(num_neurons=num_neurons_grid, num_layers=num_layers_grid)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=3)\n",
    "\n",
    "grid_result = grid.fit(X_full, y_train_trx)"
   ],
   "metadata": {
    "id": "hNCHKDI2eqPO",
    "outputId": "86f1f710-d14d-484d-f061-9177a1a23a5c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.256242 using {'num_layers': 1, 'num_neurons': 8}\n",
      "train accuracy -0.256614 for: {'num_layers': 1, 'num_neurons': 4}\n",
      "train accuracy -0.256242 for: {'num_layers': 1, 'num_neurons': 8}\n",
      "train accuracy -0.256343 for: {'num_layers': 1, 'num_neurons': 16}\n",
      "train accuracy -0.256650 for: {'num_layers': 2, 'num_neurons': 4}\n",
      "train accuracy -0.256452 for: {'num_layers': 2, 'num_neurons': 8}\n",
      "train accuracy -0.256442 for: {'num_layers': 2, 'num_neurons': 16}\n",
      "train accuracy -0.256545 for: {'num_layers': 3, 'num_neurons': 4}\n",
      "train accuracy -0.256562 for: {'num_layers': 3, 'num_neurons': 8}\n",
      "train accuracy -0.256655 for: {'num_layers': 3, 'num_neurons': 16}\n",
      "train accuracy -0.256655 for: {'num_layers': 4, 'num_neurons': 4}\n",
      "train accuracy -0.256655 for: {'num_layers': 4, 'num_neurons': 8}\n",
      "train accuracy -0.256635 for: {'num_layers': 4, 'num_neurons': 16}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "for mean, param in zip(means, params):\n",
    "    print(\"train accuracy %f for: %r\" % (mean, param))"
   ],
   "metadata": {
    "id": "ivLCP-mKeqPO",
    "outputId": "3fcdebf0-1f38-4bbd-9f73-b663b1a8bef3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Combining Sweep\n",
    "layers = 4\n",
    "neurons = 8\n",
    "batch_size = 8\n",
    "epochs = 10"
   ],
   "metadata": {
    "collapsed": false,
    "id": "dcDdbQIGeqPO"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 1s 3ms/step - loss: 0.0481 - root_mean_squared_error: 0.2193 - mean_absolute_error: 0.1563 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705 - val_mean_absolute_error: 0.1286\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0402 - root_mean_squared_error: 0.2005 - mean_absolute_error: 0.1496 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698 - val_mean_absolute_error: 0.1364\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0388 - root_mean_squared_error: 0.1969 - mean_absolute_error: 0.1520 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1642 - val_mean_absolute_error: 0.1306\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0378 - root_mean_squared_error: 0.1945 - mean_absolute_error: 0.1493 - val_loss: 0.0264 - val_root_mean_squared_error: 0.1626 - val_mean_absolute_error: 0.1299\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - mean_absolute_error: 0.1497 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1657 - val_mean_absolute_error: 0.1370\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 2ms/step - loss: 0.0373 - root_mean_squared_error: 0.1931 - mean_absolute_error: 0.1509 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1619 - val_mean_absolute_error: 0.1286\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0370 - root_mean_squared_error: 0.1924 - mean_absolute_error: 0.1499 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1614 - val_mean_absolute_error: 0.1258\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0370 - root_mean_squared_error: 0.1922 - mean_absolute_error: 0.1486 - val_loss: 0.0266 - val_root_mean_squared_error: 0.1630 - val_mean_absolute_error: 0.1314\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0367 - root_mean_squared_error: 0.1915 - mean_absolute_error: 0.1511 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1617 - val_mean_absolute_error: 0.1271\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0365 - root_mean_squared_error: 0.1909 - mean_absolute_error: 0.1473 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1650 - val_mean_absolute_error: 0.1357\n",
      "Evaluate on test data\n",
      "18/18 [==============================] - 0s 762us/step - loss: 0.0272 - root_mean_squared_error: 0.1650 - mean_absolute_error: 0.1357\n",
      "test loss, test acc: [0.027222253382205963, 0.16499167680740356, 0.13567563891410828]\n",
      "Generate predictions for 42 samples\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "predictions shape: (42, 1)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([layers.Dense(8, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(8, activation='relu'),\n",
    "                          layers.Dense(8, activation='relu'),\n",
    "                          layers.Dense(8, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=8,\n",
    "    epochs=10,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "HA6M9GnZeqPO",
    "outputId": "e832cdea-8e1e-4ce8-cfa0-00f0291f4f5c"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "Epoch 1/10\n",
      "66/66 [==============================] - 1s 3ms/step - loss: 0.4158 - root_mean_squared_error: 0.2528 - mean_absolute_error: 0.1880 - val_loss: 0.3477 - val_root_mean_squared_error: 0.1769 - val_mean_absolute_error: 0.1329\n",
      "Epoch 2/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.3317 - root_mean_squared_error: 0.2138 - mean_absolute_error: 0.1596 - val_loss: 0.2834 - val_root_mean_squared_error: 0.1662 - val_mean_absolute_error: 0.1299\n",
      "Epoch 3/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.2727 - root_mean_squared_error: 0.2060 - mean_absolute_error: 0.1539 - val_loss: 0.2313 - val_root_mean_squared_error: 0.1612 - val_mean_absolute_error: 0.1259\n",
      "Epoch 4/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.2250 - root_mean_squared_error: 0.2018 - mean_absolute_error: 0.1516 - val_loss: 0.1899 - val_root_mean_squared_error: 0.1613 - val_mean_absolute_error: 0.1308\n",
      "Epoch 5/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1862 - root_mean_squared_error: 0.1987 - mean_absolute_error: 0.1536 - val_loss: 0.1551 - val_root_mean_squared_error: 0.1585 - val_mean_absolute_error: 0.1275\n",
      "Epoch 6/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1549 - root_mean_squared_error: 0.1967 - mean_absolute_error: 0.1528 - val_loss: 0.1273 - val_root_mean_squared_error: 0.1571 - val_mean_absolute_error: 0.1255\n",
      "Epoch 7/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1303 - root_mean_squared_error: 0.1966 - mean_absolute_error: 0.1519 - val_loss: 0.1057 - val_root_mean_squared_error: 0.1575 - val_mean_absolute_error: 0.1264\n",
      "Epoch 8/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.1106 - root_mean_squared_error: 0.1962 - mean_absolute_error: 0.1522 - val_loss: 0.0892 - val_root_mean_squared_error: 0.1597 - val_mean_absolute_error: 0.1316\n",
      "Epoch 9/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0951 - root_mean_squared_error: 0.1958 - mean_absolute_error: 0.1522 - val_loss: 0.0751 - val_root_mean_squared_error: 0.1582 - val_mean_absolute_error: 0.1280\n",
      "Epoch 10/10\n",
      "66/66 [==============================] - 0s 1ms/step - loss: 0.0829 - root_mean_squared_error: 0.1957 - mean_absolute_error: 0.1518 - val_loss: 0.0648 - val_root_mean_squared_error: 0.1593 - val_mean_absolute_error: 0.1304\n",
      "Evaluate on test data\n",
      "18/18 [==============================] - 0s 700us/step - loss: 0.0648 - root_mean_squared_error: 0.1593 - mean_absolute_error: 0.1304\n",
      "test loss, test acc: [0.0647798478603363, 0.15930888056755066, 0.13041053712368011]\n",
      "Generate predictions for 42 samples\n",
      "WARNING:tensorflow:5 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x1402fd990> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "predictions shape: (42, 1)\n"
     ]
    }
   ],
   "source": [
    "factor = 0.01\n",
    "model = keras.Sequential([layers.Dense(8, activation='relu', input_dim=number_of_inputs, kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(factor)),\n",
    "                          layers.Dense(1, activation='linear') ]) # output layer for regression\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "print(\"Fit model on training data\")\n",
    "history = model.fit(\n",
    "    X_full,\n",
    "    y_train_trx,\n",
    "    batch_size=8,\n",
    "    epochs=10,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(X_full_test, y_test_trx),\n",
    "    callbacks=[callback]\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_full_test, y_test_trx, batch_size=16)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 42 samples\")\n",
    "predictions = model.predict(X_full_test.iloc[:42,])\n",
    "print(\"predictions shape:\", predictions.shape)"
   ],
   "metadata": {
    "id": "noz0g6sLeqPP",
    "outputId": "56e08cae-c25b-46f7-87ab-d04ac3f36f8a"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TW NN"
   ],
   "metadata": {
    "id": "LK4GPXF6h81X"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of inputs = 30\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2111 - mse: 0.2111 - val_loss: 0.2518 - val_mse: 0.2518\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1883 - mse: 0.1883 - val_loss: 0.2368 - val_mse: 0.2368\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1745 - mse: 0.1745 - val_loss: 0.2259 - val_mse: 0.2259\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1660 - mse: 0.1660 - val_loss: 0.2204 - val_mse: 0.2204\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1604 - mse: 0.1604 - val_loss: 0.2157 - val_mse: 0.2157\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1562 - mse: 0.1562 - val_loss: 0.2114 - val_mse: 0.2114\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1527 - mse: 0.1527 - val_loss: 0.2081 - val_mse: 0.2081\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1504 - mse: 0.1504 - val_loss: 0.2055 - val_mse: 0.2055\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1483 - mse: 0.1483 - val_loss: 0.2032 - val_mse: 0.2032\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1464 - mse: 0.1464 - val_loss: 0.2014 - val_mse: 0.2014\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1446 - mse: 0.1446 - val_loss: 0.2002 - val_mse: 0.2002\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1433 - mse: 0.1433 - val_loss: 0.1995 - val_mse: 0.1995\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1421 - mse: 0.1421 - val_loss: 0.1984 - val_mse: 0.1984\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1409 - mse: 0.1409 - val_loss: 0.1973 - val_mse: 0.1973\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1401 - mse: 0.1401 - val_loss: 0.1967 - val_mse: 0.1967\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1392 - mse: 0.1392 - val_loss: 0.1948 - val_mse: 0.1948\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1380 - mse: 0.1380 - val_loss: 0.1940 - val_mse: 0.1940\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1372 - mse: 0.1372 - val_loss: 0.1930 - val_mse: 0.1930\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 0.1913 - val_mse: 0.1913\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 0.1888 - val_mse: 0.1888\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1353 - mse: 0.1353 - val_loss: 0.1879 - val_mse: 0.1879\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1343 - mse: 0.1343 - val_loss: 0.1875 - val_mse: 0.1875\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1336 - mse: 0.1336 - val_loss: 0.1869 - val_mse: 0.1869\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1328 - mse: 0.1328 - val_loss: 0.1865 - val_mse: 0.1865\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1324 - mse: 0.1324 - val_loss: 0.1865 - val_mse: 0.1865\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1317 - mse: 0.1317 - val_loss: 0.1857 - val_mse: 0.1857\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1310 - mse: 0.1310 - val_loss: 0.1859 - val_mse: 0.1859\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1306 - mse: 0.1306 - val_loss: 0.1856 - val_mse: 0.1856\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1301 - mse: 0.1301 - val_loss: 0.1854 - val_mse: 0.1854\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1296 - mse: 0.1296 - val_loss: 0.1847 - val_mse: 0.1847\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1294 - mse: 0.1294 - val_loss: 0.1838 - val_mse: 0.1838\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1289 - mse: 0.1289 - val_loss: 0.1835 - val_mse: 0.1835\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 0.1835 - val_mse: 0.1835\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1284 - mse: 0.1284 - val_loss: 0.1833 - val_mse: 0.1833\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1280 - mse: 0.1280 - val_loss: 0.1834 - val_mse: 0.1834\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1276 - mse: 0.1276 - val_loss: 0.1829 - val_mse: 0.1829\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1272 - mse: 0.1272 - val_loss: 0.1826 - val_mse: 0.1826\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1267 - mse: 0.1267 - val_loss: 0.1814 - val_mse: 0.1814\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1264 - mse: 0.1264 - val_loss: 0.1816 - val_mse: 0.1816\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 0.1826 - val_mse: 0.1826\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 0.1826 - val_mse: 0.1826\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 0.1825 - val_mse: 0.1825\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1257 - mse: 0.1257 - val_loss: 0.1826 - val_mse: 0.1826\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1255 - mse: 0.1255 - val_loss: 0.1826 - val_mse: 0.1826\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1251 - mse: 0.1251 - val_loss: 0.1824 - val_mse: 0.1824\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1249 - mse: 0.1249 - val_loss: 0.1815 - val_mse: 0.1815\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1247 - mse: 0.1247 - val_loss: 0.1813 - val_mse: 0.1813\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1244 - mse: 0.1244 - val_loss: 0.1815 - val_mse: 0.1815\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 0.1801 - val_mse: 0.1801\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1237 - mse: 0.1237 - val_loss: 0.1798 - val_mse: 0.1798\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1236 - mse: 0.1236 - val_loss: 0.1797 - val_mse: 0.1797\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1233 - mse: 0.1233 - val_loss: 0.1795 - val_mse: 0.1795\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1230 - mse: 0.1230 - val_loss: 0.1787 - val_mse: 0.1787\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1230 - mse: 0.1230 - val_loss: 0.1781 - val_mse: 0.1781\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 0.1784 - val_mse: 0.1784\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 0.1777 - val_mse: 0.1777\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1220 - mse: 0.1220 - val_loss: 0.1781 - val_mse: 0.1781\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1219 - mse: 0.1219 - val_loss: 0.1787 - val_mse: 0.1787\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1219 - mse: 0.1219 - val_loss: 0.1786 - val_mse: 0.1786\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1214 - mse: 0.1214 - val_loss: 0.1791 - val_mse: 0.1791\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1213 - mse: 0.1213 - val_loss: 0.1797 - val_mse: 0.1797\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1209 - mse: 0.1209 - val_loss: 0.1798 - val_mse: 0.1798\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1210 - mse: 0.1210 - val_loss: 0.1797 - val_mse: 0.1797\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 0.1799 - val_mse: 0.1799\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 0.1800 - val_mse: 0.1800\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 0.1795 - val_mse: 0.1795\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 0.1784 - val_mse: 0.1784\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1203 - mse: 0.1203 - val_loss: 0.1787 - val_mse: 0.1787\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1201 - mse: 0.1201 - val_loss: 0.1792 - val_mse: 0.1792\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 0.1795 - val_mse: 0.1795\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 0.1794 - val_mse: 0.1794\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1196 - mse: 0.1196 - val_loss: 0.1784 - val_mse: 0.1784\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 0.1800 - val_mse: 0.1800\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1199 - mse: 0.1199 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 0.1807 - val_mse: 0.1807\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 0.1798 - val_mse: 0.1798\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1191 - mse: 0.1191 - val_loss: 0.1794 - val_mse: 0.1794\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1188 - mse: 0.1188 - val_loss: 0.1789 - val_mse: 0.1789\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1187 - mse: 0.1187 - val_loss: 0.1782 - val_mse: 0.1782\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1186 - mse: 0.1186 - val_loss: 0.1786 - val_mse: 0.1786\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1187 - mse: 0.1187 - val_loss: 0.1794 - val_mse: 0.1794\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1186 - mse: 0.1186 - val_loss: 0.1789 - val_mse: 0.1789\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1186 - mse: 0.1186 - val_loss: 0.1777 - val_mse: 0.1777\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1185 - mse: 0.1185 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1185 - mse: 0.1185 - val_loss: 0.1762 - val_mse: 0.1762\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1184 - mse: 0.1184 - val_loss: 0.1757 - val_mse: 0.1757\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1181 - mse: 0.1181 - val_loss: 0.1768 - val_mse: 0.1768\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1180 - mse: 0.1180 - val_loss: 0.1776 - val_mse: 0.1776\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1179 - mse: 0.1179 - val_loss: 0.1779 - val_mse: 0.1779\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1176 - mse: 0.1176 - val_loss: 0.1776 - val_mse: 0.1776\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1175 - mse: 0.1175 - val_loss: 0.1779 - val_mse: 0.1779\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 0.1777 - val_mse: 0.1777\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 0.1779 - val_mse: 0.1779\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1172 - mse: 0.1172 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1170 - mse: 0.1170 - val_loss: 0.1772 - val_mse: 0.1772\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1170 - mse: 0.1170 - val_loss: 0.1777 - val_mse: 0.1777\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 0.1785 - val_mse: 0.1785\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 0.1789 - val_mse: 0.1789\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1167 - mse: 0.1167 - val_loss: 0.1806 - val_mse: 0.1806\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 0.1810 - val_mse: 0.1810\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 665us/step\n",
      "MAE Train = 0.2698456532573381\n",
      "MSE Train = 0.1295224435742626\n",
      "R2  = 0.11531091810087546\n",
      "\n",
      "9/9 [==============================] - 0s 809us/step\n",
      "MAE Test = 0.2504495985960284\n",
      "MSE Test = 0.33248349857739545\n",
      "R2  = -0.1647074293569255\n"
     ]
    }
   ],
   "source": [
    "# Define the loss plot\n",
    "def plot_loss(history, num_neurons):\n",
    "  plt.plot(history.history['mse'], label='mse')\n",
    "  plt.plot(history.history['val_mse'], label='val_mse')\n",
    "  # plt.ylim([0, y_lim])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('mse')\n",
    "  plt.legend()\n",
    "  plt.title(f\"{num_neurons} neurons\")\n",
    "\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "  \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from   tensorflow import keras\n",
    "from   tensorflow.keras import layers, regularizers\n",
    "from   tensorflow.keras.layers.experimental import preprocessing\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from   tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#setup normalizer\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(X_train))\n",
    "\n",
    "number_of_inputs= X_train.shape[1]\n",
    "print(f\"# of inputs = {number_of_inputs}\")\n",
    "\n",
    "num_neurons = 3\n",
    "\n",
    "# create model\n",
    "model = keras.Sequential([normalizer,\n",
    "                          layers.Dense(num_neurons, activation='relu', input_dim=number_of_inputs),\n",
    "                          layers.Dense(num_neurons, activation='relu'),\n",
    "                          layers.Dense(1, activation='linear') ])  \n",
    "  \n",
    "model.compile(loss='mse',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              metrics='mse')\n",
    "\n",
    "history = model.fit(X_train, \n",
    "                    y_train, \n",
    "                    batch_size=32,\n",
    "                    epochs=100,\n",
    "                    validation_split = 0.2)  # Calculate validation results on 20% of the training data\n",
    "                  \n",
    "# Isolate and plot training curves \n",
    "hist = pd.DataFrame(history.history)\n",
    "plot_loss(history, num_neurons)\n",
    "\n",
    "# calculate metrics ---------------\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# train\n",
    "y_pred = model.predict(X_train)\n",
    "print(f\"MAE Train = {mean_absolute_error(y_train, y_pred)}\")\n",
    "print(f\"MSE Train = { mean_squared_error(y_train, y_pred)}\")\n",
    "print(f\"R2  = {                 r2_score(y_train, y_pred)}\")\n",
    "print(f\"\")\n",
    "\n",
    "# holdout\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"MAE Test = {mean_absolute_error(y_test, y_pred)}\")\n",
    "print(f\"MSE Test = { mean_squared_error(y_test, y_pred, squared=False)}\")\n",
    "print(f\"R2  = {                r2_score(y_test, y_pred)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7W-1w75ceqPP",
    "outputId": "895b9f00-63a2-47ea-f495-9a999799e9b7"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TW NN neurons sweep"
   ],
   "metadata": {
    "id": "0c2FEQCjiZIj"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the loss plot\n",
    "def plot_loss(history):\n",
    "  plt.plot(history.history['mse'], label='mse')\n",
    "  plt.plot(history.history['val_mse'], label='val_mse')\n",
    "  # plt.ylim([0, y_lim])\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('mse')\n",
    "  plt.legend()\n",
    "  plt.title(f\"{num_neurons} neurons\")\n",
    "\n",
    "  plt.grid(True)\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "#setup normalizer\n",
    "normalizer = preprocessing.Normalization()\n",
    "normalizer.adapt(np.array(X_train))\n",
    "\n",
    "number_of_inputs = X_train.shape[1]\n",
    "\n",
    "# sweep neurons\n",
    "mse_list = []\n",
    "val_mse_list = []\n",
    "\n",
    "neurons_to_try = [1, 2, 3, 5, 7, 10, 15]\n",
    "\n",
    "for num_neurons in neurons_to_try:\n",
    "\n",
    "  #---- pasted in model\n",
    "  model = keras.Sequential([normalizer,\n",
    "                            layers.Dense(num_neurons, activation = 'relu', input_dim = number_of_inputs),\n",
    "                            layers.Dense(num_neurons, activation = 'relu'),\n",
    "                            layers.Dense(1, activation = 'linear') ])\n",
    "    \n",
    "  model.compile(loss='mse',\n",
    "                optimizer = tf.keras.optimizers.Adam(0.001),\n",
    "                metrics = 'mse')\n",
    "\n",
    "  history = model.fit(X_train, y_train, \n",
    "                      epochs = 100,\n",
    "                      batch_size = 32,\n",
    "                      validation_split = 0.2)  # Calculate validation results on 20% of the training data\n",
    "                    \n",
    "  # Isolate the metric for each epoch.\n",
    "  hist = pd.DataFrame(history.history)\n",
    "\n",
    "  #---- end model paste\n",
    "\n",
    "  # record metrics\n",
    "\n",
    "  current_mse = hist['mse']\n",
    "  current_mse = current_mse[len(current_mse)-1]  # last element is the final value\n",
    "  mse_list.append(current_mse)  \n",
    "\n",
    "  current_val_mse = hist['val_mse']\n",
    "  current_val_mse = current_val_mse[len(current_val_mse)-1] #  last element is the final value\n",
    "  val_mse_list.append(current_val_mse)\n",
    "\n",
    "  plot_loss(history)\n",
    "\n",
    "  # calculate metrics ---------------\n",
    "  from sklearn.metrics import mean_absolute_error\n",
    "  from sklearn.metrics import mean_squared_error\n",
    "  from sklearn.metrics import r2_score\n",
    "\n",
    "  # train\n",
    "  y_pred = model.predict(X_train)\n",
    "  print(f\"MAE Train = {mean_absolute_error(y_train, y_pred)}\")\n",
    "  print(f\"MSE Train = { mean_squared_error(y_train, y_pred)}\")\n",
    "  print(f\"R2  = {                 r2_score(y_train, y_pred)}\")\n",
    "  print(f\"\")\n",
    "\n",
    "  # holdout\n",
    "  y_pred = model.predict(X_test)\n",
    "  print(f\"MAE Test = {mean_absolute_error(y_test, y_pred)}\")\n",
    "  print(f\"MSE Test = { mean_squared_error(y_test, y_pred)}\")\n",
    "  print(f\"R2  = {                r2_score(y_test, y_pred)}\")\n",
    "\n",
    "#plot results of sweep\n",
    "plt.plot(neurons_to_try, mse_list, label='MSE')\n",
    "plt.plot(neurons_to_try, val_mse_list, label='Validation MSE')\n",
    "\n",
    "# plt.ylim([1,y_lim])\n",
    "plt.xlabel('Neurons')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "VrbOdqLPia1K",
    "outputId": "9fb216d3-60ad-4ff1-e215-ac8ec1bb0623"
   },
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 12ms/step - loss: 0.2348 - mse: 0.2348 - val_loss: 0.2977 - val_mse: 0.2977\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2266 - mse: 0.2266 - val_loss: 0.2881 - val_mse: 0.2881\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2193 - mse: 0.2193 - val_loss: 0.2793 - val_mse: 0.2793\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2123 - mse: 0.2123 - val_loss: 0.2710 - val_mse: 0.2710\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2060 - mse: 0.2060 - val_loss: 0.2634 - val_mse: 0.2634\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2002 - mse: 0.2002 - val_loss: 0.2561 - val_mse: 0.2561\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1947 - mse: 0.1947 - val_loss: 0.2490 - val_mse: 0.2490\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1896 - mse: 0.1896 - val_loss: 0.2428 - val_mse: 0.2428\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1850 - mse: 0.1850 - val_loss: 0.2370 - val_mse: 0.2370\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1807 - mse: 0.1807 - val_loss: 0.2313 - val_mse: 0.2313\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1768 - mse: 0.1768 - val_loss: 0.2261 - val_mse: 0.2261\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1731 - mse: 0.1731 - val_loss: 0.2214 - val_mse: 0.2214\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1697 - mse: 0.1697 - val_loss: 0.2161 - val_mse: 0.2161\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1663 - mse: 0.1663 - val_loss: 0.2122 - val_mse: 0.2122\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1637 - mse: 0.1637 - val_loss: 0.2083 - val_mse: 0.2083\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1611 - mse: 0.1611 - val_loss: 0.2043 - val_mse: 0.2043\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1588 - mse: 0.1588 - val_loss: 0.2011 - val_mse: 0.2011\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1568 - mse: 0.1568 - val_loss: 0.1985 - val_mse: 0.1985\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1552 - mse: 0.1552 - val_loss: 0.1957 - val_mse: 0.1957\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1530 - mse: 0.1530 - val_loss: 0.1922 - val_mse: 0.1922\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1514 - mse: 0.1514 - val_loss: 0.1897 - val_mse: 0.1897\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1501 - mse: 0.1501 - val_loss: 0.1878 - val_mse: 0.1878\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1490 - mse: 0.1490 - val_loss: 0.1859 - val_mse: 0.1859\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1479 - mse: 0.1479 - val_loss: 0.1840 - val_mse: 0.1840\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1470 - mse: 0.1470 - val_loss: 0.1823 - val_mse: 0.1823\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1461 - mse: 0.1461 - val_loss: 0.1805 - val_mse: 0.1805\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 0.1790 - val_mse: 0.1790\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1447 - mse: 0.1447 - val_loss: 0.1779 - val_mse: 0.1779\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.1768 - val_mse: 0.1768\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1438 - mse: 0.1438 - val_loss: 0.1761 - val_mse: 0.1761\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1436 - mse: 0.1436 - val_loss: 0.1754 - val_mse: 0.1754\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1434 - mse: 0.1434 - val_loss: 0.1748 - val_mse: 0.1748\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1431 - mse: 0.1431 - val_loss: 0.1744 - val_mse: 0.1744\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1430 - mse: 0.1430 - val_loss: 0.1741 - val_mse: 0.1741\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1429 - mse: 0.1429 - val_loss: 0.1736 - val_mse: 0.1736\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1427 - mse: 0.1427 - val_loss: 0.1728 - val_mse: 0.1728\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1425 - mse: 0.1425 - val_loss: 0.1723 - val_mse: 0.1723\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1423 - mse: 0.1423 - val_loss: 0.1719 - val_mse: 0.1719\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1422 - mse: 0.1422 - val_loss: 0.1716 - val_mse: 0.1716\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1421 - mse: 0.1421 - val_loss: 0.1712 - val_mse: 0.1712\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1420 - mse: 0.1420 - val_loss: 0.1709 - val_mse: 0.1709\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1420 - mse: 0.1420 - val_loss: 0.1704 - val_mse: 0.1704\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1418 - mse: 0.1418 - val_loss: 0.1703 - val_mse: 0.1703\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1418 - mse: 0.1418 - val_loss: 0.1700 - val_mse: 0.1700\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1417 - mse: 0.1417 - val_loss: 0.1697 - val_mse: 0.1697\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1417 - mse: 0.1417 - val_loss: 0.1696 - val_mse: 0.1696\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1417 - mse: 0.1417 - val_loss: 0.1693 - val_mse: 0.1693\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1416 - mse: 0.1416 - val_loss: 0.1692 - val_mse: 0.1692\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1416 - mse: 0.1416 - val_loss: 0.1687 - val_mse: 0.1687\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1685 - val_mse: 0.1685\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1683 - val_mse: 0.1683\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1683 - val_mse: 0.1683\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1682 - val_mse: 0.1682\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1681 - val_mse: 0.1681\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1682 - val_mse: 0.1682\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1684 - val_mse: 0.1684\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1684 - val_mse: 0.1684\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1684 - val_mse: 0.1684\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1682 - val_mse: 0.1682\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1679 - val_mse: 0.1679\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1678 - val_mse: 0.1678\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1679 - val_mse: 0.1679\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1677 - val_mse: 0.1677\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1676 - val_mse: 0.1676\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1679 - val_mse: 0.1679\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1680 - val_mse: 0.1680\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1678 - val_mse: 0.1678\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1679 - val_mse: 0.1679\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1679 - val_mse: 0.1679\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1678 - val_mse: 0.1678\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1675 - val_mse: 0.1675\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1676 - val_mse: 0.1676\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1675 - val_mse: 0.1675\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1672 - val_mse: 0.1672\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1414 - mse: 0.1414 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1670 - val_mse: 0.1670\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1414 - mse: 0.1414 - val_loss: 0.1669 - val_mse: 0.1669\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1669 - val_mse: 0.1669\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1668 - val_mse: 0.1668\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1665 - val_mse: 0.1665\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1667 - val_mse: 0.1667\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1668 - val_mse: 0.1668\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1670 - val_mse: 0.1670\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1414 - mse: 0.1414 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1414 - mse: 0.1414 - val_loss: 0.1673 - val_mse: 0.1673\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1674 - val_mse: 0.1674\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1676 - val_mse: 0.1676\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1674 - val_mse: 0.1674\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1674 - val_mse: 0.1674\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1669 - val_mse: 0.1669\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1668 - val_mse: 0.1668\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1671 - val_mse: 0.1671\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1673 - val_mse: 0.1673\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1676 - val_mse: 0.1676\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1677 - val_mse: 0.1677\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1678 - val_mse: 0.1678\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 622us/step\n",
      "MAE Train = 0.2942068004977407\n",
      "MSE Train = 0.14675173417552606\n",
      "R2  = -0.002371893180132867\n",
      "\n",
      "9/9 [==============================] - 0s 794us/step\n",
      "MAE Test = 0.24998706956619912\n",
      "MSE Test = 0.09633128909467584\n",
      "R2  = -0.014948546959911102\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 11ms/step - loss: 2.0036 - mse: 2.0036 - val_loss: 2.4262 - val_mse: 2.4262\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.7275 - mse: 1.7275 - val_loss: 2.1130 - val_mse: 2.1130\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.4979 - mse: 1.4979 - val_loss: 1.8447 - val_mse: 1.8447\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.3038 - mse: 1.3038 - val_loss: 1.6320 - val_mse: 1.6320\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.1559 - mse: 1.1559 - val_loss: 1.4442 - val_mse: 1.4442\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.0167 - mse: 1.0167 - val_loss: 1.2934 - val_mse: 1.2934\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.9066 - mse: 0.9066 - val_loss: 1.1601 - val_mse: 1.1601\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8126 - mse: 0.8126 - val_loss: 1.0425 - val_mse: 1.0425\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7288 - mse: 0.7288 - val_loss: 0.9437 - val_mse: 0.9437\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6555 - mse: 0.6555 - val_loss: 0.8512 - val_mse: 0.8512\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5909 - mse: 0.5909 - val_loss: 0.7766 - val_mse: 0.7766\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.5342 - mse: 0.5342 - val_loss: 0.7034 - val_mse: 0.7034\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4865 - mse: 0.4865 - val_loss: 0.6442 - val_mse: 0.6442\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4462 - mse: 0.4462 - val_loss: 0.5944 - val_mse: 0.5944\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4107 - mse: 0.4107 - val_loss: 0.5511 - val_mse: 0.5511\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3823 - mse: 0.3823 - val_loss: 0.5150 - val_mse: 0.5150\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3582 - mse: 0.3582 - val_loss: 0.4805 - val_mse: 0.4805\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3358 - mse: 0.3358 - val_loss: 0.4511 - val_mse: 0.4511\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3165 - mse: 0.3165 - val_loss: 0.4235 - val_mse: 0.4235\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2983 - mse: 0.2983 - val_loss: 0.3995 - val_mse: 0.3995\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2830 - mse: 0.2830 - val_loss: 0.3791 - val_mse: 0.3791\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2693 - mse: 0.2693 - val_loss: 0.3589 - val_mse: 0.3589\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2558 - mse: 0.2558 - val_loss: 0.3378 - val_mse: 0.3378\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2441 - mse: 0.2441 - val_loss: 0.3219 - val_mse: 0.3219\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2341 - mse: 0.2341 - val_loss: 0.3076 - val_mse: 0.3076\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2253 - mse: 0.2253 - val_loss: 0.2949 - val_mse: 0.2949\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2173 - mse: 0.2173 - val_loss: 0.2841 - val_mse: 0.2841\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2100 - mse: 0.2100 - val_loss: 0.2738 - val_mse: 0.2738\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2034 - mse: 0.2034 - val_loss: 0.2645 - val_mse: 0.2645\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1977 - mse: 0.1977 - val_loss: 0.2564 - val_mse: 0.2564\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1926 - mse: 0.1926 - val_loss: 0.2486 - val_mse: 0.2486\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1877 - mse: 0.1877 - val_loss: 0.2418 - val_mse: 0.2418\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1834 - mse: 0.1834 - val_loss: 0.2347 - val_mse: 0.2347\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1792 - mse: 0.1792 - val_loss: 0.2289 - val_mse: 0.2289\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1757 - mse: 0.1757 - val_loss: 0.2237 - val_mse: 0.2237\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1724 - mse: 0.1724 - val_loss: 0.2191 - val_mse: 0.2191\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1698 - mse: 0.1698 - val_loss: 0.2147 - val_mse: 0.2147\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1670 - mse: 0.1670 - val_loss: 0.2109 - val_mse: 0.2109\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1643 - mse: 0.1643 - val_loss: 0.2071 - val_mse: 0.2071\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1620 - mse: 0.1620 - val_loss: 0.2033 - val_mse: 0.2033\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1599 - mse: 0.1599 - val_loss: 0.2002 - val_mse: 0.2002\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1580 - mse: 0.1580 - val_loss: 0.1971 - val_mse: 0.1971\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1560 - mse: 0.1560 - val_loss: 0.1941 - val_mse: 0.1941\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1543 - mse: 0.1543 - val_loss: 0.1916 - val_mse: 0.1916\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1527 - mse: 0.1527 - val_loss: 0.1896 - val_mse: 0.1896\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1515 - mse: 0.1515 - val_loss: 0.1872 - val_mse: 0.1872\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1502 - mse: 0.1502 - val_loss: 0.1853 - val_mse: 0.1853\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1492 - mse: 0.1492 - val_loss: 0.1834 - val_mse: 0.1834\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1480 - mse: 0.1480 - val_loss: 0.1820 - val_mse: 0.1820\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1471 - mse: 0.1471 - val_loss: 0.1807 - val_mse: 0.1807\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1463 - mse: 0.1463 - val_loss: 0.1792 - val_mse: 0.1792\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1455 - mse: 0.1455 - val_loss: 0.1781 - val_mse: 0.1781\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1448 - mse: 0.1448 - val_loss: 0.1770 - val_mse: 0.1770\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.1759 - val_mse: 0.1759\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1435 - mse: 0.1435 - val_loss: 0.1749 - val_mse: 0.1749\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1429 - mse: 0.1429 - val_loss: 0.1741 - val_mse: 0.1741\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1424 - mse: 0.1424 - val_loss: 0.1733 - val_mse: 0.1733\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1419 - mse: 0.1419 - val_loss: 0.1726 - val_mse: 0.1726\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1720 - val_mse: 0.1720\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1410 - mse: 0.1410 - val_loss: 0.1713 - val_mse: 0.1713\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1406 - mse: 0.1406 - val_loss: 0.1708 - val_mse: 0.1708\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1404 - mse: 0.1404 - val_loss: 0.1702 - val_mse: 0.1702\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 0.1693 - val_mse: 0.1693\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1396 - mse: 0.1396 - val_loss: 0.1688 - val_mse: 0.1688\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1393 - mse: 0.1393 - val_loss: 0.1685 - val_mse: 0.1685\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1391 - mse: 0.1391 - val_loss: 0.1683 - val_mse: 0.1683\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1389 - mse: 0.1389 - val_loss: 0.1678 - val_mse: 0.1678\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1386 - mse: 0.1386 - val_loss: 0.1672 - val_mse: 0.1672\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1384 - mse: 0.1384 - val_loss: 0.1667 - val_mse: 0.1667\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1382 - mse: 0.1382 - val_loss: 0.1659 - val_mse: 0.1659\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1380 - mse: 0.1380 - val_loss: 0.1654 - val_mse: 0.1654\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.1652 - val_mse: 0.1652\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1377 - mse: 0.1377 - val_loss: 0.1652 - val_mse: 0.1652\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1375 - mse: 0.1375 - val_loss: 0.1652 - val_mse: 0.1652\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1374 - mse: 0.1374 - val_loss: 0.1650 - val_mse: 0.1650\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1372 - mse: 0.1372 - val_loss: 0.1646 - val_mse: 0.1646\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1371 - mse: 0.1371 - val_loss: 0.1645 - val_mse: 0.1645\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1369 - mse: 0.1369 - val_loss: 0.1644 - val_mse: 0.1644\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1368 - mse: 0.1368 - val_loss: 0.1645 - val_mse: 0.1645\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1367 - mse: 0.1367 - val_loss: 0.1642 - val_mse: 0.1642\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 0.1638 - val_mse: 0.1638\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 0.1640 - val_mse: 0.1640\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1363 - mse: 0.1363 - val_loss: 0.1639 - val_mse: 0.1639\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1362 - mse: 0.1362 - val_loss: 0.1639 - val_mse: 0.1639\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 0.1637 - val_mse: 0.1637\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1360 - mse: 0.1360 - val_loss: 0.1637 - val_mse: 0.1637\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 0.1635 - val_mse: 0.1635\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 0.1632 - val_mse: 0.1632\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1357 - mse: 0.1357 - val_loss: 0.1625 - val_mse: 0.1625\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1356 - mse: 0.1356 - val_loss: 0.1624 - val_mse: 0.1624\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1355 - mse: 0.1355 - val_loss: 0.1624 - val_mse: 0.1624\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1354 - mse: 0.1354 - val_loss: 0.1624 - val_mse: 0.1624\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1353 - mse: 0.1353 - val_loss: 0.1626 - val_mse: 0.1626\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1352 - mse: 0.1352 - val_loss: 0.1627 - val_mse: 0.1627\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1352 - mse: 0.1352 - val_loss: 0.1625 - val_mse: 0.1625\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1351 - mse: 0.1351 - val_loss: 0.1625 - val_mse: 0.1625\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.1350 - val_loss: 0.1625 - val_mse: 0.1625\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1349 - mse: 0.1349 - val_loss: 0.1624 - val_mse: 0.1624\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1348 - mse: 0.1348 - val_loss: 0.1620 - val_mse: 0.1620\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1348 - mse: 0.1348 - val_loss: 0.1619 - val_mse: 0.1619\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 667us/step\n",
      "MAE Train = 0.28305671732603477\n",
      "MSE Train = 0.14013081991518334\n",
      "R2  = 0.0428515476126361\n",
      "\n",
      "9/9 [==============================] - 0s 731us/step\n",
      "MAE Test = 8127.267294526639\n",
      "MSE Test = 18625613013.12673\n",
      "R2  = -196239861850.44284\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 10ms/step - loss: 0.4519 - mse: 0.4519 - val_loss: 0.2753 - val_mse: 0.2753\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3939 - mse: 0.3939 - val_loss: 0.2663 - val_mse: 0.2663\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3513 - mse: 0.3513 - val_loss: 0.2614 - val_mse: 0.2614\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3168 - mse: 0.3168 - val_loss: 0.2585 - val_mse: 0.2585\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2927 - mse: 0.2927 - val_loss: 0.2551 - val_mse: 0.2551\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2754 - mse: 0.2754 - val_loss: 0.2480 - val_mse: 0.2480\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2618 - mse: 0.2618 - val_loss: 0.2431 - val_mse: 0.2431\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2501 - mse: 0.2501 - val_loss: 0.2381 - val_mse: 0.2381\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2398 - mse: 0.2398 - val_loss: 0.2333 - val_mse: 0.2333\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2296 - mse: 0.2296 - val_loss: 0.2292 - val_mse: 0.2292\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2212 - mse: 0.2212 - val_loss: 0.2249 - val_mse: 0.2249\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2140 - mse: 0.2140 - val_loss: 0.2216 - val_mse: 0.2216\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2073 - mse: 0.2073 - val_loss: 0.2178 - val_mse: 0.2178\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2012 - mse: 0.2012 - val_loss: 0.2133 - val_mse: 0.2133\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1952 - mse: 0.1952 - val_loss: 0.2110 - val_mse: 0.2110\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1896 - mse: 0.1896 - val_loss: 0.2094 - val_mse: 0.2094\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1845 - mse: 0.1845 - val_loss: 0.2058 - val_mse: 0.2058\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1801 - mse: 0.1801 - val_loss: 0.2020 - val_mse: 0.2020\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1759 - mse: 0.1759 - val_loss: 0.1996 - val_mse: 0.1996\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1725 - mse: 0.1725 - val_loss: 0.1965 - val_mse: 0.1965\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1691 - mse: 0.1691 - val_loss: 0.1947 - val_mse: 0.1947\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1662 - mse: 0.1662 - val_loss: 0.1935 - val_mse: 0.1935\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1636 - mse: 0.1636 - val_loss: 0.1912 - val_mse: 0.1912\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1613 - mse: 0.1613 - val_loss: 0.1895 - val_mse: 0.1895\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1592 - mse: 0.1592 - val_loss: 0.1888 - val_mse: 0.1888\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1569 - mse: 0.1569 - val_loss: 0.1887 - val_mse: 0.1887\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1550 - mse: 0.1550 - val_loss: 0.1870 - val_mse: 0.1870\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1532 - mse: 0.1532 - val_loss: 0.1861 - val_mse: 0.1861\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1516 - mse: 0.1516 - val_loss: 0.1853 - val_mse: 0.1853\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1503 - mse: 0.1503 - val_loss: 0.1863 - val_mse: 0.1863\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1489 - mse: 0.1489 - val_loss: 0.1852 - val_mse: 0.1852\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1476 - mse: 0.1476 - val_loss: 0.1839 - val_mse: 0.1839\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1464 - mse: 0.1464 - val_loss: 0.1828 - val_mse: 0.1828\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1454 - mse: 0.1454 - val_loss: 0.1824 - val_mse: 0.1824\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1444 - mse: 0.1444 - val_loss: 0.1829 - val_mse: 0.1829\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1432 - mse: 0.1432 - val_loss: 0.1831 - val_mse: 0.1831\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1425 - mse: 0.1425 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1417 - mse: 0.1417 - val_loss: 0.1807 - val_mse: 0.1807\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1410 - mse: 0.1410 - val_loss: 0.1805 - val_mse: 0.1805\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1405 - mse: 0.1405 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1392 - mse: 0.1392 - val_loss: 0.1810 - val_mse: 0.1810\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1389 - mse: 0.1389 - val_loss: 0.1815 - val_mse: 0.1815\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1382 - mse: 0.1382 - val_loss: 0.1818 - val_mse: 0.1818\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1377 - mse: 0.1377 - val_loss: 0.1812 - val_mse: 0.1812\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1371 - mse: 0.1371 - val_loss: 0.1804 - val_mse: 0.1804\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 0.1800 - val_mse: 0.1800\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 0.1795 - val_mse: 0.1795\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1357 - mse: 0.1357 - val_loss: 0.1797 - val_mse: 0.1797\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1353 - mse: 0.1353 - val_loss: 0.1791 - val_mse: 0.1791\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1347 - mse: 0.1347 - val_loss: 0.1788 - val_mse: 0.1788\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1343 - mse: 0.1343 - val_loss: 0.1778 - val_mse: 0.1778\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1339 - mse: 0.1339 - val_loss: 0.1769 - val_mse: 0.1769\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1336 - mse: 0.1336 - val_loss: 0.1769 - val_mse: 0.1769\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 0.1776 - val_mse: 0.1776\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 0.1772 - val_mse: 0.1772\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1330 - mse: 0.1330 - val_loss: 0.1763 - val_mse: 0.1763\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1326 - mse: 0.1326 - val_loss: 0.1759 - val_mse: 0.1759\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1322 - mse: 0.1322 - val_loss: 0.1759 - val_mse: 0.1759\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1320 - mse: 0.1320 - val_loss: 0.1758 - val_mse: 0.1758\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1318 - mse: 0.1318 - val_loss: 0.1761 - val_mse: 0.1761\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1315 - mse: 0.1315 - val_loss: 0.1758 - val_mse: 0.1758\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1315 - mse: 0.1315 - val_loss: 0.1756 - val_mse: 0.1756\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1311 - mse: 0.1311 - val_loss: 0.1757 - val_mse: 0.1757\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1308 - mse: 0.1308 - val_loss: 0.1764 - val_mse: 0.1764\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1306 - mse: 0.1306 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305 - val_loss: 0.1767 - val_mse: 0.1767\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1303 - mse: 0.1303 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1301 - mse: 0.1301 - val_loss: 0.1764 - val_mse: 0.1764\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1299 - mse: 0.1299 - val_loss: 0.1766 - val_mse: 0.1766\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1297 - mse: 0.1297 - val_loss: 0.1763 - val_mse: 0.1763\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1295 - mse: 0.1295 - val_loss: 0.1759 - val_mse: 0.1759\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1296 - mse: 0.1296 - val_loss: 0.1741 - val_mse: 0.1741\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1294 - mse: 0.1294 - val_loss: 0.1744 - val_mse: 0.1744\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.1290 - val_loss: 0.1748 - val_mse: 0.1748\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1289 - mse: 0.1289 - val_loss: 0.1750 - val_mse: 0.1750\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1286 - mse: 0.1286 - val_loss: 0.1757 - val_mse: 0.1757\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1283 - mse: 0.1283 - val_loss: 0.1760 - val_mse: 0.1760\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1282 - mse: 0.1282 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1280 - mse: 0.1280 - val_loss: 0.1768 - val_mse: 0.1768\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1278 - mse: 0.1278 - val_loss: 0.1769 - val_mse: 0.1769\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1277 - mse: 0.1277 - val_loss: 0.1773 - val_mse: 0.1773\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1274 - mse: 0.1274 - val_loss: 0.1760 - val_mse: 0.1760\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 0.1750 - val_mse: 0.1750\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1275 - mse: 0.1275 - val_loss: 0.1752 - val_mse: 0.1752\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1274 - mse: 0.1274 - val_loss: 0.1755 - val_mse: 0.1755\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1271 - mse: 0.1271 - val_loss: 0.1754 - val_mse: 0.1754\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1270 - mse: 0.1270 - val_loss: 0.1753 - val_mse: 0.1753\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1270 - mse: 0.1270 - val_loss: 0.1755 - val_mse: 0.1755\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1268 - mse: 0.1268 - val_loss: 0.1758 - val_mse: 0.1758\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1265 - mse: 0.1265 - val_loss: 0.1766 - val_mse: 0.1766\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1263 - mse: 0.1263 - val_loss: 0.1769 - val_mse: 0.1769\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1262 - mse: 0.1262 - val_loss: 0.1772 - val_mse: 0.1772\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 0.1773 - val_mse: 0.1773\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1260 - mse: 0.1260 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1257 - mse: 0.1257 - val_loss: 0.1770 - val_mse: 0.1770\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1259 - mse: 0.1259 - val_loss: 0.1770 - val_mse: 0.1770\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1257 - mse: 0.1257 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1255 - mse: 0.1255 - val_loss: 0.1774 - val_mse: 0.1774\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 0.1776 - val_mse: 0.1776\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 709us/step\n",
      "MAE Train = 0.2799887035823005\n",
      "MSE Train = 0.13565832968614622\n",
      "R2  = 0.07340040976609763\n",
      "\n",
      "9/9 [==============================] - 0s 955us/step\n",
      "MAE Test = 0.24493450483405\n",
      "MSE Test = 0.09845256255957206\n",
      "R2  = -0.037298330100309585\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 11ms/step - loss: 2.5109 - mse: 2.5109 - val_loss: 2.7801 - val_mse: 2.7801\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.9392 - mse: 1.9392 - val_loss: 2.1893 - val_mse: 2.1893\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.5183 - mse: 1.5183 - val_loss: 1.7646 - val_mse: 1.7646\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 1.2198 - mse: 1.2198 - val_loss: 1.4453 - val_mse: 1.4453\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 1.0017 - mse: 1.0017 - val_loss: 1.2096 - val_mse: 1.2096\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.8309 - mse: 0.8309 - val_loss: 1.0370 - val_mse: 1.0370\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.7084 - mse: 0.7084 - val_loss: 0.8965 - val_mse: 0.8965\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6087 - mse: 0.6087 - val_loss: 0.7817 - val_mse: 0.7817\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5334 - mse: 0.5334 - val_loss: 0.6898 - val_mse: 0.6898\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4691 - mse: 0.4691 - val_loss: 0.6139 - val_mse: 0.6139\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.4171 - mse: 0.4171 - val_loss: 0.5475 - val_mse: 0.5475\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3720 - mse: 0.3720 - val_loss: 0.4909 - val_mse: 0.4909\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3339 - mse: 0.3339 - val_loss: 0.4394 - val_mse: 0.4394\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2990 - mse: 0.2990 - val_loss: 0.3922 - val_mse: 0.3922\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2674 - mse: 0.2674 - val_loss: 0.3489 - val_mse: 0.3489\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2416 - mse: 0.2416 - val_loss: 0.3184 - val_mse: 0.3184\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2216 - mse: 0.2216 - val_loss: 0.2931 - val_mse: 0.2931\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2060 - mse: 0.2060 - val_loss: 0.2716 - val_mse: 0.2716\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1920 - mse: 0.1920 - val_loss: 0.2527 - val_mse: 0.2527\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1822 - mse: 0.1822 - val_loss: 0.2378 - val_mse: 0.2378\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1730 - mse: 0.1730 - val_loss: 0.2255 - val_mse: 0.2255\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1670 - mse: 0.1670 - val_loss: 0.2163 - val_mse: 0.2163\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1616 - mse: 0.1616 - val_loss: 0.2091 - val_mse: 0.2091\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1578 - mse: 0.1578 - val_loss: 0.2035 - val_mse: 0.2035\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1545 - mse: 0.1545 - val_loss: 0.1979 - val_mse: 0.1979\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1520 - mse: 0.1520 - val_loss: 0.1937 - val_mse: 0.1937\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1500 - mse: 0.1500 - val_loss: 0.1907 - val_mse: 0.1907\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1487 - mse: 0.1487 - val_loss: 0.1885 - val_mse: 0.1885\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1472 - mse: 0.1472 - val_loss: 0.1857 - val_mse: 0.1857\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1451 - mse: 0.1451 - val_loss: 0.1825 - val_mse: 0.1825\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1441 - mse: 0.1441 - val_loss: 0.1806 - val_mse: 0.1806\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1431 - mse: 0.1431 - val_loss: 0.1799 - val_mse: 0.1799\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1424 - mse: 0.1424 - val_loss: 0.1782 - val_mse: 0.1782\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1415 - mse: 0.1415 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1407 - mse: 0.1407 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1400 - mse: 0.1400 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1395 - mse: 0.1395 - val_loss: 0.1768 - val_mse: 0.1768\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1389 - mse: 0.1389 - val_loss: 0.1762 - val_mse: 0.1762\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1384 - mse: 0.1384 - val_loss: 0.1753 - val_mse: 0.1753\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1376 - mse: 0.1376 - val_loss: 0.1743 - val_mse: 0.1743\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1369 - mse: 0.1369 - val_loss: 0.1732 - val_mse: 0.1732\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1364 - mse: 0.1364 - val_loss: 0.1721 - val_mse: 0.1721\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1361 - mse: 0.1361 - val_loss: 0.1717 - val_mse: 0.1717\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1357 - mse: 0.1357 - val_loss: 0.1719 - val_mse: 0.1719\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1354 - mse: 0.1354 - val_loss: 0.1723 - val_mse: 0.1723\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1353 - mse: 0.1353 - val_loss: 0.1728 - val_mse: 0.1728\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.1350 - val_loss: 0.1724 - val_mse: 0.1724\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1348 - mse: 0.1348 - val_loss: 0.1723 - val_mse: 0.1723\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1346 - mse: 0.1346 - val_loss: 0.1718 - val_mse: 0.1718\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1344 - mse: 0.1344 - val_loss: 0.1721 - val_mse: 0.1721\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1343 - mse: 0.1343 - val_loss: 0.1727 - val_mse: 0.1727\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1341 - mse: 0.1341 - val_loss: 0.1727 - val_mse: 0.1727\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1339 - mse: 0.1339 - val_loss: 0.1731 - val_mse: 0.1731\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1339 - mse: 0.1339 - val_loss: 0.1729 - val_mse: 0.1729\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1337 - mse: 0.1337 - val_loss: 0.1729 - val_mse: 0.1729\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.1335 - val_loss: 0.1722 - val_mse: 0.1722\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1333 - mse: 0.1333 - val_loss: 0.1720 - val_mse: 0.1720\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1332 - mse: 0.1332 - val_loss: 0.1723 - val_mse: 0.1723\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1331 - mse: 0.1331 - val_loss: 0.1721 - val_mse: 0.1721\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1329 - mse: 0.1329 - val_loss: 0.1720 - val_mse: 0.1720\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1328 - mse: 0.1328 - val_loss: 0.1714 - val_mse: 0.1714\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1326 - mse: 0.1326 - val_loss: 0.1708 - val_mse: 0.1708\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1324 - mse: 0.1324 - val_loss: 0.1708 - val_mse: 0.1708\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1323 - mse: 0.1323 - val_loss: 0.1710 - val_mse: 0.1710\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1322 - mse: 0.1322 - val_loss: 0.1706 - val_mse: 0.1706\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1320 - mse: 0.1320 - val_loss: 0.1705 - val_mse: 0.1705\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1318 - mse: 0.1318 - val_loss: 0.1703 - val_mse: 0.1703\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1316 - mse: 0.1316 - val_loss: 0.1706 - val_mse: 0.1706\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1316 - mse: 0.1316 - val_loss: 0.1700 - val_mse: 0.1700\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1315 - mse: 0.1315 - val_loss: 0.1705 - val_mse: 0.1705\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1314 - mse: 0.1314 - val_loss: 0.1692 - val_mse: 0.1692\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1314 - mse: 0.1314 - val_loss: 0.1691 - val_mse: 0.1691\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1312 - mse: 0.1312 - val_loss: 0.1698 - val_mse: 0.1698\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1310 - mse: 0.1310 - val_loss: 0.1699 - val_mse: 0.1699\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1307 - mse: 0.1307 - val_loss: 0.1703 - val_mse: 0.1703\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305 - val_loss: 0.1701 - val_mse: 0.1701\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305 - val_loss: 0.1692 - val_mse: 0.1692\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1304 - mse: 0.1304 - val_loss: 0.1698 - val_mse: 0.1698\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1301 - mse: 0.1301 - val_loss: 0.1697 - val_mse: 0.1697\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1300 - mse: 0.1300 - val_loss: 0.1704 - val_mse: 0.1704\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1298 - mse: 0.1298 - val_loss: 0.1705 - val_mse: 0.1705\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1297 - mse: 0.1297 - val_loss: 0.1702 - val_mse: 0.1702\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1294 - mse: 0.1294 - val_loss: 0.1701 - val_mse: 0.1701\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1293 - mse: 0.1293 - val_loss: 0.1699 - val_mse: 0.1699\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 0.1705 - val_mse: 0.1705\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 0.1709 - val_mse: 0.1709\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 0.1710 - val_mse: 0.1710\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1290 - mse: 0.1290 - val_loss: 0.1709 - val_mse: 0.1709\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1289 - mse: 0.1289 - val_loss: 0.1711 - val_mse: 0.1711\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 0.1712 - val_mse: 0.1712\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1287 - mse: 0.1287 - val_loss: 0.1717 - val_mse: 0.1717\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1286 - mse: 0.1286 - val_loss: 0.1714 - val_mse: 0.1714\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1284 - mse: 0.1284 - val_loss: 0.1709 - val_mse: 0.1709\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1281 - mse: 0.1281 - val_loss: 0.1705 - val_mse: 0.1705\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1279 - mse: 0.1279 - val_loss: 0.1704 - val_mse: 0.1704\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1277 - mse: 0.1277 - val_loss: 0.1701 - val_mse: 0.1701\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1276 - mse: 0.1276 - val_loss: 0.1698 - val_mse: 0.1698\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1274 - mse: 0.1274 - val_loss: 0.1697 - val_mse: 0.1697\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1273 - mse: 0.1273 - val_loss: 0.1684 - val_mse: 0.1684\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1271 - mse: 0.1271 - val_loss: 0.1684 - val_mse: 0.1684\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAESCAYAAAAVLtXjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAt8ElEQVR4nO3deZwjdZ3/8VdVkk76SHd6ZnpumAGW+XIM96kiICAoKMshLCqyrA9EVHREV1dY0HWXXURRVxdZBRYPVn64gCi3KCAOCKiAcgzzhRlnBuZg6Jnp+0g6Sf3+qEp3uqd7prun0+lOvZ+PRz+SVKWqPp9K+lPffFP1jeN5HiIiEi5uuQMQEZHJp+IvIhJCKv4iIiGk4i8iEkIq/iIiIaTiLyISQtFyByBSKsaYbwLnANuCSdZa+3dlDElkylDxl0r2duA8a+3vyx2IyFTj6CIvqUTGmDjQBjwA7AWsAi6z1r4+5HmLgUeC5x0FzAD+2Vr7s2D+PwNn43eRrgU+aa3daIz5LXC9tfbO4Hn9j40xaeCXwEHAh4Fq4BtADZABrrTWPmSMuRA4E8gDewfzLrDWvmSMOQu4MpiXA75grf3dxO4lCTP1+Uulmg88ClwOHAw8DfzSGOMM89w9gV9Za48E/gn4OoAx5gLgAOBIa+3B+AeIm0ex7SrgXmutAdYAdwLLrLUHAn8P/K8xZo/guccBn7bWLgWeBL4QTP8G/oHmcOAq4PhRZy4yCur2kYpkrV0DnFp4bIy5Dr+ILsYvyMX68As7wHP4rX+A9wFHAn8yxgBE8Fvvo7E8uD0KWGWtfSaI62VjzJP4xdwDnrXWri/a9lnB/duBu40x9wO/JjggiUwUtfylIhljDjTGfGTIZAe/0A+Vsdbmg/te8Dzwi/211tqDg5b/4cA7hnke+K39Yp3B7XD/Yy4QC+73FE3vX6e19p+Dbf0JuBB4yhij/1eZMHozSaXKA98t6l75BPBCUSt7NH4FXGSMqQ8e/ytwa3C/Gf9ggDFmL+DAEdbxtP8Uc2Tw3P2BY4HfjrRRY0zUGLMWqLXWfh/4JLAvAwcMkV2m4i8VyVr7EvBp4F5jzCv4X6x+cIyruRm4D3jaGPMyfoG/MJh3NXCyMeYl4Fpg2C9jrbVb8E83/S9jzIvAbcA/WGtf3UHsWeCzwG3GmOeAO4CPWmvTY4xfZEQ620dEJITU8hcRCSEVfxGREFLxFxEJIRV/EZEQmhYXeeXzeS+XG98X05GIw3iXnc7CmHcYc4Zw5h3GnGHsecdikS1A03DzpkXxz+U8Wlu7x7VsKlUz7mWnszDmHcacIZx5hzFnGHveTU3JdSPNU7ePiEgIqfiLiISQir+ISAhNiz5/EQmvXC5LS0sz2Wymf9rmzQ5hHJ1gpLyj0SoaG5uIREZf0lX8RWRKa2lpJpGoobZ2Lo7jD6QaibjkcvmdLFl5hsvb8zy6utppaWlm1qx5o16Xun1EZErLZjPU1tb3F34ZzHEcamvrB30yGg0VfxGZ8lT4d2w8+6eii7/TvQVn5b3lDkNEZMqp6OIfX30f0bv+HifdXu5QRESmlIou/l6sFgCnt6XMkYiITC0VfbaPF08B4KZbybOovMGIyC67/+XN3PPSmzgOTNSZnqcvnctp+8/Z4XMeeOBennzyd6TTabZu3cI553yQ5csfZ82a1XzqU8tYvvxx1q9/g3Q6zTnnnMd73nMazz//LDfeeAORSIT58xfwxS/+M9Ho1Cm5UyeSEsgnUgA4va1ljUNEpr/u7m6+/e3v8Zvf/Iqf/ew2brzxRzz//LP8+Mf/w6ZNG/nBD36E4zj84Q9P43ke11777/z3f99MY+MMbrrpv3nggXs5/fQzy51Gv4ou/sUtfxGZ/k7bfw6n7T+nLOf57723AaCuLsnixXvgOA7JZJJIJMpnPvN5vv71f6e7u4uTT34vra0tbN26hauu+hIA6XSaI444alLj3ZmKLv75eAMATrqtzJGIyHQ38umUHta+wjXXXEc6nebss0/j5JPfy+zZs/na175FXV0dTzzxONXVNZMa785UdPH3En7xd9XtIyIltG3bVi655KO4rst5551PLBZj2bJ/5AtfWIbnedTU1HLVVV8td5iDONNhfIy+vpw33rG7Z91o6Nnvw3Qd8+UJjmpqC+N452HMGSo/7zffXMfcuYNP2NDwDtsbbj81NSWfBQ4f7vkVfaonANUp9fmLiAxR+cU/0aizfUREhqj44u9VN6rlLyIyRMUXf6pTavmLiAxR+cU/0ahTPUVEhqj44u8VvvCdBmc1iYhMloov/iQacXJpyPaWOxIRkSmj4ou/V50CwE1rZE8RKa1LL72YdevWljuMUanoK3wBqG4EgsHd6uaXNxYR2SXxlXeSeOV2HGfifsC9d9/zSO/zgQlZ13RS+cU/4Rd/N91KrsyhiMj0dMUVX+Ccc87jkEMOY+XKFXzve98hlWqks7ODLVuaOeuscznzzJ0fQC644O846KBDWb36NRYtWkxj4wz+8pfnicViXHfdd1mx4iWuv/4/iUajJBIJrr76Wqqq4nzjG//B+vVv4HkeF110CYceOuxFu2My4cXfGBMDbgEWA3HgamvtPUXzLwMuApqDSR+31tqJjqPAK275i8i0lt7nA6T3+cCkD+/w/vefwYMP3schhxzG/fffy6GHHs6ee+7FccedwJYtzVx66cWjKv7d3d28+92n8PnP/xMf+tDZfPrTl3HxxZ/k0ksvZs2a1Sxf/jgnnHAS5577IZ544ne0t3fw1FMP0tCQ4vLLv0xnZzuXXHIR//u//7fLOZWi5X8+sNVa+xFjzAzgz8A9RfMPAy6w1j5bgm0P0tbTx6pmj7cBrk73FJFxOuqot3HDDd+hvb2NF154nuuu+y7f//71PP74Y9TU1JLNZke9LmP2AQpDQ+8JQDKZJJ3O8JGP/AM/+cktLFv2CZqaZrPffktZvXoVL7zwPCtWvITjOORyWVpbW0mlUruUUymK/x3AncF9Bxi6Vw4DLjfGzAXut9ZeU4IYAPi1beb6R1fzclwtfxEZP9d1ede7TuK6677GO995PLff/r8sXXogZ575AZ577k889dQTY1jbSENDw8MPP8Cpp76PSy/9LLfe+kPuuefnLFq0mNmzZ3PBBR+lry/DD394M/X19buc04QXf2ttJ4AxJol/ELhyyFNuB74HtAN3G2PeZ629b0frjEQcUqmxj4XdWJ+gy4vjuTGqnS7i41jHdBWJuOPaZ9NZGHOGys9782aHSGT7ExOHm1ZKp59+BmeffTp33PELNm7cwLe+9XUeeeRhkskk0WiUXC6L4zi47vDxFkQiLpGIi+MU33eIRByWLj2Aa6+9mkSiGtd1+dKXrmTWrCauuebfuPTSi+nq6uLss88hFtu+dDvO2OpkSYZ0NsbsBtwN3GCtvaVougPUW2vbgsefBGZaa/9tR+sb75DOv1u9lc//4mVebfgMub1OofNd1455HdNVpQ/zO5ww5gyVn7eGdB4wkUM6l+IL3znAw8Cl1tpHhsyuB14yxuwLdAEn4H85XBINCT+9dKyeKg3uJiKTYMWKl7jhhu9uN/3EE08e1ZfCk6UUff5XAI3AVcaYq4JpNwG11tobjTFXAI8BaeARa+0DJYgBgIZEDICeSD1x9fmLTFue5+3gZxSnlv32W8r11984qdscTw9OKfr8lwHLdjD/VuDWid7ucOqr/fS63CSN6W2TsUkRmWDRaBVdXe3U1tZPmwPAZPI8j66udqLRqjEtV9EXedUHLf8Opw43vabM0YjIeDQ2NtHS0kxnZ2v/tIm8wnc6GSnvaLSKxsamMa2root/1HWoi0dpo06neopMU5FIlFmz5g2aVulfco9kIvOu+IHdUjUxWvK1uH2dkOsrdzgiIlNC5Rf/6hhb8/65r/pRFxERX+UX/5oYzTm/+Ou3fEVEfBVf/BuqY2zuC1r+6vcXEQFCUPwba6rYlEkAavmLiBRUfPFvqI6xIV0NgKPiLyIChKD4p2pitHi1ALjq9hERAcJQ/KtjdFCDh6M+fxGRQMUX/4bqGB4u2ap69fmLiAQqvvinavzxLtLRerX8RUQClV/8q/3xfXojavmLiBRUfvGv8Yt/l5tUy19EJFDxxb8+EcPBH9lTwzuIiPgqvvhHXIdkwh/ZU90+IiK+ii/+APWJKC1erd/y98L3u58iIkOFovg3JGJszdfieHmcTEe5wxERKbtQFP/6RJTmXHCVb8/WMkcjIlJ+oSj+DdUx1vclAXC7m8scjYhI+YWj+CeirMvUA+B2vVXmaEREyi8kxT/GmnSh5b+5zNGIiJRfKIp/fSJKK3Xk3SrcbrX8RURCUfwbqmOAQ19ilrp9REQISfGvT0QB6I3PVMtfRISQFP+GYHC3rtgs3C71+YuIhKP4By3/9ugMneopIkJIin+h26fFnYHbuw1ymTJHJCJSXqEo/nXxKK4DW5xGANzuLWWOSESkvEJR/F3HIRmP8lY+5T/Wuf4iEnLRiV6hMSYG3AIsBuLA1dbae4rmvx/4MpAFbrHW3jTRMQynoTrGxlwDoKt8RURK0fI/H9hqrX0n8B7g+sKM4MDwbeBk4DjgYmPMnBLEsJ2GRJQN2cJVvir+IhJuE97yB+4A7gzuO/gt/IJ9gVXW2hYAY8wTwLHBMiOKRBxSqZpxBROJuKRSNcxMJtjQ0YCHQ01uG4lxrm+6KOQdJmHMGcKZdxhzhonNe8KLv7W2E8AYk8Q/CFxZNLseKP4txQ6gYWfrzOU8Wlu7xxVPKlVDa2s3NVGHV7uyeNUzyWzbQOc41zddFPIOkzDmDOHMO4w5w9jzbmpKjjivJF/4GmN2Ax4DbrXW3lY0qx0ojiYJtJYihqEaEjHaerPka2brXH8RCb1SfOE7B3gYuNRa+8iQ2a8AextjZgCd+F0+1010DMOpT0TpyuTI1swmoj5/EQm5UvT5XwE0AlcZY64Kpt0E1FprbzTGfA74Ff6njlustRtKEMN2CkM89MZnkdy2cjI2KSIyZZWiz38ZsGwH8+8F7p3o7e5MY1D8O2MzaejZ4v+QuxOKyxxERLYTmurXVFcFQIvTiJPP4vRsK3NEIiLlE5riP7PWL/7NpACd6y8i4Raa4j8rKP6bcikADe0sIqEWmuKfiEWoi0dYnw1+yF0tfxEJsVKc7TNlzaqtYk3aTzmi8X1EJMRC0/IHv/hv6nbIV9XjqOUvIiEWquI/s7aKLV0Z8jVNutBLREItVMV/Vm08KP6z1ecvIqEWruJfV0U6myeTaNKY/iISauEq/sHpnh2xmf6veXlemSMSESmPUBb/1sgMnGwvTqajzBGJiJRHKIv/Fl3lKyIhF67iH4zvszE/EwC3Y1IGFBURmXJCVfxrqyIkoi5r800ARNrfKHNEIiLlEaorfB3HYVZdFWvSNXhujEjH6+UOSUSkLELV8ge/37+5O0cuuQBXLX8RCalwFv/ODPn63Ym0q+UvIuEUuuI/s7aKrV0ZcsndVPxFJLRCV/xn1VbRlcmRrluI29uCk+ksd0giIpMufMW/8HOOsXkAuGr9i0gIha/4Bxd6bY7MAXS6p4iEUwiLfxyADQTFv0PFX0TCJ4TF32/5b8jUkI/VqttHREIpdMW/oTpK1HXY0tVHvn43dfuISCiFrvg7jhOc7pkml9S5/iISTqEr/jBwoVeu0PLXuP4iEjKhLP5NdcFv+dbvhpPtxundVu6QREQmVSiLf/9VvvW7AxBpW1fmiEREJteoRvU0xkSAC4FFwKPAS9baLSWMq6Rm1VbR1pult2YhDfine2bnHlrusEREJs1oh3T+AbAReDfwR+AnwKk7WsAYcxRwrbX2+CHTLwMuApqDSR+31toxxLzLCqd7NkfnMAc0uqeIhM5ou332stZ+Geix1t4LNOzoycaYLwI3A4lhZh8GXGCtPT74m9TCD9CU9C/02tQTJZ+YoTN+RCR0Rlv8o8aYWQDGmCSQ38nzVwNnjTDvMOByY8wTxpjLR7n9CbWwwT8mrW/rGTjjR0QkREbb7XMl8CQwD3ga+OyOnmytvcsYs3iE2bcD3wPagbuNMe+z1t63o/VFIg6pVM0oQx26rLvdsjV1CVwHtvTmiMzaE2fTn8e9/qlquLwrXRhzhnDmHcacYWLzHlXxt9Y+DhhjTBPQYq3NjmdjxhgH+E9rbVvw+H7gEGCHxT+X82ht7R7PJkmlaoZddm4yzqo32+mdMZ/qtvto3dYBbmRc25iKRsq7koUxZwhn3mHMGcaed1NTcsR5o+r2McZ82BhzHv6XvBuMMf846q0PVg+8ZIypCw4EJwDPjnNdu2RBqpr1rb3k6nfDyffhdr1ZjjBERMpitH3+y4BfA+cDuwPvH8tGjDEfMsZcHLT4rwAeA5YDL1trHxjLuibKbqlq1rf2DJzr365z/UUkPEbb598b3HZYa9PGmJ0uZ61dCxwd3L+taPqtwK1jjHPCLUwlaOvN0lazBykgsu1V+ha8vdxhiYhMitG2/Ffhf9H7P8aYLwN/KV1Ik2NhqhqAdX0N5OMNRLeuLHNEIiKTZ7Qt/1/gd/d8Cv+AMe1HQluY8k/3fKO1l+yMfVT8RSRURlv8vwFcDLSWLpTJtaDBb/lvaOslN3Mf4q/+3B/d03HKHJmISOmNtvi/HJzuWTFqqiLMrK1ifWsP2QWG6kwHbudG8skF5Q5NRKTkRlv8f2mMeQp4pTDBWvvR0oQ0eRY2JPxunwP2ASC6dSUZFX8RCYHRFv/PAF+ngrp9ABY2VvPHdS3kZu4LQGTrK7D4xDJHJSJSeqMt/m9aa39W0kjKYGFDgvs7M/S4deTq5utLXxEJjdEW/x5jzEPA8wRn+lhrryhZVJNkt9TAl76zZ+5DdNukDzAqIlIWoy3+95Y0ijIpnO65vrWXA2cYqt5YDrk+iMTKHJmISGmNdmC3H5c6kHJYELT817f2kJ25D06+j0jrX8nNNGWOTESktEL5G74FDYkoyXg0KP7+l77Rber3F5HKF+ri7zgOC1MJf3TPxr3wnAiRrer3F5HKF+riD/4YP+vbeiASJ5faS2f8iEgoqPinEmxqT5PN5cnONOr2EZFQUPFPVZPLe7zZkSY3cx8i7a/jZDrLHZaISEmFvvgXzvVf19JDdoY/zENE5/uLSIULffH/m1m1ALz2VifZWfsDEG1+sZwhiYiUXOiLfzIRZX59HPtWF/nkAnJ184ht/EO5wxIRKanQF3+AJbPreLW5ExyHvnlHEtv0jD+2v4hIhVLxxy/+b7T00J3J0Tf/KCJdm3H1g+4iUsFU/AEzuw4PeK25k755RwKo60dEKpqKP7Ckyf/S99XmLnIzlpCPp/yuHxGRCqXiD8xJxmlIRLFvdYLj+v3+avmLSAVT8ccf42fJ7Dpefcu/uKtv/pFE29bgdL1V5shEREpDxT+wpKmO1Vu6yOa9gX7/TWr9i0hlUvEPLJldSybnsXZbN9mmA/Ci1cQ2qt9fRCqTin/AzK4D8Lt+IjH65h6mlr+IVCwV/8CiGTXEo67/pS/QN+9IoltW4KTbyhyZiMjEU/EPRF2HvWbV8mpzFwB984/CwSO26U9ljkxEZOKVrPgbY44yxvx2mOnvN8b80RjzlDHmY6Xa/ngsaarl1bc68TyPvjmH4kXixNYvL3dYIiITriTF3xjzReBmIDFkegz4NnAycBxwsTFmTiliGI8ls+to782yuSMNsWr6FryNqrWPlDssEZEJV6qW/2rgrGGm7wussta2WGszwBPAsSWKYcwKX/qu3Oz3+6cXn0S0bQ2R1r+WMywRkQkXLcVKrbV3GWMWDzOrHij+BrUDaNjZ+iIRh1SqZlyxRCLuqJc9sjZOLOKwcms3ZxxRAwe8D353JQ2bf0d+8dJxbb9cxpJ3pQhjzhDOvMOYM0xs3iUp/jvQDiSLHieB1p0tlMt5tLZ2j2uDqVTNmJbdf26Sp1dvDZaZRWPjEvIrH6LNXDiu7ZfLWPOuBGHMGcKZdxhzhrHn3dSUHHHeZJ/t8wqwtzFmhjGmCr/L56lJjmGHDlnYwMrNHXRncgBkFp9AbOMz+l1fEakok1L8jTEfMsZcbK3tAz4H/Aq/6N9ird0wGTGM1iELG8h58OKmdgAyi07EyfcRe+N3ZY5MRGTilKzbx1q7Fjg6uH9b0fR7gXtLtd1ddeD8elwHnl/fxlGLGumbezj5eANV6x4hs9ep5Q5PRGRC6CKvIWqropjZdTy/PvheOhIjs9txxNc+Cl6+vMGJiEwQFf9hHLKwgZc2tZPJ+sU+s/gE3J5mos0vljkyEZGJoeI/jEMXNpDJeax4swOAzO4n4DkuVWseLnNkIiITQ8V/GAct8C89eH6D3/XjVc+gb8E7SLz6C/C8MkYmIjIxVPyHkaqOsefMmoF+f6DXnEWkfR3Rzc+VMTIRkYmh4j+CQxY28MLGdrJ5v6Wf2fM9eNEECfvzMkcmIrLrVPxHcOjCBroyOV5r9i/u8qqSpPc4hfiqeyCXKXN0IiK7RsV/BIcs9Pv9n1nb0j8tveQs3N4Wql5/vFxhiYhMCBX/ETTVxVk6L8kjr27pn5bZ7VjyiRnEX1XXj4hMbyr+O3DSkiZWvtXJGy09/oRIjPTepxNf8zBOur28wYmI7AIV/x04ccksAH7zanP/tN4lZ+Lk0sRXP1CusEREdpmK/w7MrU9wwLx6fmMHin92zqFkU3uReOknOudfRKYtFf+dOMnM4tXmLtZtC8bQdhx6DvoYseYXiG18urzBiYiMk4r/Tpy4pAkY0vWzz9nkEzOo/vON5QpLRGSXqPjvxJxknIMX1PMbO3DWD9FqepZeQHztr4m0rC5fcCIi46TiPwonLWli1ZYu1mwd+Pm0ngMuxIvEqf7LTWWMTERkfFT8R+GEJbNwgIdWvtU/zauZRa85i8TKO3B6tpYvOBGRcVDxH4Wmujjv2HMGv3zxTbK5gR906TnoYpxcmuoXf1S+4ERExkHFf5Q+cNB8tnZleGzVQCs/N2Nv0nucQvVfbsbp2VbG6ERExkbFf5SOXtzI/IYEd/5546DpXUf/E05fFzV/+k6ZIhMRGTsV/1GKuA5nHziP59a3sXpLV//03Iwl9O77d1S/9BPctnVljFBEZPRU/Mfg9KVzqYo43PWXTYOmdx/5eXAj1D7z9TJFJiIyNir+Y5CqiXGSaeKBFZvpymT7p+dr59J90MdIvPZLom+9UMYIRURGR8V/jD5w0Hy6MjkeWPHWoOk9h3yCfKKR2ie/qjF/RGTKU/Efo6XzkhwwL8mPnnmd3r5c/3QvXk/X0V+iauMzxFfeUcYIRUR2TsV/jBzH4dJj9+Ctzgz/77kNg+b17vdB+uYdQd3v/02nforIlKbiPw6HLkxx7F4z+fEf3qClu+j3fB2XjuOuwcl0UPv7fy9fgCIiO6HiP06XvnMPevpy/M/Trw+anpu5Dz0Hf5zqlT8jtuGpMkUnIrJjKv7jtMfMGv72gLnc+ZdNAz/zGOg6/LPk6nen7rEv4GQ6yxShiMjIoqVYqTHGBW4ADgLSwEXW2lVF878DHAN0BJP+1lrbVopYSunity/moVfe4tu/Xc03z9gfx3H8GbFqOk78Fg2/OJe65VfRceK3yxuoiMgQpWr5nwEkrLVvA74EfHPI/MOAU6y1xwd/067wA8yqreJjb1vE8r9u49HXtgya1zf/aLoPX0Zi5R3E7c/LFKGIyPBKVfyPAR4CsNY+DRxemBF8KtgbuNEY86Qx5qMlimFSfPCwhewzu46vP7KKtp6+QfO6D19G37wjqXv8cty2teUJUERkGI5XgguSjDE3A3dZax8MHr8O7GmtzRpjksAy4FtABHgM+Ki1dsRLY/P5vJfLjS/OSMQlVzQMcym8vLGds3/wFGcePJ9rzjxg8My29URvPhYvtZjcBfdDrLqksRRMRt5TTRhzhnDmHcacYex5x2KRZylqfBcrSZ8/0A4kix671trCeAjdwHestd0AxphH8b8bGLH453Iera3dI83eoVSqZtzLjtaCmigfPmwhP/njG7xrzxkcuaixaO4Mqk74Fg0PfJTMPZ+l44RvQeG7gRKajLynmjDmDOHMO4w5w9jzbmpKjjivVN0+TwKnAhhjjgZeLJq3BHjSGBMxxsTwu4ieK1Eck+Zjb9ud3Rur+epDlq1dmUHzMnucTNcRl5FYeQfVL9xSpghFRAaUqvjfDfQaY34PfBu4zBjzOWPM6dbaV4BbgaeBx4GfWGtfLlEckyYRi/Af79uXtt4sl9/3yqBf/ALoPuIy0otPpvbJfyW24fdlilJExFeSPv+J1teX86Zyt0+xB1/ZzJcfsJx36AI+/669Bs1zMh2k7nw/bs9WWs6+h3xqj5LFEcaPxWHMGcKZdxhzhnF1+4zY56+LvCbYe/edw3mHLuD25zbwwIrNg+Z5VUnaT/W7fRru+4jG/xGRslHxL4Flx+7BoQsbuPrhV/nDupZB83KpPWk77UdEOjfR8MA/QLZnhLWIiJSOin8JRCMu3/jb/di9sZov/HIFr2zuGDQ/O/cw2t/9XaJvPkf9rz8D+dwIaxIRKQ0V/xKpT8T47lkH0FAdZdldL7Fu2+B+usxep9F1zFeI//VB6h77InjhO2dZRMpHxb+EZifj/NfZ/kVfn7zjBdZuHXwA6DnoIrqOuIzqlT+jdvlX9AtgIjJpVPxLbNGMGq7/wAFk8x4X3f5nVrw5uAuo+4jP0X3wx6l58YfUPn2NDgAiMilU/CfBktl13HzewdRWRfjE/73AH18v+hLYceh6+5X07P8Rap67gfqHPobT21q2WEUkHFT8J8lujdXc/MGDmVsf5zN3vcT9LxedBuo4dB73H3S+48tUrX2Exp+dQnTTn8oXrIhUPBX/SdRUF+em8w7i4IUN/MtDlhueWEO+0M3jOPQcfDGtZ90NboTU3WdT+8RX9WMwIlISKv6TrD4R47/OWsoZB8zlh8+8weX3vkJXJts/PzvnYFrOfYje/T5IzV9uovG246ladZ++CxCRCaXiXwbRiMsV796bzx63J79dtYULf/o8q7d09c/34vV0Hv81Ws7+JV5iBg2/uoTUz8/QmEAiMmFU/MvEcRw+fPhCbjjnQNp7s1z40+d5YMVmisdays49jJZzH6DjuK/hdmwg9YtzafjlB/2DgD4JiMguUPEvs8N2S/HTjxzKvnOTfOVBy+d+8TKb2nsHnuBG6V16PtvOX07nO75CdOsKUr84l9Sd7yP+2r2Q6xt55SIiI9ConlNENu/xs+c28P0n1wJw8dsXce4hC4hHhxyfsz0kVt5F9Z9/QLRtDfnqmfT+zemkzVlkZx/c/0Mx0yXviRTGnCGceYcxZ5jYUT1V/KeYTe29fP2RVTzx12001VVx/uELOevAeSRikcFPzOeoev0x4ivvJL721zi5NLm6+WQWn0Rm0YnU7PcuWrvD9cFuur3WEyWMeYcxZ1DxH5Pp+CbxPI8/vdHK/zz9Os++0UZjdYzT9p/D+/afw16zard7vpNuI776QarW/pqqN5bjZLvxHJfszH3Jzj2cbNMBZGcasjMMxGrKkNHkmI6v9UQIY95hzBlU/Mdkur9J/ry+jZ8+u57lf91GLu+x39wkp+zTxElLmpidjG+/QC5NbMPTJFueJ7f2GaKbn8Pt888k8nDI180n17A7ufpF5OsXkWsI/pK74SUaJ+X3hUtlur/W4xXGvMOYM6j4j0mlvEm2dWd46JW3uO/lzbzW7BfzgxfUc+SiRg5Z0MDSeclBXUP9eedzuO2vE922kujWlURa1xBpX0ekbR1uz5ZB2/DcKvK1c8jXzCKfaMRLNJKPN+BVJfFidf5tvIF8IoWXSJGPN5KvngHR6ilx0KiU13qswph3GHMGFf8xqcQ3ydpt3fzGNvPoa1tY1dyFB0RdBzO7jqXzkhw4v55D9pxFgwtVQ78wLpbpItLxOpG2dUQ6NuB2b8bt2ozb3YzT24rb24KTbsXJdOIw8vvEi8TxYrXBXw2eGwM3Am4ML5rAi1bjRashGvfnRarwnMKBauh6HXDc/j/PjYITATeKF4n563RjEInhuVX+baQKInFq65N09noD053IwLo8L9iWB/k8jpcDL+cPpZ3P+Y8dF69o2wMhuXhOFNxgmufheHl/+XywjqIhuR2Cx57n/xUOjI7j51fIvD+3IE4cPBx/X3v5on3j9C/rFe47LrhRcFySqSTtHX3gRvz5wTPBGzgl2HHwKOTmFK2TwdsoxI03sN+dSNH+8vAicYjGB++j/qQ8yGcH9rU3cOsE+6g/h+A90r8eb5i8vTx4WZx8dtDvXjQ01NDW3jPCvinaz17eX9YbeJ2c/tdrmPceXjC5KPb++HNFr7O/Hf/9UngNIwPvn+L9W3gvF+//oc8h2B87oeI/BpVY/Iu19/bxwsZ2nl/fzoub2lnxZgfprP8GdR2Ym4yzIFXNgoYE8xsSzEnGmVlTxYzaGI01VaSqY0TdnbTaPQ+yPbjpNpx0m3/b2+IfHAq3fd04fV04fV3+P3/e/4d1cr3Q14OT7cbJZSCXwcmlB1+nUFyEggLQ/4+Wz/r3Zcrx3Cj9Z4s7zrhfq0JDIOyvs+dE8KIJiFT1HxC9SJz2U28h27QUmNjiH931kKWc6hMxjtlzJsfsOROAbC7Pqi1dbO7NsXJ9K6+39LChrZfHV22lpWf4awLqE1EaElHq4gN/NTGXRCxCdSxCPOoW/dUTj6ZIRPekpjpCbUOEmqoIMdclGnGIRVxiEYeqiEvUdYi6DhHXwdmVbqFCazKfxcn3Qb7Pv831BQeUNE4uTbLapbOtAyef8a9/CA4gfovTwSvEELTS+ltqhceeB17wKaD44BS0Pvtbnv2fDiLBp5OBlnvwBP9TQnGLtrgV3r/eXFGLtrjVW9RC9Ia0oAv3CwfIfJaa6ig9nd1Bi7uYE4TkDFquuNXr9K83iLPw6YegGOeDFn9/vo5/AM/2+gdxf0H/E4Eb9T+NFB0UvP6WuDtwkO/PKe+/fvngfVn8Kaj4E4sbBSc6qGVcXV1FT09m8CeVofuo8FoFn5C84Lb408J2MRV/kuj/ZOMMvB7Fn1j792duYF8xsI+doXEVPi16XjCv6AecvHywX9PBfvXj9yJxcjWzKQUV/woTjbjsMyfJ0akajluUGjSvO5OjuTPNtu4+tnZl2NbdR1tPHy09/m1nJktnOsfWrm56+3J09+Xp6cv1f5LYFZHgQND/F3GJuQ7RyMABIuL4t65TeMzgx0XPiQbLRhyHaCRKxIlRU11Ftq8O13GCP//Tj9N/35/u9N8fHGNhnuM4uNB/3yncx7/jEKw3KK79JT+YVtzL4/jP6le8TtcZWF9hGwTLO97gdQzajhs8P5iYrE3QRW//th0H3KI4/PUUuoO2z6XwuHg7/dvtX8HgPAcmO8VP2X6fBfvaYej0wfulWPHr42yXhz8tlaqmva2nPzd3pJymwHdRU5WKf4jUVEVYNKOGRTPGtpznefTlPNLZPOlsjt5snt5snu5Mjq5Mlp5Mjr6cR18+79/mPLL5PJlsnpznkct7ZPMe2Zx/25fL+7d5j2wuTy4POc+/n/foXyYf3KbzHjnPIx/cZvPBOoP15DzIBfNyueC5nkfeAzx/voTbwMF1++nFMwYfyAv3ne2XYeBA1P+BsqhBUWhIFJZ3h6xvhwfhYEHXgUQ0wr+81wx7iveuUvGXnXIch6qoQ1XUJTmF3zI76g/1goNB4aBQeNw/H6//+9m85/mdB4Xn+isIptE/r/C4eHmGeU7RRvAYWD/e4PseQ9c5eLuFaYXv6Qrbqa2L09HRWzTNI58viqt/HzDoOQNxBs8sPC5+MmwfU9E+HbyPB/IrPB5pX+YHLzpI/+szZBuF6QDxRIyenr5B+zjvDeTA0ByH29CQ12fwPh7IflAP4HbP9Qa/3oNyHn5+8T4e+p5i0GOoijrUVu38i+DxmLr/ySITyHGCbqQROxumr0o/qWE4Ycx5ooXr+n8REQFU/EVEQknFX0QkhFT8RURCSMVfRCSESnK2jzHGBW4ADgLSwEXW2lVF8z8GfBzIAldba+8rRRwiIjK8UrX8zwAS1tq3AV8CvlmYYYyZC3wGeAdwCnCNMWaYsYlFRKRUSnWe/zHAQwDW2qeNMcUDCx0JPGmtTQNpY8wq4EDgjyOtLBJxSKXG9yMkkYg77mWnszDmHcacIZx5hzFnmNi8S1X864G2osc5Y0zUWpsdZl4H0LCjlbmuu8V1WTfeYNxRDJVaicKYdxhzhnDmHcacYcx5LxppRqmKfzuQLHrsBoV/uHlJoHUn62uauNBERKRUff5PAqcCGGOOBl4smvcH4J3GmIQxpgHYF3ipRHGIiMgwSvJjLkVn+xyIP1DdP+AfDFZZa+8Jzva5GP/g8x/W2rsmPAgRERnRtPglLxERmVi6yEtEJIRU/EVEQkjFX0QkhCr2x1x2NsREJTHGxIBbgMVAHLgaWAH8CP9HgV4CPmWt3fUf451ijDGzgWeBd+MPF/IjKj/ny4HTgSr89/jjVHDewfv7x/jv7xzwMSr8tTbGHAVca6093hjzNwyTqzHmK8Bp+Pvis9baP4xlG5Xc8j+DEYaYqEDnA1utte8E3gNcD3wLuDKY5gB/W8b4SiIoCj8AeoJJYcj5eODt+MOjHAfsRuXnfSoQtda+HfhX4N+p4JyNMV8EbgYSwaTtcjXGHIr/+h8FnAd8b6zbqeTiP2iICeDwHT99WrsDuCq47+C3BA7DbxECPAicVIa4Su064PvAxuBxGHI+Bf+6mbuBe4H7qPy8XwWiwaf5eqCPys55NXBW0ePhcj0GeNha61lrX8ffP2O6GLaSi/+wQ0yUK5hSstZ2Wms7jDFJ4E7gSsCx1hbO493pEBrTjTHmQqDZWvuroskVnXNgFn5D5hzgEuCn+FfQV3LenfhdPiuBm4DvUsGvdXDdU1/RpOFyHfMwOUNVcvHf0RATFccYsxvwGHCrtfY2oLj/czRDaEw3HwXebYz5LXAw8BNgdtH8SswZYCvwK2ttxlprgV4G/9NXYt6X4ee8BP87vB/jf99RUIk5Fxvuf3k8w+QMUsnFf0dDTFQUY8wc4GHgn6y1twSTnw/6hwHeCywvR2ylYq091lp7nLX2eODPwAXAg5Wcc+AJ4D3GGMcYMx+oBR6p8LxbGGjlbgNiVPj7e4jhcn0SOMUY4xpjdsdv3G4Zy0orshskcDd+y/D3DAwxUamuABqBq4wxhb7/ZcB3jTFVwCv43UGV7vPATZWcs7X2PmPMsfhjZLnAp4A1VHbe3wZuMcYsx2/xXwH8icrOudh272trbS7YH08x8D4YEw3vICISQpXc7SMiIiNQ8RcRCSEVfxGREFLxFxEJIRV/EZEQquRTPUXGJDiX+v/wB8UraLbWnrOL6/0RcLu19qFdWY/IRFLxFxnsUWvteeUOQqTUVPxFdiIYQmIlsA/+BYN/Z6190xjzTfwBtgBus9Z+xxizN/6IjFVAN/6IiwAfD0ZrbAA+Mdbhd0Ummoq/yGAnBMW+4P7g9vfW2kuMMZ8ErjDGPAzsARyN/3/0hDHmUfzfUrjGWvuQMeZ04JBg+WettVcHA9JdiH+FrkjZqPiLDLZdt48x5jTg0eDh7/HHjn8DWB6MtthnjHka2A8w+JfcY629J1j+Q/g/OAPwJlBT6iREdkZn+4iMzmHB7TuAl/HHWDkG+n9U5u3Aa8H0I4LpHzbGfDpYTuOoyJSilr/IYEO7fQCqgQuNMZ8DuoCPWGu3GmOON8Y8hd+//3/W2ueMMV8AfmCMuRK/z/98Bg4cIlOGBnYT2YngYHCJtXZluWMRmSjq9hERCSG1/EVEQkgtfxGREFLxFxEJIRV/EZEQUvEXEQkhFX8RkRD6/7zrIyofuzlmAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 654us/step\n",
      "MAE Train = 0.27541958173636494\n",
      "MSE Train = 0.13517066748866746\n",
      "R2  = 0.07673133381183683\n",
      "\n",
      "9/9 [==============================] - 0s 756us/step\n",
      "MAE Test = 654.9729329431012\n",
      "MSE Test = 120881848.21405849\n",
      "R2  = -1273613768.2303352\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 11ms/step - loss: 0.8516 - mse: 0.8516 - val_loss: 0.5556 - val_mse: 0.5556\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6431 - mse: 0.6431 - val_loss: 0.4785 - val_mse: 0.4785\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5231 - mse: 0.5231 - val_loss: 0.4264 - val_mse: 0.4264\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4372 - mse: 0.4372 - val_loss: 0.3883 - val_mse: 0.3883\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3786 - mse: 0.3786 - val_loss: 0.3546 - val_mse: 0.3546\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3356 - mse: 0.3356 - val_loss: 0.3305 - val_mse: 0.3305\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3024 - mse: 0.3024 - val_loss: 0.3123 - val_mse: 0.3123\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2765 - mse: 0.2765 - val_loss: 0.2985 - val_mse: 0.2985\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2571 - mse: 0.2571 - val_loss: 0.2889 - val_mse: 0.2889\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2414 - mse: 0.2414 - val_loss: 0.2818 - val_mse: 0.2818\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2279 - mse: 0.2279 - val_loss: 0.2718 - val_mse: 0.2718\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2169 - mse: 0.2169 - val_loss: 0.2639 - val_mse: 0.2639\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2077 - mse: 0.2077 - val_loss: 0.2586 - val_mse: 0.2586\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2005 - mse: 0.2005 - val_loss: 0.2545 - val_mse: 0.2545\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1941 - mse: 0.1941 - val_loss: 0.2509 - val_mse: 0.2509\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1887 - mse: 0.1887 - val_loss: 0.2475 - val_mse: 0.2475\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 0.2448 - val_mse: 0.2448\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1796 - mse: 0.1796 - val_loss: 0.2431 - val_mse: 0.2431\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1756 - mse: 0.1756 - val_loss: 0.2409 - val_mse: 0.2409\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1718 - mse: 0.1718 - val_loss: 0.2380 - val_mse: 0.2380\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1685 - mse: 0.1685 - val_loss: 0.2340 - val_mse: 0.2340\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1662 - mse: 0.1662 - val_loss: 0.2300 - val_mse: 0.2300\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1639 - mse: 0.1639 - val_loss: 0.2273 - val_mse: 0.2273\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1615 - mse: 0.1615 - val_loss: 0.2267 - val_mse: 0.2267\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1591 - mse: 0.1591 - val_loss: 0.2258 - val_mse: 0.2258\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1572 - mse: 0.1572 - val_loss: 0.2243 - val_mse: 0.2243\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1552 - mse: 0.1552 - val_loss: 0.2232 - val_mse: 0.2232\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1535 - mse: 0.1535 - val_loss: 0.2211 - val_mse: 0.2211\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1517 - mse: 0.1517 - val_loss: 0.2204 - val_mse: 0.2204\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1500 - mse: 0.1500 - val_loss: 0.2182 - val_mse: 0.2182\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1487 - mse: 0.1487 - val_loss: 0.2150 - val_mse: 0.2150\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1467 - mse: 0.1467 - val_loss: 0.2130 - val_mse: 0.2130\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1457 - mse: 0.1457 - val_loss: 0.2104 - val_mse: 0.2104\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1442 - mse: 0.1442 - val_loss: 0.2105 - val_mse: 0.2105\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1426 - mse: 0.1426 - val_loss: 0.2099 - val_mse: 0.2099\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1418 - mse: 0.1418 - val_loss: 0.2104 - val_mse: 0.2104\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1411 - mse: 0.1411 - val_loss: 0.2100 - val_mse: 0.2100\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1399 - mse: 0.1399 - val_loss: 0.2078 - val_mse: 0.2078\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1389 - mse: 0.1389 - val_loss: 0.2061 - val_mse: 0.2061\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1379 - mse: 0.1379 - val_loss: 0.2037 - val_mse: 0.2037\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1371 - mse: 0.1371 - val_loss: 0.2031 - val_mse: 0.2031\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 0.2034 - val_mse: 0.2034\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1357 - mse: 0.1357 - val_loss: 0.2030 - val_mse: 0.2030\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1350 - mse: 0.1350 - val_loss: 0.2019 - val_mse: 0.2019\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1342 - mse: 0.1342 - val_loss: 0.2013 - val_mse: 0.2013\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1337 - mse: 0.1337 - val_loss: 0.2005 - val_mse: 0.2005\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1332 - mse: 0.1332 - val_loss: 0.1995 - val_mse: 0.1995\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1327 - mse: 0.1327 - val_loss: 0.1999 - val_mse: 0.1999\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1322 - mse: 0.1322 - val_loss: 0.2007 - val_mse: 0.2007\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1317 - mse: 0.1317 - val_loss: 0.1997 - val_mse: 0.1997\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1311 - mse: 0.1311 - val_loss: 0.1982 - val_mse: 0.1982\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1307 - mse: 0.1307 - val_loss: 0.1988 - val_mse: 0.1988\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1302 - mse: 0.1302 - val_loss: 0.1997 - val_mse: 0.1997\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1298 - mse: 0.1298 - val_loss: 0.1989 - val_mse: 0.1989\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1293 - mse: 0.1293 - val_loss: 0.1953 - val_mse: 0.1953\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1288 - mse: 0.1288 - val_loss: 0.1956 - val_mse: 0.1956\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1295 - mse: 0.1295 - val_loss: 0.1952 - val_mse: 0.1952\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1283 - mse: 0.1283 - val_loss: 0.1952 - val_mse: 0.1952\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1276 - mse: 0.1276 - val_loss: 0.1952 - val_mse: 0.1952\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1273 - mse: 0.1273 - val_loss: 0.1944 - val_mse: 0.1944\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1268 - mse: 0.1268 - val_loss: 0.1935 - val_mse: 0.1935\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1269 - mse: 0.1269 - val_loss: 0.1923 - val_mse: 0.1923\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 0.1929 - val_mse: 0.1929\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1261 - mse: 0.1261 - val_loss: 0.1935 - val_mse: 0.1935\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1255 - mse: 0.1255 - val_loss: 0.1938 - val_mse: 0.1938\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1255 - mse: 0.1255 - val_loss: 0.1950 - val_mse: 0.1950\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 0.1950 - val_mse: 0.1950\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1253 - mse: 0.1253 - val_loss: 0.1957 - val_mse: 0.1957\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1252 - mse: 0.1252 - val_loss: 0.1953 - val_mse: 0.1953\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1246 - mse: 0.1246 - val_loss: 0.1941 - val_mse: 0.1941\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1243 - mse: 0.1243 - val_loss: 0.1939 - val_mse: 0.1939\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.1941 - val_mse: 0.1941\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.1939 - val_mse: 0.1939\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.1921 - val_mse: 0.1921\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1234 - mse: 0.1234 - val_loss: 0.1913 - val_mse: 0.1913\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1242 - mse: 0.1242 - val_loss: 0.1915 - val_mse: 0.1915\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1238 - mse: 0.1238 - val_loss: 0.1923 - val_mse: 0.1923\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1228 - mse: 0.1228 - val_loss: 0.1925 - val_mse: 0.1925\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1225 - mse: 0.1225 - val_loss: 0.1924 - val_mse: 0.1924\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1223 - mse: 0.1223 - val_loss: 0.1920 - val_mse: 0.1920\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 0.1918 - val_mse: 0.1918\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1221 - mse: 0.1221 - val_loss: 0.1923 - val_mse: 0.1923\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1216 - mse: 0.1216 - val_loss: 0.1934 - val_mse: 0.1934\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 0.1933 - val_mse: 0.1933\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1224 - mse: 0.1224 - val_loss: 0.1942 - val_mse: 0.1942\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1218 - mse: 0.1218 - val_loss: 0.1953 - val_mse: 0.1953\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1214 - mse: 0.1214 - val_loss: 0.1973 - val_mse: 0.1973\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1212 - mse: 0.1212 - val_loss: 0.1958 - val_mse: 0.1958\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1208 - mse: 0.1208 - val_loss: 0.1938 - val_mse: 0.1938\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1204 - mse: 0.1204 - val_loss: 0.1931 - val_mse: 0.1931\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1202 - mse: 0.1202 - val_loss: 0.1930 - val_mse: 0.1930\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1202 - mse: 0.1202 - val_loss: 0.1927 - val_mse: 0.1927\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1199 - mse: 0.1199 - val_loss: 0.1936 - val_mse: 0.1936\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1198 - mse: 0.1198 - val_loss: 0.1929 - val_mse: 0.1929\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1197 - mse: 0.1197 - val_loss: 0.1936 - val_mse: 0.1936\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 0.1926 - val_mse: 0.1926\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1193 - mse: 0.1193 - val_loss: 0.1913 - val_mse: 0.1913\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1191 - mse: 0.1191 - val_loss: 0.1917 - val_mse: 0.1917\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1189 - mse: 0.1189 - val_loss: 0.1915 - val_mse: 0.1915\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1191 - mse: 0.1191 - val_loss: 0.1927 - val_mse: 0.1927\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAESCAYAAAAVLtXjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzNUlEQVR4nO3deZwcVb3w/08tvc7Ws2XfyHZCCATCFhaVRRbZUVBcf+qDioKiuKFXUX+PXkXBFbmKK3gfH4x6ucBllUWWQARDkCXkQCAJ2TOZzN7TSy3PH9Uz6Ulmkslkepau7/v1mle6q6qrzrcz8z1V51SdY/i+jxBCiHAxR7sAQgghRp4kfyGECCFJ/kIIEUKS/IUQIoQk+QshRAhJ8hdCiBCyR7sAQpSCUupDwDVFi2qAacA0rfX20SmVEGOHIff5i3KnlIoAjwO/11r/crTLI8RYIGf+Igy+DOzoL/ErpU4BvgO8ASwCYsCVWutHlVJR4HrgbYAFrAI+o7VuV0qtBy7RWv+zsJ/1wCXATuAJ4BVgVuGzxwPfKOyjHbhGa/2MUuqbhW0mAzOBJuA9WustSqlPAlcAOSADfEJrvXo4vxQRbtLmL8qaUqoB+Dzw2X1sdjxwo9b6KOA3wDcLy68FHOBorfViYAvwvUEcdhrwv7XW8wmam34BvEtrfQRwHXCnUqq6sO1bgEu11guAFuATSikL+DFwttb6WOAW4ORBBSzEIEnyF+Xu48CdWut1+9hmg9b6+cLr54C6wuvzgAuBVUqp54GLgIWDOKYDPF14fRrwsNb6DQCt9SPADuDowvq/a63bC69XAXVaaxf4M/CUUuomoI2gUhJi2EjyF+XuPcDv9rNNd9FrHzAKry3gaq31kVrrI4HjCJp29twOIFr0Oqu1dgqv+/sbM4HIvo6ttf4AcD6wlqDZ6r/2E4MQB0SSvyhbSqlaYC7w1BB38QBwlVIqqpQygV8B3y2sawKOKRxnKUG7fX8eAc5USs0ubHsaMB34xz7K3aCU2gg0a61/DHwNWDzEGITolyR/Uc7mAlu11vkhfv5/A+sJmmNWE5yVf76w7svA1YXmoI8BK/vbQaGT9lPAfymlXiLoMzhfa9020EG11juBbwMPK6VWFj5z+RBjEKJfcqunEEKEkJz5CyFECEnyF0KIEJLkL4QQISTJXwghQmhcDO/geZ7vukPrmLYsg6F+djwLY9xhjBnCGXcYY4YDjzsSsXYCjf2tGxfJ33V9WlvTQ/psKpUc8mfHszDGHcaYIZxxhzFmOPC4GxurNgy0Tpp9hBAihCT5CyFECEnyF0KIEBoXbf5CiPByXYeWliYcJ9e7bPt2gzCOTjBQ3LYdpba2EcsafEqX5C+EGNNaWpqIx5NUVEzCMIKBVC3LxHW9US7ZyOsvbt/36epqp6WliYaGgcYX3Js0+wghxjTHyVFRUd2b+EVfhmFQUVHd58poMCT5CyHGPEn8+zaU76esk/+udI4HXt422sUQQogxp6yT/9/WNHHV7c/TmXX2v7EQQoRIWSf/mB2EJ8lfCCH6Kuu7fSpiQXhdOXeUSyKEGA73vLydu17ahmHAcN3pecGiSZx72MR9bnPvvXezfPnjZLNZmpt3cuml7+WJJx5j3brXufLKq3niicfYtGkj2WyWSy+9jLPPPpdVq1Zyyy03Y1kWU6ZM5Utf+jdse+yk3LFTkhKoiFqAJH8hxMFLp9P86Ec/56GHHuBPf/ojt9zye1atWsmtt/6GrVu38Mtf/h7DMHjmmRX4vs/113+H//iPX1NbW8evfvUf3Hvv3VxwwcWjHUavkCR/afYRohyce9hEzj1s4qjc5z9vngKgsrKKWbMOwTAMqqqqsCybz3zm83z/+98hne7izDPfQWtrC83NO/n6168FIJvNcuyxx49oefenvJN/T7NPVs78hRAHZ+DbKX20foXvfvcGstks73rXuZx55juYMGEC3/veD6msrOTJJx8jkUiOaHn3p6yTf6Wc+QshRsCuXc1cccVHMU2Tyy77AJFIhKuv/gJf/OLV+L5PMlnB17/+rdEuZh9lnfwrotLhK4Q4eOecc37v66VLT2Tp0hOBoCnohz+8qd/PHHfcUo47bumIlG8oyvpWz2TPmb80+wghRB9lnfwt0yAZteiUZh8hhOijrJM/QGXMlmYfIYTYQ0na/JVSJnAzsBjIApdrrdcWrf888D7AA/5da31HKcoBheQvzT5CCNFHqc78LwLiWusTgGuBG3tWKKVSwNXACcCZwI9LVAag58xfmn2EEKJYqZL/ycD9AFrrFcAxReu6gA1AReGnpE9qSLOPEELsrVS3elYDbUXvXaWUrbXuOQXfCKwGLOC7+9uZZRmkUkN7QKIybrOzMzvkz49XlmVKzCFR7nFv325gWXufp/a3LAwGitswDixPlir5twNVRe/NosT/DmAycEjh/QNKqeVa62cG2pnr+rS2podUkIqYRXt3fsifH69SqaTEHBLlHrfv+3sN5TBWp3G86qqP88UvfpWZM2eVZP/7itv3986TjY1V/W4LpUv+y4HzgWVKqaXAi0XrWoBuIKu19pVSrUCqROWQZh8hykhszV+Iv3I7hjF8E7hnDr2M7IJLhmVf40mpkv8dwBlKqacAA/iIUuoaYK3W+i6l1NuBFUopD3gS+FuJytHb4ev7vkwFJ4QYkq9+9YtceullHHXU0axZs5qf//wnpFK1dHZ2sHNnE+9857u5+OL9VyAf+tB7WLx4Ca+//hozZ86itraOf/1rFZFIhBtu+CmrV7/ETTf9GNu2icfjfPvb1xONxvjBD/6dTZs24vs+l19+BUuWHLPfY+1PSZK/1toDrthj8Zqi9d8AvlGKY++pMmbj+ZBxPBIRayQOKYQokeyCS8guuGTEm33OP/8i7rvvfzjqqKO55567WbLkGGbPnsPb3nYaO3c2cdVVHx9U8k+n05xxxll8/vNf5n3vexef/vTn+PjHP8VVV32cdete54knHuO0097Ou9/9Pp588nHa2zt4+un7qKlJ8ZWvXEdnZztXXHE5//mfyw46prIe2weC5A/QlXUk+QshhuT440/g5pt/Qnt7Gy+8sIobbvgpv/jFTTz22KMkkxU4zuBvJ1dqAdAzNPRsAKqqqshmc3zwgx/httt+y9VXf5LGxgksXLiI119fywsvrGL16pcwDAPXdWhtbSWVSh1UTKFJ/p05l4ZRLosQYnwyTZNTT307N9zwPd7yllO4/fb/ZNGiI7j44kt47rl/8vTTTx7A3gZufn7wwXs555zzuOqqz/KHP/yOu+76L2bOnMWECRP40Ic+Sj6f43e/+zXV1dUHHVP5J/+4jOwphDh45557Ae9+94XcfvsdbN26hR/96Ps8/PCDVFZWYlkWuVzuoI9x6KGL+N73vk0ikcAwDL70pX+joaGR66//Nldd9XG6urq4+OJLMM2Dv83VGK4e81LK511/qLeyvdqa4f2/eYafX3I4x82sHeaSjV3lfvtff8IYM5R/3Nu2bWDSpJl9lo3VWz1LbV9x9/c9NTZWraTvQ7a9yv/MXyZxF0KMoNWrX+Lmm3+61/LTTz9zUJ3CIyVEyV/G9xFivBpPt2ovXLiIm266ZUSPOZQWnLJ/PrpS5vEVYlyz7ShdXe3D9lBXufF9n66udmw7ekCfK/sz/wpp9hFiXKutbaSlpYnOztbeZcP5hO94MlDcth2ltrbxgPZV9sk/ZptELUOSvxDjlGXZNDRM7rOs3Du5BzKccZd9sw8EE7lLm78QQuwWjuQfs+TMXwghioQj+UdturJy5i+EED1CkvzlzF8IIYpJ8hdCiBAKR/KXSdyFEKKPcCT/qCUPeQkhRJGQJH858xdCiGKhSP6VMYuc65NzwjcKoBBC9CcUyb8iGszglZZOXyGEAEo0vINSygRuBhYDWeByrfXawrojgR8Xbb4UuEhrfX8pygJBsw9AZ84hlYyU6jBCCDFulGpsn4uAuNb6BKXUUuBG4EIArfXzwCkASqlLgc2lTPyw+8xfbvcUQohAqZp9TgbuB9Bar6CfmWSUUhXAt4CrS1SGXhWxnuQvnb5CCAGlO/OvBtqK3rtKKVtrXZx9/xfwZ631zv3tzLIMUqnkkApiWSaT6iuDNxF7yPsZbyzLDE2sPcIYM4Qz7jDGDMMbd6mSfztQVfTe3CPxA7wfGNScZq7rD3kY01QqiZfNA7BjVzo0w8CGccjbMMYM4Yw7jDHDgcfd2Fg14LpSNfssB84BKLT5v1i8UilVA8S01htLdPw+KmQqRyGE6KNUZ/53AGcopZ4CDOAjSqlrgLVa67uA+cD6Eh17L5U9Hb7ylK8QQgAlSv5aaw+4Yo/Fa4rWP0twR9CIiNkmliFn/kII0SMUD3kZhlEY3E3O/IUQAkKS/CG4179Tkr8QQgChSv4ym5cQQvQIUfKXCV2EEKJHeJK/TOIuhBC9wpP8pdlHCCF6hSj5y5m/EEL0CFHyl9m8hBCiR3iSf8yiO+/hev5oF0UIIUZdeJK/zOYlhBC9QpP8KwuDu7UXRvgUQogwC03yrytM39iSluQvhBChSf4NFVEAdnbmRrkkQggx+kKT/OsLyb85LclfCCFCk/xrExEMoLlLkr8QQoQm+duWSSoRYackfyGECE/yB2iojNLcJR2+QggRquRfn4xKs48QQhC25F8RkeQvhBCUaA5fpZQJ3AwsBrLA5VrrtUXr3wF8g2By95XAlVrrko+7UF8Rozmdw/d9DMMo9eGEEGLMKtWZ/0VAXGt9AnAtcGPPCqVUFfAD4Dyt9fHAeqChROXoo74iQt71ac/IAG9CiHArVfI/GbgfQGu9AjimaN2JwIvAjUqpJ4DtWuumEpWjjwa5118IIYASNfsA1UBb0XtXKWVrrR2Cs/xTgSOBTuAJpdTTWutXB9qZZRmkUskhFcSyzN7PzpxYDUAGc8j7Gy+K4w6LMMYM4Yw7jDHD8MZdquTfDlQVvTcLiR+gGXhWa70NQCn1OEFFMGDyd12f1tb0kAqSSiV7PxvzPQA27GhnYX1iSPsbL4rjDoswxgzhjDuMMcOBx93YWDXgulI1+ywHzgFQSi0laObp8RywSCnVoJSygaXA6hKVo4/eZh+5118IEXKlOvO/AzhDKfUUwR09H1FKXQOs1VrfpZT6CvBAYdtlWuuXSlSOPiqiFjHblMHdhBChV5Lkr7X2gCv2WLymaP3twO2lOPa+GIZBfUVUOnyFEKEXqoe8QJ7yFUIICGPyr5DB3YQQInTJv6Eiyi5J/kKIkAtd8q+viNKWccg53mgXRQghRk0okz/ALun0FUKEWGiTv3T6CiHCrKyTv9m2AXPFTeDvHjC0dyJ3edBLCBFiZZ38o5uewHr4Osyurb3LZCJ3IYQo8+TvVs8CwGpd17usLhkBoFme8hVChFh5J//UbKBv8o8UJnKXM38hRJiVdfL3Kifh2wms1jf6LJfpHIUQYVfWyR/DhLrZWG17JP9kVJ7yFUKEWnknf8Cvm93Pmb+M7yOECLcQJP+5WO1vgrv71s6GQvL3/ZLPGS+EEGNSCJL/HAzPwerY2LusviJKzvXpzLqjWDIhhBg9ZZ/8qZ8D9L3jp773QS9p+hFChFPZJ3+/bi4AVtvu5D+pKgbA1vbMqJRJCCFGW9knfxJ1eLGaPp2+U1NxADa3SfIXQoRT+Sd/w8BN9b3jp74iSsw22dwqyV8IEU6DmsNXKWUBHwZmAo8AL2mtd+5jexO4GVgMZIHLtdZri9b/BDgZ6CgsulBr3TaUAAbDTc0msvnp3vemYTClOs7mtu5SHVIIIca0wU7g/ktgC3AG8CxwG3DOPra/CIhrrU9QSi0FbgQuLFp/NHDWviqQ4eTWHEJc/xXy3RBJAEHTjzT7CCHCarDNPnO01tcB3Vrru4Ga/Wx/MnA/gNZ6BXBMz4rCVcE84Bal1HKl1EcPvNgHpneMn6JO36k1cba0ZeRefyFEKA32zN9WSjUAKKWqgP3NgVgNFDfjuEopW2vtABXAz4AfAhbwqFLqn1rrFwbamWUZpFLJQRZ1z8+aJKYvDAqV34yfCuqhOZOq6Vq1BT8aobZw62c5sSxzyN/ZeBXGmCGccYcxZhjeuAeb/L8GLAcmAyuAz+5n+3agqui9WUj8AGngJ1rrNIBS6hGCvoEBk7/r+rS2pgdZ1L5SqSSt5mQagcwWTffkYD91UQuAV97cxWGTq4e077EslUoO+Tsbr8IYM4Qz7jDGDAced2Nj1YDrBtXso7V+TGutgDnAYq313/bzkeUU+gQKbf4vFq2bDyxXSllKqQhBE9FzgynHkEUrcCsmYsvtnkIIAQz+bp/3Ay4QA76vlPqB1vqGfXzkDuAMpdRTgAF8RCl1DbBWa32XUuoPBFcQeeA2rfXLBxXFIOx5u+fUGkn+QojwGmyzz9XAO4DbgRnAg8CAyV9r7QFX7LF4TdH6HwA/OKCSHiS3ZjaxN+7rfZ+IWNQlI5L8hRChNNi7fXoyZIfWOsvgK40xw03Nxszswsi09C6bWpOQ5C+ECKXBJv+1BM00v1FKXQf8q3RFKg2n4VAA7KaXepdNTcXZ0ioPegkhwmewyf+/gQ3AlcCJwCGlKlCpOBOOxMcgsn133/LUmjjbOrI47v7uXBVCiPIy2OabHwAfB1pLV5TS8mPVuLXzsLf1Tf6eD9s6skxLJUaxdEIIMbIGm/xf1lo/VtKSjID8pKOIrXsQfB8MY/ftnq0ZSf5CiFAZbPK/Uyn1NPBKzwKtdcmHZRhuzsQlJF75E2bberzUIUytCRJ+MMBb7egWTgghRtBgk/9ngO8zjpt9APKTlgAQ2f4c2dQhNFZGiViG3PEjhAidwSb/bVrrP5W0JCPArZ2PF6kIkr96V9HQzpL8hRDhMtjk362Uuh9YBfgAWuuvlqxUpWJaOBMWY29/vnfR1FRcJnURQoTOYJP/3SUtxQhyJi4h8fwvwOkGO8HUmgQvbunY/weFEKKMDCr5a61vLXVBRkp+0hKSnoPd9BLO5GOZWhOnI+vQnslTHY+MdvGEEGJElP8cvnvITzwKgEjhfv+eAd42SdOPECJEQpf8/WQjbvWM3id9Z9YFEyOsaw7f2OBCiPAKXfKH4OzfLiT/GbUJ4rbJmh2do1wqIYQYOaFM/s7EJVidWzE7t2CZBvMnVKK3S6evECI8Qpn8c1NPACD65uMAqAmVvNrUhSeTuQshQiKUyd+tPxS3cgrRDQ8BsGBCJV05Vzp9hRChEcrkj2GQm/X24MzfyaAmVgKwRpp+hBAhEc7kD+Rmno7hpIlsWcHs+iQRy0BLp68QIiRKMh2jUsoEbgYWA1ngcq312n62uQe4U2v9i1KUY19y007CtxPE1v+N/IxTmNtQwZrtkvyFEOFQqjP/i4C41voE4Frgxn62+TajOY6yHSc37S1E1z0Evh/c8bOjE186fYUQIVCq5H8ycD+A1noFcEzxSqXUJYDXs81oyR3ydqzOzVi71rBgQiVtGYftHdnRLJIQQoyIkjT7ANVAW9F7Vylla60dpdQi4H3AJcB1g9mZZRmkUskhFcSyzIE/e/h58OiXqNn2GMfM+Sg8vJaNnXkWzKgb0rHGkn3GXabCGDOEM+4wxgzDG3epkn87UFX03tRaO4XXHwKmAo8As4CcUmq91nrAqwDX9WltHdrwC6lUch+frSY1YTGsuY9J8z+GZcDKdc0cO6VqgO3Hj33HXZ7CGDOEM+4wxgwHHndj48C5rFTJfzlwPrBMKbUUeLFnhdb6Sz2vlVLfJJgoZtSaf3IzTyf57I9I5FuYVZ+UO36EEKFQqjb/O4CMUuop4EfA55RS1yilLijR8YYsd8iZGPjE1j+IKnT6CiFEuSvJmb/W2gOu2GPxmn62+2Ypjn8gnIbDcGpmEXvtbtS0t3Lv6h3s7MrRUBEd7aIJIUTJhPYhr16GQXbuBUQ2L+eIVHCnj5b7/YUQZU6SP5Cdex6G77G48wls0+C5Ta2jXSQhhCgpSf4EA705tXOpXHcPR0yp5pkNraNdJCGEKClJ/lBo+jmfyOYVnDrFQe/opLU7P9qlEkKIkpHkX5Cdez4GPmfyD3xg5cbW0S6SEEKUjCT/ArduPk6d4pAdf6MiaknTjxCirEnyL5KddwHRbc/y9il5nnmzZbSLI4QQJSPJv0hmbvAM2vvtR9nUmmFzW/col0gIIUpDkn8RL3UI2UPOYsmOv1BBN89K048QokxJ8t9DesmV2Lk2Lk88xrNvto52cYQQoiQk+e/BmbSE3NST+Ih5D89vaMKTyV2EEGVIkn8/0kdfRcpt5rT8I6xt6hrt4gghxLCT5N+P/LST6a4/nCusu3nqjR2jXRwhhBh2kvz7Yxjkjv00s8zt+C//dbRLI4QQw06S/wBys89mW8VCPtL9OzZu3TraxRFCiGElyX8ghkn61O9RRwc89u3RLo0QQgwrSf77UDVzCfckL2JJ851YW54d7eIIIcSwkeS/H01HXs1mv57Yw18CV0b6FEKUB0n++/HWBTP5pvNhKtpfI/nsD0e7OEIIMSxKMoevUsoEbgYWA1ngcq312qL1VwIfBnzgBq31slKUYzikkhE6p7+du3Y8zwUrf4Zbv5DsvPNHu1hCCHFQSnXmfxEQ11qfAFwL3NizQinVAHwSOBE4HbhRKWWUqBzD4swFjXwh/SHa6o6i6pHPYTe9ONpFEkKIg1Kq5H8ycD+A1noFcEzPCq31TuBIrXUemARktNZjegyFU+Y2YNgxbkj9G168jup7P4rZtX20iyWEEENWkmYfoBpoK3rvKqVsrbUDoLV2lFJXAd8Cfrq/nVmWQSqVHFJBLMsc8md7pIALF0/hzy9s4XMfuo3aZRdQd+elOO/+IzTMP6h9l8pwxD3ehDFmCGfcYYwZhjfuUiX/dqCq6L3Zk/h7aK1vUkrdAtynlDpVa/3oQDtzXZ/W1vSQCpJKJYf82WLvXDSRZSs38Wud5GPn/5Ga+/4X1u/OpP3sX5Cf/taD3v9wG664x5MwxgzhjDuMMcOBx93YWDXgulI1+ywHzgFQSi0FehvJVeC/Cu38eYIOYa9E5Rg2cxoqOH5mimWrttA9YQktl9yDVzWFmrs/SOK5n4Pn7H8nQggxRpQq+d8BZJRSTwE/Aj6nlLpGKXWB1loD/wKeBp4CVmitHytROYbVe4+exs6uHH/TTXjV02h953+Tm30WlU9/l9pl52BvXzXaRRRCiEEx/HEwXn0+7/qj3ewD4Pk+7/n9P4nbFrd94CgMwwDfJ7rufiof/xpm1w66l3ySrqXXgjG6j1CE8bI4jDFDOOMOY8wwpGaflRTdcFNMHvI6AKZh8N4lU1mzo5PnN7cHCw2D3Ox30PK+v5NZ+F6Sz91M9QOfBCczuoUVQoh9kOR/gM5ZOJFUIsIvn1pP8VWTH62i85Tr6TzpOmKv30PqrvdiZFpGsaRCCDEwSf4HKB6x+MSJM1m5sY2HX93Zd6Vh0H3kx2k76xfYO16gdtk5RLb8Y3QKKoQQ+yDJfwguPmIy8xor+PFjb5DJu3utz809j9aLloFhUnPHJVQ8/e/gZkehpEII0T9J/kNgmQZfOG0O2zuy3PrMxn63cSYdza73PNjbD1B7+xnEV98ulYAQYkyQ5D9ES6alOGtBI7c9u5HNbd39bxStoPPU79N27q34doKqR79A3W0nkvznzzA7t4xsgYUQoogk/4Pw6bfOxjQMvvfQWrx93DKbm3U6re++n9YL/ohbN5+Kf1xP3a3HU/Pf7ya++naM7l0jWGohhJDkf1AmVsX4zNtms2J9C7c/t3nfGxsG+elvpe3C/0vzB54kfeznsDo2U/XoF6j/3ZHU3HEJiX/9GrNtw8gUXggRaqUa2yc0Llk8mX+sb+Fnj69jybQaFkwceCyNHl7NLNLHXUP62GB46Oi6B4i9cT+VT36Tyie/iVM7j9zM08hPPYH8pKPx47UjEIkQIkzkCd9h0Nqd5/23rSQesfjDB5aQjFpD2o/Ztp7Y+oeIrn+YyJYVGF4wbaRTOw+3bj5OajZuag5Ow0Lc2nlgRQbcVxifgAxjzBDOuMMYMwzvE75y5j8MUokI33rHAj715xe4/uHX+ObZKhj64QB5NbPoXnw53Ysvh3w3kR3PE9n6LPb257B2rib6xv0YfnBrqW9GcRoOJT/5OPLTTiY/5Tj86P6vOoQQAiT5D5tjZqT42IkzueWpDcyur+D/O276we0wkgiafaaesHuZm8dqW4+982Xsphexm14g8dJtJP/1K3zDIj/tZDLzLyY3+ywgfGOdCyEGT5L/MLp86QzWN6e56Yl1TK9NcNq8huE9gBXBrZuHWzeP7PyLgmVOhsi2lUQ3Pk5s7d1UP/xZ/L/H8OedRXTWeeRmngZ2fHjLIYQY9yT5DyPDMLjubMXW9gzX3buGyZct5tBBdAAfFDtOftpJ5KedRNfSa7G3P0f81TuIv3EPNWvuwotWkZ/+lqB5aMrxOKk5YCdgCM1SQojyIR2+JdDclePD/2cVWcfjpksOZ/6EyhE9PkCqOkrXyw8Re+1OopuWY3Vs6l3nGyZ+pBI/Vo0Xr8WP1+IlG3GrZ+BWz8CrmoZXMRG3YhJExk/zkXQChkcYY4bh7fCV5F8iG3al+dSfXyDjePzsXYezcNLIdsbuGbfZsYXI1n9gdm7ByHVh5Dowc+0YmRbMTAtm13bMzq0Y9P198OK1OPULC3cYzcWL1eBHq/DjKZza+RBJjGhc+yIJITzCGDPI3T7jwsy6JLdctphPLXuBT/35BX7yzkUsnlozauXxqqaQrbp43xu5WayOzZgdmzHT2zG7tmO1bcDeuZrEy3/A2GOOAt8wcWvn4TQeTm76yeRmnIqfqC9hFEKI4SLJv4Sm1iT45XsWc+VfXuTKv7zIv505j3ccOnG0izUwK4abmo2bmr33Os/F7NqGkevAyHVipncEdx3tfJnom48S13/Bx8CZcARO4xE49Qtw6g/FaVw0rpqOhAgLSf4lNqk6zq8uW8y1d7/Cdfdq1mzv5NNvnY1tjrMOV9PCq5raZ1FuzjnBC98LnlTe8CiRTU8Qe+1OEi//IVhlWDgNC3EmLik8h+ADPr4Vx49W4kcqwHcx8mmMfBdg4NtxfDuBVzERp/FwvKpp0kEtxDArSfJXSpnAzcBiIAtcrrVeW7T+c8Blhbf3aq2/VYpyjBV1ySg3X3I4P/r7G/xx5Wb0jk6+duZ8pqXGTnv5QTFMnAmLcSYshmM/C76P2bUVe+cr2NufI7L1n8T0XzHcDD3DSRlebtC792I1OPULgquSmtm4dfPJTzxSmpiEOAilOvO/CIhrrU9QSi0FbgQuBFBKzQbeDxwPeMCTSqk7tNYvlKgsY4JtmXzx9LkcOqmSGx55nctuXcnlS2fwgWOmYVtlNr6eYeBVTiFXOYXcrNP738ZzMfJdGPlOfMMOrgAiCfB9cLMYTjdW+5vYTS8FD7S1vEZs3YOY3c29u3CrZ+LUzS9cQVRiJpNUdncHn/c9fCsWXEVEKvASDXgVE/CSE/Cj1UGndawqOK5RZt+/EINQquR/MnA/gNZ6hVKquLd5I3C21toFUEpFgNDMdn7eYZM4bkYtP3hkLT9/cj33r9nB506Zw/EzQzZ4m2nhx6rxY9V9lxuAmcSPJHES9TgTj+q7OtOKvWsN9vbng5/WNwqVSBeGlyVmRPCtKBgmhpsFJ4PhdGP4Xr/F8A2zUBHU4MXr8JKNeIUrCsPJYLgZjGwHRrYNM9uGb0XxE/V4iXrcikl41TNwq6fjRyqDMjhpjGw7ZmYXRvcuDDeHH6/Bi9XgVU4lN+NtMlCfGBNKcqunUurXwF+11vcV3r8JzNZaO0XbGMAPgCqt9Sf2tT/P83zXHVo5LcvEdfv/wx9tD72yne/ct4ZNLd2cqhr58lmKOY3D80zAWI67VAaM2XMh3Qyd2zG6dkC2HbIdGNl2yLRBth0j0wrpnRidTZDeGfQx2HGwY0EFFU8FP24W0s3Bftq3YOQ6ByyPH68BKwqZNgw3aObyDQt/5kn4M04KrjjcXFC+SLxwvMLT2H7QN7KbgR+vhkQdJOrwk/WQrINoFZZtDe7/2vfBd6G7Fdo3Y7Rvhkxr0feUL3wn7UGcVgzsGESS+FWToWoyfuWkYJkZAdMGzwEvH8RgmMFgg1YMYlUl7acZ9O+37wXxppswOncEvwOdWzF2vgpNr2Dseh1i1fg1MyA1A79uLv6EhfgTFkLVFDCHNkhjqRzo33UkYo3sff5KqR8CK7TWywrvN2mtpxWtjwO/BTqAT/VcBQxkPN7nP1hZx2PZqs38ZsWbdOddzlCNfPj4GcxtqDio/Y71uEthxGP2fYxsK1b7mxhON36kImhiilQGZ/c9o676PjgZ7F1riK57kNgbD2C3vLp7N4Y54JXJfotgRqGyEScRNGkBwRVIrmP3FVGuK7hN18vv9RxHv/vECBK8mxtyubxoVeHOsTlBc1u8Dj9eG8Tq5cHNY+S7MDMtGNk2DKcbfA/DcwAfDAvfsIIrRCsKViz417TxzQjxWIRsZ1vhSqsDs7sJM70TM9taKIER7C/b1jsYYp/yJRpx6ubj1s7ByHVidWzCbH8Tq2vbXnH4sRp8KxZUboYZlM2K4lsxDC9feFZmF4abL2xfBWYkOHa2LVieqMNLTgi+i8opuJVT8ComYri54P/GzQb7NoPGGDO9s/fuus4Tv4aXOgQYH/f5LwfOB5YV2vxf7FlROOO/E3hEa319iY4/bsRskw8eO53zDpvIH57dxF//tZUH1jTx1jn1vHfJVI6eXjOkEULFCDAM/Hgtzv6acQwDIgmciUfhTDyK9NIvg9MNhh38sRtGkAzdDDgZwCgkmaL/d9/DzLYVEk0rRmYXZnczZnczcacFv2UzVtv6YNPCQ3he1bSgIopWgB3HNyNgRvCjVbhVU/Aqp+DFa4PjQZDUivtBfB88ByPfidm1DbNzG2a6KbiK8fIYvhskaCsSxOI7wfZOBqt9I1br60S2rMBM7xywg9+3YnixFH4kUfgurN54eysDNxsc080FFUehgohHKvAjSfxoFV6iHqf+0KDSNYLEj2EG+07U4SXqC8l3YtDvs2dzY89/VbYda5fGbtaY6e29zX24uaCy992gv8rLgpvDt5JBs1+8Ft+MYuTaMXMd4DnBE/SxGjAjmN3NGOkmrI4tRLb+s6iS6p9v2njJCbhV0wdVYQ9Fqc78e+72OYLgN+sjwDnAWsAC/i+wougjX9FaPz3Q/sr5zH9Pbd15lq3awp9WbaYt4zCnIcm7j5zCmQsmUBkbfF093uIeDmGMGcZB3L4P+TRmpgXwwYrgmxH8SDIYZ2oIxnzM+5PrwuxuAiuKbyeCKwvfx/Ad8D38WE2/NyLI8A4HYLz+kmTyLg/qJpat2oLe0UnMNjllbj3nHjaRY2fU7vc5gfEa98EIY8wQzrjDGDOMj2YfcZDiEYsLFk3i/MMm8vK2Dv7n5e38TTfxwJom6pIRzlwwgbMXNLJwUpU0CwkhDpgk/zHOMAwWTa5m0eRqrjllDk++0cx9r+zgr//awu3PbWZKTZzT5zVwumpk4cRKqQiEEIMiyX8cidomp81v5LT5jXRkHB59bScPvdrEH5/bzB/+uYnGyignzqrjpNl1nHLYJKQaEEIMRJL/OFUVt7ng8ElccPgk2rrzPPFGM8vf2MVDrzZx50vb4K7VTK6OcejEKhZMrGTBxEoOnVBFKjnwpO9CiPCQ5F8GahIRzjtsEucdNgnH9Xhhazuvt2Z5bt0uXtnewSOv7ezddkp1jMMmV7NochWLJlczv7GCeGRsPcgihCg9Sf5lxrZMlkxLcdqiJK2LguGj2zN59I5O1mzv5OVtHbywpZ2/6SYALNNgbkMFCyZUMrshySH1SWbXVzChMir9B0KUMUn+IVAdj3DsjFqOnbH7YaSmziwvb+1g9fYOXt7aweOvNwfNRQWVMYvZ9RXMrk8ysy7JzNoEM+uSTKmJj7/hqIUQe5HkH1KNlTFOmRfjlHkNvcta0jneaE7z+s40bzR38UZzmr+vbaa1e3elYJsG01JxZtYmmVmXYEZtgum1CaZUx2mojEnFIMQ4Iclf9KpNRjk6GeXo6ak+y9u682xo6WbDrvTuf3d1s3zdLhxv90OCpgETKmPMbkgyt6GSuY1JJlTGqEtGqUtGqI7b0pQkxBghyV/sV00iwhGJCEdM6TseiuP5bGvPsLG1m23tWbZ1ZNnSluH1nV08s2FTn4oBIBExmVwdZ0pNnKk1caangquGhoooNYkINXFbOp+FGCGS/MWQBU1AiX5nJHNcjzdbu9nZmaMlnac5nWNbe5at7Rk2t2VYubGV7vzeI0ZGLYOqeISqmEVtIkJDZYzGyigNFdHgCqIiQl0iSm0yQm0yQqTcJsIRYoRI8hclYVtmocO4/6Gpfd+nOZ1nU0s3u9I5WjMObd15OjIOHdngpyWdZ832Dh5/PUfW6X9o4YqoRU3cpjoeoa4qRtw0qIhaVMZsquI21TGb6oRNZdQOlsVsquM2NYkIMVsqDhFekvzFqDAMg4aK4Ix+f3zfpyvnsiudpyWdozmdpzWdo6U7T0s6T0fWoa3bIZ1z2ZrO0ZV16My6pPP7nCaCmG2SjFgkIibxiEUiYhGPmMTt4HVF1CIZ3b0+HrFIRkwSkZ7lFpVRu3ebmG0Rs00iliF9G2LMk+QvxjzDMKiMBWfuM2oHHgJ4zxEPHdcLKoaM01shtGcdOjJ52jIO7RmH7rxLd94lnXPJOB7ZvEtzV450YVk6F6w/kLFvTQPidqEi6alc7OKKxSQWsUjYQUUSsQy6ci7tGYeM41GXjDCxKsaEyhjVcbsQu0XUMolYQeXSsz+5u0oMlSR/UbZsy6Q2GaU2uf+ri33xfZ+c69Odd8nk3T4VQzrn0pVzyTguWccj63hk8kFFElQsfZftSufI5L3eSifjeOQcr9AkZRGzLZ7bmKMt4+y/YIBlgGka9IzMHo+YVMdsquIRokX9ITHboCJqU1GoRHoYBliGgWUGP73LMTCNoOK1TQpXOzYV0aCy6qmEIqZJxDawTRPLCHZoGoUZI30fn6AirIwFTXEZx6OtO09bJo/vB6PXxm2TqpgtfTgjTJK/EPthGAYx2wj6CBLDPzaS7/t7NRNl8i5NnTnasw6dGYfOnEPO9ci7Pnm3p0LxyDgu0ahNJuv0fq690G+SL8z16vuQdz22tGfoyjpkXb930D/P9/F8cDwPr6hbxSskbt/3cbxgm5FQGbOoitlELZOoHVzp2KaBbQaViuv5OB5YtoEFRCyTmGX2XmXZpkFnNriq68q5vZWiYUAyYlERC5rzeproorZJpFDx2aZB1DKJ2cG+gn+D9xHT7K0gDXbPrmwZBlE72MY2DQwjmL3KMAwsw8A0d29jjrGmQEn+Qoyy/voH4hGL6fto4ipW6olNfN8n63h0FZrA8q5fqIg8HNcn7wWVku/vrkyCq4bgCqI779KZdejMucRsk5pCh7tpBHNYd+e9Qgd/jl1debpyDjnXJ+d45FwPx/N7f2zTIGob2LZFOuvQkXHY6QSVYHfew3E9quJBx35lzKbnYsbzoTPnsL0jG1Skjtd71TVS01n1XCkZhe/GLFQQtmX0ufoyjaC8juthmQbfPX8hakLlsJdHkr8QYp8Mw+jt8B4rhqvC8wuVlVuoXHKFiiRT1ISXdTzyno9X2KaHAbiFijFX2Ca40gj26fk+rhf85F2fbKHC7KkkfT/4fE/F5hW29Xy/tyJIRizqSjQSryR/IURoBc0zwQCHUSAZtYBwDHtekuRfNIH7YiALXK61XrvHNo3AcuAIrXWmFOUQQgjRv1J1rV8ExLXWJwDXAjcWr1RKnQU8CEwq0fGFEELsQ6mS/8nA/QBa6xXsPXu8B7wd2FWi4wshhNiHUrX5VwNtRe9dpZSttXYAtNZ/A1BKDWpnlmWQSiWHVBDLMof82fEsjHGHMWYIZ9xhjBmGN+5SJf92oKrovdmT+IfCdf0h9+yX+ja4sSqMcYcxZghn3GGMGQ487sbGqgHXlarZZzlwDoBSainwYomOI4QQYghKdeZ/B3CGUuopgtthP6KUugZYq7W+q0THFEIIMUglSf5aaw+4Yo/Fa/rZblYpji+EEGLfDN8fqYebD0oTsGG0CyGEEOPMTKCxvxXjJfkLIYQYRjJ+qhBChJAkfyGECCFJ/kIIEUKS/IUQIoQk+QshRAhJ8hdCiBAq28lcBjOnQLlQSkWA3wKzgBjwbWA18HuC6UZfAq4sPHxXVpRSE4CVwBmAQzhi/gpwARAl+B1/jDKOu/D7fSvB77cLfIwy/79WSh0PXK+1PkUpNZd+YlVKfQM4l+C7+KzW+pkDOUY5n/lfxD7mFCgzHwCatdZvAc4GbgJ+CHytsMwALhzF8pVEISn8EuguLApDzKcAJwInAW8DplP+cZ8D2FrrE4H/H/gOZRyzUupLwK+BeGHRXrEqpZYQ/P8fD1wG/PxAj1POyX9/cwqUkz8DXy+8NgjOBI4mOCMEuI9g/oRycwPwC2BL4X0YYj6LYKDEO4C7gf+h/ON+FbALV/PVQJ7yjvl14J1F7/uL9WTgQa21r7V+k+D76fdJ3oGUc/Lvd06B0SpMKWmtO7XWHUqpKuAvwNcAQ2vd8/h2B1AzagUsAaXUh4EmrfUDRYvLOuaCBoITmUsJxs/6PwRDppdz3J0ETT5rgF8BP6WM/6+11n8lqOB69BfrnvntgL+Dck7+wzqnwFinlJoOPAr8QWv9R4LZ0npUAa2jUa4S+ijByLF/B44EbgMmFK0vx5gBmoEHtNY5rbUGMvT9oy/HuD9HEPN8gj68Wwn6O3qUY8zF+vtb3jO/HfB3UM7JPzRzCiilJhLMifxlrfVvC4tXFdqHAd4BPDEaZSsVrfVbtdZv01qfAjwPfAi4r5xjLngSOFspZSilpgAVwMNlHncLu89ydwERyvz3ew/9xbocOEspZSqlZhCc3O48kJ2WZTNIwV5zCoxyeUrpq0At8HWlVE/b/9XAT5VSUeAVguagcvd54FflHLPW+n+UUm8FniE4ebsSWEd5x/0j4LdKqScIzvi/CvyT8o652F6/11prt/B9PM3u34MDIqN6CiFECJVzs48QQogBSPIXQogQkuQvhBAhJMlfCCFCSJK/EEKEUDnf6inEASncS72MYFC8Hk1a60sPcr+/B27XWt9/MPsRYjhJ8heir0e01peNdiGEKDVJ/kLsR2EIiTXAAoIHBt+jtd6mlLqRYIAtgD9qrX+ilJpHMCJjFEgTjLgI8InCaI01wCcPdPhdIYabJH8h+jqtkOx73FP49ymt9RVKqU8BX1VKPQgcAiwl+Dt6Uin1CMFcCt/VWt+vlLoAOKrw+ZVa628XBqT7MMETukKMGkn+QvS1V7OPUupc4JHC26cIxo7fCDxRGG0xr5RaASwEFMEj92it7yp8/n0EE84AbAOSpQ5CiP2Ru32EGJyjC/+eBLxMMMbKydA7qcyJwGuF5ccWlr9fKfXpwudkHBUxpsiZvxB97dnsA5AAPqyUugboAj6otW5WSp2ilHqaoH1/mdb6OaXUF4FfKqW+RtDm/wF2VxxCjBkysJsQ+1GoDK7QWq8Z7bIIMVyk2UcIIUJIzvyFECKE5MxfCCFCSJK/EEKEkCR/IYQIIUn+QggRQpL8hRAihP4f5vZ0KWmsQMUAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 641us/step\n",
      "MAE Train = 0.27148281717505557\n",
      "MSE Train = 0.13365274093560509\n",
      "R2  = 0.08709936742486146\n",
      "\n",
      "9/9 [==============================] - 0s 907us/step\n",
      "MAE Test = 28.59801805088114\n",
      "MSE Test = 226604.43178403444\n",
      "R2  = -2387508.198053424\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 1s 26ms/step - loss: 0.9082 - mse: 0.9082 - val_loss: 0.6572 - val_mse: 0.6572\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6130 - mse: 0.6130 - val_loss: 0.4683 - val_mse: 0.4683\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4515 - mse: 0.4515 - val_loss: 0.3616 - val_mse: 0.3616\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3591 - mse: 0.3591 - val_loss: 0.3028 - val_mse: 0.3028\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3037 - mse: 0.3037 - val_loss: 0.2663 - val_mse: 0.2663\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2692 - mse: 0.2692 - val_loss: 0.2417 - val_mse: 0.2417\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2459 - mse: 0.2459 - val_loss: 0.2275 - val_mse: 0.2275\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2289 - mse: 0.2289 - val_loss: 0.2202 - val_mse: 0.2202\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2157 - mse: 0.2157 - val_loss: 0.2110 - val_mse: 0.2110\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2047 - mse: 0.2047 - val_loss: 0.2060 - val_mse: 0.2060\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1968 - mse: 0.1968 - val_loss: 0.2025 - val_mse: 0.2025\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1897 - mse: 0.1897 - val_loss: 0.1991 - val_mse: 0.1991\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1838 - mse: 0.1838 - val_loss: 0.1961 - val_mse: 0.1961\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1783 - mse: 0.1783 - val_loss: 0.1930 - val_mse: 0.1930\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1740 - mse: 0.1740 - val_loss: 0.1916 - val_mse: 0.1916\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1697 - mse: 0.1697 - val_loss: 0.1906 - val_mse: 0.1906\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1666 - mse: 0.1666 - val_loss: 0.1902 - val_mse: 0.1902\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1629 - mse: 0.1629 - val_loss: 0.1885 - val_mse: 0.1885\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1596 - mse: 0.1596 - val_loss: 0.1872 - val_mse: 0.1872\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1568 - mse: 0.1568 - val_loss: 0.1850 - val_mse: 0.1850\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1547 - mse: 0.1547 - val_loss: 0.1849 - val_mse: 0.1849\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1523 - mse: 0.1523 - val_loss: 0.1831 - val_mse: 0.1831\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1505 - mse: 0.1505 - val_loss: 0.1821 - val_mse: 0.1821\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1484 - mse: 0.1484 - val_loss: 0.1815 - val_mse: 0.1815\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1467 - mse: 0.1467 - val_loss: 0.1813 - val_mse: 0.1813\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1452 - mse: 0.1452 - val_loss: 0.1812 - val_mse: 0.1812\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1439 - mse: 0.1439 - val_loss: 0.1823 - val_mse: 0.1823\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1430 - mse: 0.1430 - val_loss: 0.1818 - val_mse: 0.1818\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1411 - mse: 0.1411 - val_loss: 0.1792 - val_mse: 0.1792\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1397 - mse: 0.1397 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1387 - mse: 0.1387 - val_loss: 0.1755 - val_mse: 0.1755\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1373 - mse: 0.1373 - val_loss: 0.1747 - val_mse: 0.1747\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1363 - mse: 0.1363 - val_loss: 0.1724 - val_mse: 0.1724\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1358 - mse: 0.1358 - val_loss: 0.1725 - val_mse: 0.1725\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1347 - mse: 0.1347 - val_loss: 0.1744 - val_mse: 0.1744\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1338 - mse: 0.1338 - val_loss: 0.1752 - val_mse: 0.1752\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1328 - mse: 0.1328 - val_loss: 0.1748 - val_mse: 0.1748\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1319 - mse: 0.1319 - val_loss: 0.1728 - val_mse: 0.1728\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1305 - mse: 0.1305 - val_loss: 0.1738 - val_mse: 0.1738\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1294 - mse: 0.1294 - val_loss: 0.1774 - val_mse: 0.1774\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1291 - mse: 0.1291 - val_loss: 0.1784 - val_mse: 0.1784\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1292 - mse: 0.1292 - val_loss: 0.1806 - val_mse: 0.1806\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1286 - mse: 0.1286 - val_loss: 0.1807 - val_mse: 0.1807\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1273 - mse: 0.1273 - val_loss: 0.1794 - val_mse: 0.1794\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1262 - mse: 0.1262 - val_loss: 0.1787 - val_mse: 0.1787\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1254 - mse: 0.1254 - val_loss: 0.1783 - val_mse: 0.1783\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1246 - mse: 0.1246 - val_loss: 0.1794 - val_mse: 0.1794\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1241 - mse: 0.1241 - val_loss: 0.1780 - val_mse: 0.1780\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1235 - mse: 0.1235 - val_loss: 0.1781 - val_mse: 0.1781\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1231 - mse: 0.1231 - val_loss: 0.1787 - val_mse: 0.1787\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1227 - mse: 0.1227 - val_loss: 0.1775 - val_mse: 0.1775\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1222 - mse: 0.1222 - val_loss: 0.1782 - val_mse: 0.1782\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1213 - mse: 0.1213 - val_loss: 0.1765 - val_mse: 0.1765\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1212 - mse: 0.1212 - val_loss: 0.1756 - val_mse: 0.1756\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1205 - mse: 0.1205 - val_loss: 0.1770 - val_mse: 0.1770\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1206 - mse: 0.1206 - val_loss: 0.1771 - val_mse: 0.1771\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1204 - mse: 0.1204 - val_loss: 0.1766 - val_mse: 0.1766\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1195 - mse: 0.1195 - val_loss: 0.1777 - val_mse: 0.1777\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1190 - mse: 0.1190 - val_loss: 0.1795 - val_mse: 0.1795\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1187 - mse: 0.1187 - val_loss: 0.1829 - val_mse: 0.1829\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1186 - mse: 0.1186 - val_loss: 0.1816 - val_mse: 0.1816\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.1803 - val_mse: 0.1803\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1174 - mse: 0.1174 - val_loss: 0.1799 - val_mse: 0.1799\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1169 - mse: 0.1169 - val_loss: 0.1795 - val_mse: 0.1795\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1159 - mse: 0.1159 - val_loss: 0.1816 - val_mse: 0.1816\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1152 - mse: 0.1152 - val_loss: 0.1816 - val_mse: 0.1816\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1146 - mse: 0.1146 - val_loss: 0.1805 - val_mse: 0.1805\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1143 - mse: 0.1143 - val_loss: 0.1819 - val_mse: 0.1819\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1139 - mse: 0.1139 - val_loss: 0.1776 - val_mse: 0.1776\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1151 - mse: 0.1151 - val_loss: 0.1753 - val_mse: 0.1753\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1137 - mse: 0.1137 - val_loss: 0.1795 - val_mse: 0.1795\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1130 - mse: 0.1130 - val_loss: 0.1839 - val_mse: 0.1839\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1125 - mse: 0.1125 - val_loss: 0.1848 - val_mse: 0.1848\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 0.1832 - val_mse: 0.1832\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.1112 - mse: 0.1112 - val_loss: 0.1846 - val_mse: 0.1846\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1107 - mse: 0.1107 - val_loss: 0.1823 - val_mse: 0.1823\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1106 - mse: 0.1106 - val_loss: 0.1841 - val_mse: 0.1841\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1099 - mse: 0.1099 - val_loss: 0.1854 - val_mse: 0.1854\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1092 - mse: 0.1092 - val_loss: 0.1849 - val_mse: 0.1849\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1089 - mse: 0.1089 - val_loss: 0.1860 - val_mse: 0.1860\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1084 - mse: 0.1084 - val_loss: 0.1860 - val_mse: 0.1860\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1079 - mse: 0.1079 - val_loss: 0.1869 - val_mse: 0.1869\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1078 - mse: 0.1078 - val_loss: 0.1882 - val_mse: 0.1882\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 0.1890 - val_mse: 0.1890\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1068 - mse: 0.1068 - val_loss: 0.1883 - val_mse: 0.1883\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1064 - mse: 0.1064 - val_loss: 0.1872 - val_mse: 0.1872\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 0.1889 - val_mse: 0.1889\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1059 - mse: 0.1059 - val_loss: 0.1916 - val_mse: 0.1916\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 0.1911 - val_mse: 0.1911\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1052 - mse: 0.1052 - val_loss: 0.1910 - val_mse: 0.1910\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1049 - mse: 0.1049 - val_loss: 0.1902 - val_mse: 0.1902\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1046 - mse: 0.1046 - val_loss: 0.1920 - val_mse: 0.1920\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1046 - mse: 0.1046 - val_loss: 0.1971 - val_mse: 0.1971\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1041 - mse: 0.1041 - val_loss: 0.1954 - val_mse: 0.1954\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1035 - mse: 0.1035 - val_loss: 0.1940 - val_mse: 0.1940\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1031 - mse: 0.1031 - val_loss: 0.1954 - val_mse: 0.1954\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1027 - mse: 0.1027 - val_loss: 0.1934 - val_mse: 0.1934\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1024 - mse: 0.1024 - val_loss: 0.1938 - val_mse: 0.1938\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1019 - mse: 0.1019 - val_loss: 0.1954 - val_mse: 0.1954\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1016 - mse: 0.1016 - val_loss: 0.1955 - val_mse: 0.1955\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 645us/step\n",
      "MAE Train = 0.25338574842376416\n",
      "MSE Train = 0.11987786793489519\n",
      "R2  = 0.18118715184260892\n",
      "\n",
      "9/9 [==============================] - 0s 844us/step\n",
      "MAE Test = 575.8046162506976\n",
      "MSE Test = 93414369.47820465\n",
      "R2  = -984215817.745025\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1699: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 10ms/step - loss: 0.9471 - mse: 0.9471 - val_loss: 0.6269 - val_mse: 0.6269\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.4693 - mse: 0.4693 - val_loss: 0.4025 - val_mse: 0.4025\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.3100 - mse: 0.3100 - val_loss: 0.3326 - val_mse: 0.3326\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2413 - mse: 0.2413 - val_loss: 0.3006 - val_mse: 0.3006\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.2033 - mse: 0.2033 - val_loss: 0.2833 - val_mse: 0.2833\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1808 - mse: 0.1808 - val_loss: 0.2721 - val_mse: 0.2721\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1679 - mse: 0.1679 - val_loss: 0.2659 - val_mse: 0.2659\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1587 - mse: 0.1587 - val_loss: 0.2603 - val_mse: 0.2603\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1517 - mse: 0.1517 - val_loss: 0.2548 - val_mse: 0.2548\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1467 - mse: 0.1467 - val_loss: 0.2513 - val_mse: 0.2513\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1413 - mse: 0.1413 - val_loss: 0.2473 - val_mse: 0.2473\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1370 - mse: 0.1370 - val_loss: 0.2473 - val_mse: 0.2473\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1335 - mse: 0.1335 - val_loss: 0.2456 - val_mse: 0.2456\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1309 - mse: 0.1309 - val_loss: 0.2484 - val_mse: 0.2484\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1289 - mse: 0.1289 - val_loss: 0.2422 - val_mse: 0.2422\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1260 - mse: 0.1260 - val_loss: 0.2404 - val_mse: 0.2404\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1240 - mse: 0.1240 - val_loss: 0.2393 - val_mse: 0.2393\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1221 - mse: 0.1221 - val_loss: 0.2384 - val_mse: 0.2384\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1202 - mse: 0.1202 - val_loss: 0.2363 - val_mse: 0.2363\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1190 - mse: 0.1190 - val_loss: 0.2282 - val_mse: 0.2282\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1185 - mse: 0.1185 - val_loss: 0.2273 - val_mse: 0.2273\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1178 - mse: 0.1178 - val_loss: 0.2311 - val_mse: 0.2311\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1158 - mse: 0.1158 - val_loss: 0.2287 - val_mse: 0.2287\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1144 - mse: 0.1144 - val_loss: 0.2291 - val_mse: 0.2291\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1126 - mse: 0.1126 - val_loss: 0.2294 - val_mse: 0.2294\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1118 - mse: 0.1118 - val_loss: 0.2287 - val_mse: 0.2287\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1104 - mse: 0.1104 - val_loss: 0.2271 - val_mse: 0.2271\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1097 - mse: 0.1097 - val_loss: 0.2261 - val_mse: 0.2261\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1083 - mse: 0.1083 - val_loss: 0.2254 - val_mse: 0.2254\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1078 - mse: 0.1078 - val_loss: 0.2211 - val_mse: 0.2211\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1073 - mse: 0.1073 - val_loss: 0.2210 - val_mse: 0.2210\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1062 - mse: 0.1062 - val_loss: 0.2219 - val_mse: 0.2219\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1051 - mse: 0.1051 - val_loss: 0.2209 - val_mse: 0.2209\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1045 - mse: 0.1045 - val_loss: 0.2224 - val_mse: 0.2224\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1036 - mse: 0.1036 - val_loss: 0.2223 - val_mse: 0.2223\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1033 - mse: 0.1033 - val_loss: 0.2231 - val_mse: 0.2231\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1039 - mse: 0.1039 - val_loss: 0.2275 - val_mse: 0.2275\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1029 - mse: 0.1029 - val_loss: 0.2228 - val_mse: 0.2228\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1013 - mse: 0.1013 - val_loss: 0.2217 - val_mse: 0.2217\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1007 - mse: 0.1007 - val_loss: 0.2218 - val_mse: 0.2218\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1004 - mse: 0.1004 - val_loss: 0.2192 - val_mse: 0.2192\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 0.2189 - val_mse: 0.2189\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1001 - mse: 0.1001 - val_loss: 0.2209 - val_mse: 0.2209\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.1002 - mse: 0.1002 - val_loss: 0.2179 - val_mse: 0.2179\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0998 - mse: 0.0998 - val_loss: 0.2207 - val_mse: 0.2207\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0982 - mse: 0.0982 - val_loss: 0.2206 - val_mse: 0.2206\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0974 - mse: 0.0974 - val_loss: 0.2181 - val_mse: 0.2181\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0967 - mse: 0.0967 - val_loss: 0.2193 - val_mse: 0.2193\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0966 - mse: 0.0966 - val_loss: 0.2247 - val_mse: 0.2247\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0964 - mse: 0.0964 - val_loss: 0.2223 - val_mse: 0.2223\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0954 - mse: 0.0954 - val_loss: 0.2185 - val_mse: 0.2185\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0950 - mse: 0.0950 - val_loss: 0.2192 - val_mse: 0.2192\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0942 - mse: 0.0942 - val_loss: 0.2209 - val_mse: 0.2209\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0941 - mse: 0.0941 - val_loss: 0.2213 - val_mse: 0.2213\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0930 - mse: 0.0930 - val_loss: 0.2206 - val_mse: 0.2206\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 0.2201 - val_mse: 0.2201\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 0.2180 - val_mse: 0.2180\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0922 - mse: 0.0922 - val_loss: 0.2181 - val_mse: 0.2181\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0926 - mse: 0.0926 - val_loss: 0.2179 - val_mse: 0.2179\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0917 - mse: 0.0917 - val_loss: 0.2207 - val_mse: 0.2207\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0910 - mse: 0.0910 - val_loss: 0.2200 - val_mse: 0.2200\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0908 - mse: 0.0908 - val_loss: 0.2230 - val_mse: 0.2230\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0905 - mse: 0.0905 - val_loss: 0.2227 - val_mse: 0.2227\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.2198 - val_mse: 0.2198\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 0.2207 - val_mse: 0.2207\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 0.2159 - val_mse: 0.2159\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0897 - mse: 0.0897 - val_loss: 0.2219 - val_mse: 0.2219\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 0.2310 - val_mse: 0.2310\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0902 - mse: 0.0902 - val_loss: 0.2307 - val_mse: 0.2307\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0879 - mse: 0.0879 - val_loss: 0.2321 - val_mse: 0.2321\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0879 - mse: 0.0879 - val_loss: 0.2277 - val_mse: 0.2277\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.2255 - val_mse: 0.2255\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0876 - mse: 0.0876 - val_loss: 0.2225 - val_mse: 0.2225\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0871 - mse: 0.0871 - val_loss: 0.2247 - val_mse: 0.2247\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0895 - mse: 0.0895 - val_loss: 0.2277 - val_mse: 0.2277\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0872 - mse: 0.0872 - val_loss: 0.2189 - val_mse: 0.2189\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0868 - mse: 0.0868 - val_loss: 0.2165 - val_mse: 0.2165\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0854 - mse: 0.0854 - val_loss: 0.2188 - val_mse: 0.2188\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0852 - mse: 0.0852 - val_loss: 0.2203 - val_mse: 0.2203\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0845 - mse: 0.0845 - val_loss: 0.2206 - val_mse: 0.2206\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.2211 - val_mse: 0.2211\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0844 - mse: 0.0844 - val_loss: 0.2218 - val_mse: 0.2218\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0840 - mse: 0.0840 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0835 - mse: 0.0835 - val_loss: 0.2221 - val_mse: 0.2221\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0843 - mse: 0.0843 - val_loss: 0.2193 - val_mse: 0.2193\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0838 - mse: 0.0838 - val_loss: 0.2238 - val_mse: 0.2238\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0835 - mse: 0.0835 - val_loss: 0.2265 - val_mse: 0.2265\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0826 - mse: 0.0826 - val_loss: 0.2238 - val_mse: 0.2238\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0818 - mse: 0.0818 - val_loss: 0.2250 - val_mse: 0.2250\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0814 - mse: 0.0814 - val_loss: 0.2244 - val_mse: 0.2244\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0812 - mse: 0.0812 - val_loss: 0.2275 - val_mse: 0.2275\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0817 - mse: 0.0817 - val_loss: 0.2237 - val_mse: 0.2237\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0907 - mse: 0.0907 - val_loss: 0.2164 - val_mse: 0.2164\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0858 - mse: 0.0858 - val_loss: 0.2224 - val_mse: 0.2224\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0834 - mse: 0.0834 - val_loss: 0.2215 - val_mse: 0.2215\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0807 - mse: 0.0807 - val_loss: 0.2204 - val_mse: 0.2204\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0797 - mse: 0.0797 - val_loss: 0.2236 - val_mse: 0.2236\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0801 - mse: 0.0801 - val_loss: 0.2254 - val_mse: 0.2254\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0796 - mse: 0.0796 - val_loss: 0.2223 - val_mse: 0.2223\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.0789 - mse: 0.0789 - val_loss: 0.2225 - val_mse: 0.2225\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 629us/step\n",
      "MAE Train = 0.2337485538850152\n",
      "MSE Train = 0.10666979902944224\n",
      "R2  = 0.2714034420172601\n",
      "\n",
      "9/9 [==============================] - 0s 729us/step\n",
      "MAE Test = 4934.439489830413\n",
      "MSE Test = 6865621537.703811\n",
      "R2  = -72336337124.3202\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
