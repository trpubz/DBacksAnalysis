{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Prep & Modeling\n",
    "## Filtering"
   ],
   "metadata": {
    "collapsed": false,
    "id": "3m83__aSeqPA"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "assert pd.__version__ >= '1.5', \"Upgrade Pandas to 1.5+\"\n",
    "import numpy as np\n",
    "# Make numpy printouts easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "marte_raw = pd.read_csv('marte_vs_nlwest_19_22.csv',\n",
    "                        usecols=['pitch_type', 'game_date', 'release_speed', 'release_pos_x', 'release_pos_z', 'pitcher', 'zone', 'des', 'p_throws', 'bb_type', 'balls', 'strikes', 'game_year', 'pfx_x', 'pfx_z', 'hc_x', 'hc_y', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_spin_rate', 'release_extension', 'estimated_woba_using_speedangle', 'woba_value', 'woba_denom', 'iso_value', 'launch_speed_angle', 'pitch_name'])\n",
    "\n",
    "# rename the primary response variable\n",
    "marte_raw.rename(columns={'estimated_woba_using_speedangle': 'xwOBA'}, inplace=True)\n",
    "print(f\"data-set shape prior to filtering: {marte_raw.shape}\")\n",
    "\n",
    "# filter sacrifice events; if woba_denom is NaN, then sacrifice event\n",
    "# filter walks and strikeout events\n",
    "marte_raw.dropna(axis='rows', subset=['woba_denom', 'xwOBA'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering sac hits, walks, strikeouts: {marte_raw.shape}\")\n",
    "\n",
    "# filter missing observation data\n",
    "marte_raw.dropna(axis='rows', subset=['release_spin_rate'], how='any', inplace=True)\n",
    "print(f\"data-set shape after to filtering missing spin observations: {marte_raw.shape}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- release_speed\n",
    "    - Pitch velocities from 2008-16 are via Pitch F/X, and adjusted to roughly out-of-hand release point. All velocities from 2017 and beyond are Statcast, which are reported out-of-hand.\n",
    "- release_pos_x\n",
    "    - horizontal Release Position of the ball measured in feet from the catcher's perspective.\n",
    "- release_pos_z\n",
    "    - Vertical Release Position of the ball measured in feet from the catcher's perspective.\n",
    "- plate_x\n",
    "    - Horizontal position of the ball when it crosses home plate from the catcher's perspective.\n",
    "- plate_z\n",
    "    - Vertical position of the ball when it crosses home plate from the catcher's perspective.\n",
    "- pitcher\n",
    "    - MLB Player Id tied to the play event.\n",
    "- zone\n",
    "    - Zone location of the ball when it crosses the plate from the catcher's perspective.\n",
    "- pfx_x\n",
    "    - Horizontal movement in feet from the catcher's perspective.\n",
    "- pfx_z\n",
    "    - Vertical movement in feet from the catcher's perpsective.\n",
    "- effective_speed\n",
    "    - Derived speed based on the the extension of the pitcher's release.\n",
    "- release_spin\n",
    "    - Spin rate of pitch tracked by Statcast.\n",
    "- spin_axis\n",
    "    - The Spin Axis in the 2D X-Z plane in degrees from 0 to 360, such that 180 represents a pure backspin fastball and 0 degrees represents a pure topspin (12-6) curveball"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Filtering ext., Computed Features, NaN Conversions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# filter raw set with proposed model metrics\n",
    "marte_vs = marte_raw.drop(columns=['woba_value','game_year', 'pitcher', 'game_date', 'release_pos_x', 'release_pos_z', 'des', 'bb_type', 'balls', 'strikes', 'hc_x', 'hc_y', 'hit_distance_sc', 'launch_speed', 'launch_angle', 'effective_speed', 'release_extension', 'woba_denom', 'iso_value', 'launch_speed_angle', 'pitch_name'])\n",
    "print(f\"new data-set shape after to filtering for proper metrics: {marte_vs.shape}\")\n",
    "\n",
    "# vectorize the horizontal & vertical movement using pythagorean theorem\n",
    "marte_vs['pfx_v'] = np.sqrt(marte_vs.pfx_x ** 2 + marte_vs.pfx_z ** 2)\n",
    "\n",
    "print(f\"number of NaN xwOBA PAs prior to conversion: {marte_vs.xwOBA.isnull().sum()}\")\n",
    "\n",
    "# if you do not filter walks and strikeouts from the raw data, this will allow more granular filtering\n",
    "################################################################\n",
    "# # if the xwOBA stat is NaN & a strikeout, then need to use the woba_value\n",
    "# marte_vs['xwOBA'] = marte_vs.apply(lambda x: x.woba_value if (math.isnan(x.xwOBA) and x.woba_value == 0.0) else x.xwOBA, axis=1)\n",
    "#\n",
    "# # filter out walks, dropped 54 walks\n",
    "# marte_vs.dropna(axis='rows', subset=['xwOBA'], how='any', inplace=True)\n",
    "# print(f\"data-set shape after to filtering walks: {marte_vs.shape}\")\n",
    "##########################################################\n",
    "\n",
    "# reorder columns for logical readability\n",
    "marte_vs = marte_vs.reindex(columns=['xwOBA', 'p_throws', 'pitch_type', 'release_speed', 'release_spin_rate', 'zone', 'pfx_x', 'pfx_z', 'pfx_v'])\n",
    "\n",
    "print(marte_vs.head())\n",
    "print(pd.pivot_table(marte_vs.describe(), columns=marte_vs.describe().index))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " â„¢ exploration\n",
    "import seaborn as sns\n",
    "\n",
    "# sns.pairplot(marte_vs[['xwOBA', 'woba_value', 'p_throws', 'pitch_type', 'release_speed', 'release_spin_rate', 'spin_axis', 'zone', 'pfx_x', 'pfx_z', 'pfx_v']], corner=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sns.set(rc={\"figure.figsize\":(4, 7)})\n",
    "sns.kdeplot(marte_vs.xwOBA, hue=marte_vs['pitch_type'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sns.histplot(marte_vs, x='xwOBA')  # potential need for response transformation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "# Yeo-Johnson transformation of output\n",
    "pt_out = PowerTransformer(standardize=True)\n",
    "# extract target and convert to 1D array\n",
    "y_xwOBA = marte_vs.xwOBA.to_numpy().reshape(-1, 1)\n",
    "# transformation\n",
    "trx_xwOBA = pt_out.fit_transform(y_xwOBA)\n",
    "sns.histplot(trx_xwOBA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import QuantileTransformer, quantile_transform\n",
    "# qt transformation output\n",
    "\n",
    "qt_xwOBA = quantile_transform(y_xwOBA, n_quantiles=6, output_distribution=\"normal\", copy=True)\n",
    "sns.histplot(qt_xwOBA)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ff = marte_vs.groupby(['pitch_type']).get_group('FF')\n",
    "g = sns.jointplot(data=ff, x='release_spin_rate', y='release_speed', kind='hex')\n",
    "g.fig.suptitle(\"Raw\")\n",
    "g.fig.subplots_adjust(top=0.95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# used for positive values\n",
    "pt = PowerTransformer(method='box-cox')\n",
    "bc_trx = pt.fit_transform(ff[['release_spin_rate', 'release_speed']])\n",
    "# convert to df\n",
    "bc_trx = pd.DataFrame(bc_trx, columns=pt.get_feature_names_out())\n",
    "\n",
    "g = sns.jointplot(data=bc_trx, x='release_spin_rate', y='release_speed', kind='hex')\n",
    "g.fig.suptitle(\"PowerTransformer\")\n",
    "g.fig.subplots_adjust(top=0.95)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations\n",
    "### Dummies\n",
    "A common mistake is to apply transformations to the entire data before splitting into training and test sets. This will bias the model evaluation because information would have leaked from the test set to the training set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "marte_vs_trx = pd.get_dummies(data=marte_vs, columns=['pitch_type', 'zone'])\n",
    "marte_vs_trx = pd.get_dummies(data=marte_vs_trx, columns=['p_throws'], drop_first=True)\n",
    "marte_vs_trx.head()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature and output transformations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = marte_vs_trx.drop(columns=['xwOBA'])  # remove response var and extra features, spin_axis should be converted to categorical if desired to use in analysis, removed earlier on ingest\n",
    "\n",
    "y = marte_vs.xwOBA\n",
    "# split data into training and testing sets\n",
    "\n",
    "X = sm.add_constant(X)   # only needed for sm (not smf)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.35, random_state=1642)\n",
    "\n",
    "print('Train set shape\\n', X_train.shape, y_train.shape)\n",
    "print('Test set shape\\n', X_test.shape, y_test.shape)\n",
    "print('---')\n",
    "\n",
    "# transform numerical data\n",
    "from sklearn.preprocessing import PowerTransformer, MinMaxScaler\n",
    "\n",
    "num_feats = ['release_speed', 'release_spin_rate', 'pfx_v', 'pfx_x', 'pfx_z']\n",
    "# print(X[num_feats].describe())\n",
    "# used for positive values\n",
    "pt = PowerTransformer()\n",
    "# get a transformed series of numerical features\n",
    "X_train_trx = pt.fit_transform(X_train[num_feats])\n",
    "# overwrite raw numerical data\n",
    "X_train[num_feats] = X_train_trx\n",
    "\n",
    "# transform the test set with the trained lambdas\n",
    "X_test_trx = pt.transform(X_test[num_feats])\n",
    "# overwrite raw numerical dataframe\n",
    "X_test[num_feats] = X_test_trx\n",
    "############################\n",
    "# # normalize output\n",
    "# mms = MinMaxScaler().fit(y_train.to_numpy().reshape(-1, 1))\n",
    "# y_train_trx = pd.Series(map(lambda x: x[0], mms.transform(y_train.to_numpy().reshape(-1, 1))), index=y_train.index)\n",
    "# # normalize on the test output, converted to a pandas.Series with the original indicies\n",
    "# y_test_trx = pd.Series(map(lambda x: x[0], mms.transform(y_test.to_numpy().reshape(-1, 1))), index=y_test.index)\n",
    "\n",
    "print('Train trx set shape\\n', X_train_trx.shape, y_train.shape)\n",
    "print('Test trx set shape\\n', X_test_trx.shape, y_test.shape)\n",
    "print('---')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modeling\n",
    "### Naive Model\n",
    "*Note: did not transform the output for the naive model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Marte's xwOBA for last 4 seasons ('19-'22) == .348\n",
    "from sklearn.metrics import *\n",
    "\n",
    "print(y.mean())\n",
    "y_same_xwOBA = pd.Series(.365, index=range(0, y_train.size))\n",
    "# if squared is false then rmse\n",
    "naive_rmse = mean_squared_error(y_true=y_train, y_pred=y_same_xwOBA, squared=False)\n",
    "print(f\"naive mse: {naive_rmse}\")\n",
    "\n",
    "naive_r2 = r2_score(y_true=y_train, y_pred=y_same_xwOBA)\n",
    "print(f\"naive r2 score: {naive_r2}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Classical Modeling\n",
    "#### Model 1 -- OLS full feature\n",
    "no spin axis feature"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model1_feats = ['const', 'release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 'pfx_v', 'pitch_type_CH', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL', 'zone_1', 'zone_2', 'zone_3', 'zone_4', 'zone_5', 'zone_6', 'zone_7', 'zone_8', 'zone_9', 'zone_11', 'zone_12', 'zone_13', 'zone_14', 'p_throws_R']\n",
    "model1 = sm.OLS(endog=y_train, exog=X_train[model1_feats])\n",
    "results1 = model1.fit()\n",
    "print(results1.summary())\n",
    "print('--------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model 1 evaluation\n",
    "xwOBA_pred1 = results1.predict(X_test[model1_feats])\n",
    "\n",
    "m1_mse = mean_squared_error(y_test, xwOBA_pred1, squared=False)\n",
    "print(f\"model1 mse: {m1_mse}\")\n",
    "\n",
    "m1_r2 = r2_score(y_test, xwOBA_pred1)\n",
    "print(f\"model r2 score: {m1_r2}\")\n",
    "\n",
    "# sns.scatterplot(y_test, xwOBA_pred1).set(xlabel='True', ylabel='Predicted')\n",
    "sns.residplot(y_test, xwOBA_pred1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model 2 -- OLS backward selection p-val"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# removed release_speed, p_throws_R, all zones\n",
    "model2_feats = ['const', 'pitch_type_CU', 'pitch_type_SI', 'zone_13', 'zone_14']\n",
    "model2 = sm.OLS(endog=y_train, exog=X_train[model2_feats])\n",
    "results2 = model2.fit()\n",
    "print(results2.summary())\n",
    "print('--------------')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xwOBA_pred2 = results2.predict(X_test[model2_feats])\n",
    "\n",
    "m2_mse = mean_squared_error(y_test, xwOBA_pred2, squared=False)\n",
    "print(f\"model2 mse: {m2_mse}\")\n",
    "\n",
    "m2_r2 = r2_score(y_test, xwOBA_pred2)\n",
    "print(f\"model r2 score: {m2_r2}\")\n",
    "\n",
    "sns.residplot(y_test, xwOBA_pred2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model 2a -- Interaction Variables --------------------------------\n",
    "create a PolynomialFeatures with interactions for all variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
    "#\n",
    "# cat_features = ['pitch_type', 'zone', 'p_throws']\n",
    "# ohe = OneHotEncoder(sparse=False)\n",
    "# # encode the 3 categorical features\n",
    "# marte_vs_enc = ohe.fit_transform(marte_vs[cat_features])\n",
    "# # need to keep index for proper concat\n",
    "# # convert to df\n",
    "# ohe_df = pd.DataFrame(marte_vs_enc, columns=ohe.get_feature_names_out(), index=marte_vs.index)\n",
    "# # merge dataframes and drop redundant columns\n",
    "# data = pd.concat([ohe_df, marte_vs], axis='columns').drop(columns=['pitch_type', 'zone', 'p_throws', 'game_year', 'pitcher', 'xwOBA', 'woba_value', 'spin_axis'], axis='columns')\n",
    "# num_feats = ['release_speed', 'release_spin_rate', 'pfx_v']\n",
    "# # normalize numerical features\n",
    "# data[['release_speed', 'release_spin_rate', 'pfx_v']] = MinMaxScaler().fit_transform(data[num_feats])\n",
    "# poly = PolynomialFeatures(interaction_only=True)\n",
    "# # interaction dataframe with transformations\n",
    "# # TODO need to not combine pitch type interactions and zone interactions with themselves\n",
    "# marte_vs_inter = pd.DataFrame(poly.fit_transform(data), columns=poly.get_feature_names_out(), index=marte_vs.index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ###  Recursive Feature Elimination\n",
    "# from sklearn.feature_selection import RFE\n",
    "# from sklearn import linear_model\n",
    "#\n",
    "# scores = pd.DataFrame(columns=['scores','num features'])\n",
    "# model2a = linear_model.LinearRegression()\n",
    "#\n",
    "# for k in range(1, marte_vs_inter.shape[1]):\n",
    "#     # rfe = RFE(model, k)\n",
    "#     rfe = RFE(estimator=model2a, n_features_to_select=k)\n",
    "#     fit = rfe.fit(marte_vs_inter, marte_vs.xwOBA)\n",
    "#     score = fit.score(marte_vs_inter, marte_vs.xwOBA)\n",
    "#     run = pd.Series({'scores': score, 'features': k})\n",
    "#     scores = pd.concat([scores, run.to_frame().T], ignore_index=True)\n",
    "#     # f = fit.get_support(1) #the most important features\n",
    "#     #\n",
    "#     # # final_features = data[data.columns[f]] # final features: this gives wrong results\n",
    "#     # final_features = X[X.columns[f]] # final features\n",
    "#\n",
    "#     print(\"Num Features: %d\" % fit.n_features_)\n",
    "#     # print(\"Selected Features: %s\" % final_features.columns)\n",
    "#     print(\"Score: %2.2f\" % score)\n",
    "#     print(\"----------\")\n",
    "#\n",
    "# sns.lineplot(data=scores, x='features', y='scores')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model 2b RFE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression, LassoLarsIC\n",
    "\n",
    "scores = pd.DataFrame(columns=['test scores', 'train scores', 'num features'])\n",
    "\n",
    "model2b = LinearRegression()\n",
    "\n",
    "for k in range(1, 28):\n",
    "    # rfe = RFE(model, k)\n",
    "\n",
    "    rfe = RFE(estimator=model2b, n_features_to_select=k)\n",
    "    fit = rfe.fit(X_train, y_train)\n",
    "    train_score = fit.score(X_train, y_train)\n",
    "    test_score = fit.score(X_test, y_test)\n",
    "    if test_score < 0:\n",
    "        continue\n",
    "    run = pd.Series({'train scores': train_score, 'test scores': test_score,'num features': k})\n",
    "    scores = pd.concat([scores, run.to_frame().T], ignore_index=True)\n",
    "\n",
    "    f = fit.get_support(1) #the most important features\n",
    "    final_features = X_train[X_train.columns[f]] # final features\n",
    "\n",
    "    print(\"Num Features: %d\" % fit.n_features_)\n",
    "    print(\"Selected Features: %s\" % final_features.columns)\n",
    "    print(\"Test Score: %2.3f\" % test_score)\n",
    "    print(\"----------\")\n",
    "\n",
    "mod2b_feats = ['const', 'pitch_type_SI', 'pitch_type_CU', 'zone_13']\n",
    "y_pred_mod2b = model2b.fit(X_train[mod2b_feats], y_train).predict(X_test[mod2b_feats])\n",
    "\n",
    "m2b_mse = mean_squared_error(y_test, y_pred_mod2b, squared=False)\n",
    "print(f\"model3 mse: {m2b_mse}\")\n",
    "\n",
    "m2b_r2 = r2_score(y_test, y_pred_mod2b)\n",
    "print(f\"model3 r2 score: {m2b_r2}\")\n",
    "\n",
    "print(f\"aic: {sm.OLS(endog=y_train, exog=X_train[mod2b_feats]).fit().aic}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = scores.set_index('num features')\n",
    "sns.lineplot(data=scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model 3.5 LassoLarcIC regression\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_model_selection.html"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoLarsIC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "model3_feats = ['const', 'release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 'pfx_v', 'pitch_type_CH', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL', 'zone_1', 'zone_2', 'zone_3', 'zone_4', 'zone_5', 'zone_6', 'zone_7', 'zone_8', 'zone_9', 'zone_11', 'zone_12', 'zone_13', 'zone_14', 'p_throws_R']\n",
    "\n",
    "lasso_lars_ic = make_pipeline(LassoLarsIC(criterion=\"aic\", fit_intercept=True)).fit(X_train[model3_feats], y=y_train)\n",
    "\n",
    "y_pred_mod3 = lasso_lars_ic.predict(X_test[model3_feats])\n",
    "\n",
    "results = pd.DataFrame(\n",
    "    {\n",
    "        \"alphas\": lasso_lars_ic[-1].alphas_,\n",
    "        \"AIC criterion\": lasso_lars_ic[-1].criterion_,\n",
    "    }\n",
    ").set_index(\"alphas\")\n",
    "alpha_aic = lasso_lars_ic[-1].alpha_\n",
    "\n",
    "m3_mse = mean_squared_error(y_test, y_pred_mod3, squared=False)\n",
    "print(f\"model3 mse: {m3_mse}\")\n",
    "\n",
    "m3_r2 = r2_score(y_test, y_pred_mod3)\n",
    "print(f\"model r2 score: {m3_r2}\")\n",
    "\n",
    "print(f\"lowest aic: {lasso_lars_ic[-1].criterion_.min()}\")\n",
    "\n",
    "sns.residplot(y_test, y_pred_mod3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ax = results.plot()\n",
    "ax.vlines(\n",
    "    alpha_aic,\n",
    "    results[\"AIC criterion\"].min(),\n",
    "    results[\"AIC criterion\"].max(),\n",
    "    label=\"alpha: AIC estimate\",\n",
    "    linestyles=\"--\",\n",
    "    color=\"tab:blue\",\n",
    ")\n",
    "ax.set_xlabel(r\"$\\alpha$\")\n",
    "ax.set_ylabel(\"criterion\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# try groupby pitch_type\n",
    "# convert pitch dummies to single column\n",
    "org_pit_col_train = pd.from_dummies(X[['pitch_type_CH', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL']], sep='pitch_type_')\n",
    "# drop dummy pitch_types from transformed train set\n",
    "X_grp_pit = X.drop(columns=['pitch_type_CH', 'pitch_type_CU', 'pitch_type_FC', 'pitch_type_FF', 'pitch_type_FS', 'pitch_type_KC', 'pitch_type_SI', 'pitch_type_SL'], axis=1)\n",
    "# # add back zipped column, need to use .values attribute or will have index issues\n",
    "X_grp_pit['pitch_type'] = org_pit_col_train.values\n",
    "# # groupby pitch_type\n",
    "X_ff = X_grp_pit.groupby(['pitch_type']).get_group('FF')\n",
    "X_ff = X_ff.drop(columns=['pitch_type'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y = marte_vs.groupby(['pitch_type']).get_group('FF').xwOBA\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_ff, y, test_size=0.35, random_state=1642)\n",
    "\n",
    "print(y.describe())\n",
    "print('---')\n",
    "print('Train set shape\\n', X_train.shape, y_train.shape)\n",
    "print('Test set shape\\n', X_test.shape, y_test.shape)\n",
    "print('---')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "num_feats = ['release_speed', 'release_spin_rate', 'pfx_v', 'pfx_x', 'pfx_z']\n",
    "# used for positive values\n",
    "pt = PowerTransformer()\n",
    "nct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('pt_pre', pt, num_feats)\n",
    "    ])\n",
    "\n",
    "# get a transformed series of numerical features\n",
    "X_train_trx = pt.fit_transform(X_train[num_feats])\n",
    "# overwrite raw numerical data\n",
    "X_train[num_feats] = X_train_trx\n",
    "\n",
    "# transform the test set with the trained lambdas\n",
    "X_test_trx = pt.transform(X_test[num_feats])\n",
    "# overwrite raw numerical dataframe\n",
    "X_test[num_feats] = X_test_trx\n",
    "############################\n",
    "# # normalize output\n",
    "# mms = MinMaxScaler().fit(y_train.to_numpy().reshape(-1, 1))\n",
    "# y_train_trx = pd.Series(map(lambda x: x[0], mms.transform(y_train.to_numpy().reshape(-1, 1))), index=y_train.index)\n",
    "# # normalize on the test output, converted to a pandas.Series with the original indicies\n",
    "# y_test_trx = pd.Series(map(lambda x: x[0], mms.transform(y_test.to_numpy().reshape(-1, 1))), index=y_test.index)\n",
    "\n",
    "\n",
    "print('Train trx set shape\\n', X_train_trx.shape, y_train.shape)\n",
    "print('Test trx set shape\\n', X_test_trx.shape, y_test.shape)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Model 4 -- Single pitch filter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "model4_feats = ['const', 'release_speed', 'release_spin_rate', 'pfx_x', 'pfx_z', 'pfx_v']\n",
    "\n",
    "# lm = LinearRegression()\n",
    "# pl = make_pipeline(nct, lm)\n",
    "#\n",
    "# cv = cross_val_score(estimator=pl, X=X_ff[num_feats], y=y, cv=200, scoring='neg_root_mean_squared_error')\n",
    "# cv.mean()\n",
    "\n",
    "model4 = sm.OLS(endog=y_train, exog=X_train[model4_feats])\n",
    "results4 = model4.fit()\n",
    "print(results4.summary())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xwOBA_pred4 = results4.predict(X_test[model4_feats])\n",
    "\n",
    "m4_mse = mean_squared_error(y_test, xwOBA_pred4, squared=False)\n",
    "print(f\"model2 mse: {m4_mse}\")\n",
    "\n",
    "m4_r2 = r2_score(y_test, xwOBA_pred4)\n",
    "print(f\"model r2 score: {m4_r2}\")\n",
    "\n",
    "sns.residplot(y_test, xwOBA_pred4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
